[{"path":"index.html","id":"introduction-to-statistics","chapter":"Introduction to Statistics","heading":"Introduction to Statistics","text":"Welcome captivating world statistics! course provide solid foundation statistical theory taking journey practical aspects subject. Along way, ’ll gain experience statistical software, learn interpret effectively communicate statistical findings, explore range topics data analysis, statistical inference, randomness. areas ’ll delve include linear regression, experimental design, normal distribution, sampling distributions, confidence intervals, bootstrap method.Although statistics field relies mathematics, stands apart distinct discipline. heart course ability interpret results grasp underlying concepts, rather merely obtaining numerical outcomes. engaging diverse set problems, ’ll become well-versed statistical methodologies. However, ’s crucial remember deep understanding concepts key drawing meaningful conclusions.","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Introduction to Statistics","heading":"0.1 Learning Objectives","text":"Learn basic principles data analysis, data produced used studies experiments.Learn basic principles data analysis, data produced used studies experiments.Understand role variation randomness. Understand principles inference: confidence intervals hypothesis tests.Understand role variation randomness. Understand principles inference: confidence intervals hypothesis tests.Develop ability examine statistical arguments critically.Develop ability examine statistical arguments critically.Learn use software (R/RStudio) analyze data, create graphs, perform basic statistical testsLearn use software (R/RStudio) analyze data, create graphs, perform basic statistical tests","code":""},{"path":"what-is-r.html","id":"what-is-r","chapter":"1 What is R?","heading":"1 What is R?","text":"R free open source statistical programming language facilitates statistical computation. myriad application can done R, thanks huge online support community dedicated packages. However, R graphical user interface run typing commands text interface.","code":""},{"path":"what-is-r.html","id":"what-is-rstudio","chapter":"1 What is R?","heading":"1.1 What is RStudio?","text":"RStudio provides graphical interface R! can think RStudio graphical front-end R provides extra functionality. use R programming language RStudio interface essential component course.","code":""},{"path":"what-is-r.html","id":"r-studio-server","chapter":"1 What is R?","heading":"1.2 R Studio Server","text":"quickest way get started go https://maize.mathcs.carleton.edu, opens R Studio window web browser. logged , recommend following:Step 1: Create folder course can save work. Files window, click New Folder.Step 2: Click Tools -> Global Options -> R Markdown. uncheck box says “Show output inline…”(also possible download RStudio laptop. Instructions may found end document.)","code":""},{"path":"what-is-r.html","id":"rrstudio","chapter":"1 What is R?","heading":"1.3 R/RStudio","text":"use R programming language RStudio interface \nessential component course. two options using\nRStudio:server version RStudio web \n(https://maize.mathcs.carleton.edu). advantage using \nserver version work stored cloud,\nautomatically saved backed . means \ncan access work computer campus using web\nbrowser. server may run slow peak days/hours. also recommend\ndownload local version R server computer case rare outages.server version RStudio web \n(https://maize.mathcs.carleton.edu). advantage using \nserver version work stored cloud,\nautomatically saved backed . means \ncan access work computer campus using web\nbrowser. server may run slow peak days/hours. also recommend\ndownload local version R server computer case rare outages.local version RStudio installed machine. \noption highly recommended due computational resources \ncourse demands. Using version can store files local machine. Additionally, can save work GitHub. learn use GitHub beginning course. R RStudio free open-source. Please make sure recently updated R RStudio.local version RStudio installed machine. \noption highly recommended due computational resources \ncourse demands. Using version can store files local machine. Additionally, can save work GitHub. learn use GitHub beginning course. R RStudio free open-source. Please make sure recently updated R RStudio.","code":""},{"path":"what-is-r.html","id":"installing-rrstudio-not-needed-if-you-are-using-the-maize-server","chapter":"1 What is R?","heading":"1.4 Installing R/RStudio (not needed if you are using the maize server)","text":"Download latest version R: https://cran.r-project.org/Download free Rstudio desktop version: https://www.rstudio.com/products/rstudio/download/Use default download install options . R, download “precompiled binary” distribution rather source codeUpdating R/RStudio (needed using maize server)used local version R/RStudio still installed machine, make sure recent versions program.check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .RStudio, check updates menu option Help > Check updates. Follow directions update needed.RStudio, check updates menu option Help > Check updates. Follow directions update needed.work? (sanity check install/update)whatever appropriate operating system launch\nRStudio. get window similar screenshot see\n,\nboring haven’t written code\nmade figures yet!Put cursor pane labeled Console, \ninteract live R process. Create simple object code\nlike x <- 2 * 4 (followed enter return). inspect \nx object typing x followed enter return. see\nvalue 8 printed. happened, ’ve succeeded \ninstalling R RStudio!","code":""},{"path":"what-is-r.html","id":"install-latex-for-knitting-r-markdown-documents-to-pdf","chapter":"1 What is R?","heading":"1.5 Install LaTeX (for knitting R Markdown documents to PDF):","text":"need Latex compiler create pdf document R Markdown file. use maize server, don’t need install anything. using local RStudio, install Latex compiler. recommended installers Windows Mac:MacTeX Mac (3.2GB)MacTeX Mac (3.2GB)MiKTeX Windows (190MB)MiKTeX Windows (190MB)Alternatively, can install tinytex R package running\ninstall.packages(\"tinytex\") console.Alternatively, can install tinytex R package running\ninstall.packages(\"tinytex\") console.","code":""},{"path":"what-is-r.html","id":"updating-rrstudio-not-needed-if-you-are-using-the-maize2-server","chapter":"1 What is R?","heading":"1.6 Updating R/RStudio (not needed if you are using the maize2 server)","text":"used local version R/RStudio still installed machine, make sure recent versions program.check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .RStudio, check updates menu option Help > Check updates. Follow directions update needed.RStudio, check updates menu option Help > Check updates. Follow directions update needed.","code":""},{"path":"what-is-r.html","id":"opening-a-new-file","chapter":"1 What is R?","heading":"1.7 Opening a new file","text":"using Rstudio computer, using File>Open File menu find open .Rmd file.using Maize Rstudio browser:Files tab, select Upload Choose File find .Rmd downloaded. Click OK upload course folder/location maize server account.Files tab, select Upload Choose File find .Rmd downloaded. Click OK upload course folder/location maize server account.Click .Rmd file appropriate folder open file.Click .Rmd file appropriate folder open file.","code":""},{"path":"what-is-r.html","id":"running-codes-and-knitting-.rmd-files","chapter":"1 What is R?","heading":"1.8 Running codes and knitting .Rmd files:","text":"can run line code placing cursor line code clicking Run Selected Line(s)can run line code placing cursor line code clicking Run Selected Line(s)can run entire chunk clicking green triangle right side code chunk.can run entire chunk clicking green triangle right side code chunk.small edit code addition, Knit Markdown. wait end Knit, harder find errors work.small edit code addition, Knit Markdown. wait end Knit, harder find errors work.Format output type: can use pdf_document, html_document type, word_document type.Format output type: can use pdf_document, html_document type, word_document type.Maize users: may also need allow “pop-” web browser knitting documents.Maize users: may also need allow “pop-” web browser knitting documents.","code":""},{"path":"what-is-r.html","id":"few-more-instructions","chapter":"1 What is R?","heading":"1.9 Few More Instructions","text":"default setting Rstudio running chunks “output” (numbers, graphs) \nshown inline within Markdown Rmd. prefer plots appear right console chunk, change settings follows:Select Tools > Global Options.Click R Markdown section uncheck (needed) option Show output inline \nR Markdown documents.Click OK.Now try running R chunks .Rmd file see difference. can recheck box prefer\ndefault setting.","code":""},{"path":"what-is-r.html","id":"vpn","chapter":"1 What is R?","heading":"1.10 VPN","text":"plan work campus term, need install Carleton’s VPN. allow access maize server (needed).Installing GlobalProtect VPNFollow directions install VPN.","code":""},{"path":"r-markdown-basics.html","id":"r-markdown-basics","chapter":"2 R Markdown Basics","heading":"2 R Markdown Basics","text":"R Markdown file (.Rmd file) combines R commands written analyses, ‘knit’ together HTML, PDF, Microsoft Word document.R Markdown file contains three essential elements:Header: header (top) file contains information like document title, author, date preferred output format (pdf_document, word_document, html_document).Header: header (top) file contains information like document title, author, date preferred output format (pdf_document, word_document, html_document).Written analysis: write analysis header embed R code needed. online help shows ways add formatting details like bold words, lists, section labels, etc final pdf/word/html document. example, adding ** word bold word compiled document.Written analysis: write analysis header embed R code needed. online help shows ways add formatting details like bold words, lists, section labels, etc final pdf/word/html document. example, adding ** word bold word compiled document.R chunks: R chunks contain R commands want evaluated. embed chunks within written analysis evaluated compile document.R chunks: R chunks contain R commands want evaluated. embed chunks within written analysis evaluated compile document.Markdown simple formatting syntax authoring HTML, PDF, MS Word documents. details using R Markdown see http://rmarkdown.rstudio.com.","code":""},{"path":"r-markdown-basics.html","id":"r-markdown-syntax","chapter":"2 R Markdown Basics","heading":"2.1 R Markdown Syntax","text":"","code":""},{"path":"r-markdown-basics.html","id":"lists-in-r-markdown","chapter":"2 R Markdown Basics","heading":"2.1.1 Lists in R Markdown:","text":"can use asterisk mark provide emphasis, *italics* **bold**. can create lists dash:produceItem 1Item 2Item 3\nSubitem 1\nSubitem 1Item 4You can embed Latex equations -line, $\\frac{1}{n} \\sum_{=1}^{n} x_{}$ produce \\(\\frac{1}{n} \\sum_{=1}^{n} x_{}\\) new line $$\\text{Var}(X) = \\frac{1}{n-1}\\sum_{-1}^{n} (x_{} - \\bar{x})^2$$ produce \\[\\text{Var}(X) = \\frac{1}{n-1}\\sum_{-1}^{n} (x_{} - \\bar{x})^2\\]","code":"- Item 1\n- Item 2\n- Item 3\n  + Subitem 1\n* Item 4"},{"path":"r-markdown-basics.html","id":"embed-an-r-code-chunk","chapter":"2 R Markdown Basics","heading":"2.1.2 Embed an R code chunk:","text":"Use followingto produce:can also evaluate display results R code. tasks can accomplished suitably labeled chunk like following:","code":"```r\nUse back ticks to \ncreate a block of code\n```Use back ticks to \ncreate a block of code\nsummary(cars)     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \nfit <- lm(dist ~ speed, data = cars)\nfit\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nCoefficients:\n(Intercept)        speed  \n    -17.579        3.932  "},{"path":"r-markdown-basics.html","id":"including-plots","chapter":"2 R Markdown Basics","heading":"2.1.3 Including Plots:","text":"can also embed plots. See Figure 2.1 example:\nFigure 2.1: fancy pie chart.\n(Credit: Yihui Xie)","code":"\npar(mar = c(0, 1, 0, 1))\npie(\n  c(280, 60, 20),\n  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),\n  col = c('#0292D8', '#F7EA39', '#C4B632'),\n  init.angle = -50, border = NA\n)"},{"path":"r-markdown-basics.html","id":"read-in-data-files","chapter":"2 R Markdown Basics","heading":"2.1.4 Read in data files:","text":"","code":"\nsimple_data <- read.csv(\"https://deepbas.io/data/simple-1.dat\", )\nsummary(simple_data)    initials            state                age      \n Length:3           Length:3           Min.   :45.0  \n Class :character   Class :character   1st Qu.:47.5  \n Mode  :character   Mode  :character   Median :50.0  \n                                       Mean   :52.0  \n                                       3rd Qu.:55.5  \n                                       Max.   :61.0  \n     time          \n Length:3          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \nknitr::kable(simple_data)"},{"path":"r-markdown-basics.html","id":"hide-the-code","chapter":"2 R Markdown Basics","heading":"2.1.5 Hide the code:","text":"enter echo = FALSE option R chunk (see .Rmd file). prevents R code printed document; just see results.","code":""},{"path":"homework-guidelines.html","id":"homework-guidelines","chapter":"3 Homework Guidelines","heading":"3 Homework Guidelines","text":"can discuss homework problems classmates, must write homework solutions work R (sharing commands output) unless explicitly told otherwise.Getting help: can use following resources complete homework:\nCarleton faculty (, stat faculty, etc)\nDiscussions classmates (see ) knowledgeable friends\nmath skills center\nLab assistants (CMC 304)\nPrefects\nStudent solutions provided back student textbook student solution manual\nokay get coding help prefects, tutors, classmates, online resources, extra care done write versions codes.\nCarleton faculty (, stat faculty, etc)Discussions classmates (see ) knowledgeable friendsThe math skills centerLab assistants (CMC 304)PrefectsStudent solutions provided back student textbook student solution manualIt okay get coding help prefects, tutors, classmates, online resources, extra care done write versions codes.use resources ones listed complete assignments (homework, reports, etc) class. E.g. use friend’s old assignments reports, answers found internet, textbook (instructor) solutions manual, etc.","code":""},{"path":"homework-guidelines.html","id":"format","chapter":"3 Homework Guidelines","heading":"3.1 Format","text":"top assignment, provide following details:\nClass name (e.g., Stat xxx)\nHomework number (e.g., “homework 1”)\nname\nnames classmates worked part assignment\nClass name (e.g., Stat xxx)Homework number (e.g., “homework 1”)nameThe names classmates worked part assignmentTurn neat, correctly ordered, legible assignment ragged edges. can’t read, graded.Staple - folded corners accepted!","code":""},{"path":"homework-guidelines.html","id":"content","chapter":"3 Homework Guidelines","heading":"3.2 Content","text":"must show work formulas used answer question requires numerical answer. sure show natural sequence work needed answer problem.Use complete sentences answering problem requires explanation overall problem summary.","code":""},{"path":"homework-guidelines.html","id":"problems-using-r","chapter":"3 Homework Guidelines","heading":"3.3 Problems using R","text":"problems must written Word pdf document using R Markdown.Label output problem number.First give answer problem written form, never just give R output answer. Follow written answer “work” contains relevant R commands output (numeric output graphs) needed answer homework problem. include typos unnecessary commands/output.","code":""},{"path":"report-guidelines.html","id":"report-guidelines","chapter":"4 Report Guidelines","heading":"4 Report Guidelines","text":"data analysis report writing class ask two things :use appropriate statistical methods answer research questions andclearly concisely communicate meaning statistics graphs reader basic knowledge statistics.report organized, well-written proper use grammar, contain sound reasoning correct interpretations statistical evidence. Also include least one graphical display data body report. sure hide code used produce !lab reports organized following sections:\nIntroduction: describe data research questions\nResults: describe statistical analysis interpret graphs numbers\nDiscussion: summarize findings answer research questions, describe limitations \nanalysis\nTechnical Appendix: Staple relevant R commands output end written report. including commands without output enough. must appropriately comment code (telling section code ), edit code output (typos errors allowed).\nlab reports organized following sections:Introduction: describe data research questionsResults: describe statistical analysis interpret graphs numbersDiscussion: summarize findings answer research questions, describe limitations \nanalysisTechnical Appendix: Staple relevant R commands output end written report. including commands without output enough. must appropriately comment code (telling section code ), edit code output (typos errors allowed).Type report Word/Google doc (similar software) use R (Excel, Statkey software) analysis. can also use R Markdown write reports need take care include labeled numbered graphical output R main document. Commands numerical output placed Technical Appendix. interested using Markdown talk hints use reports.Type report Word/Google doc (similar software) use R (Excel, Statkey software) analysis. can also use R Markdown write reports need take care include labeled numbered graphical output R main document. Commands numerical output placed Technical Appendix. interested using Markdown talk hints use reports.Carefully decide appropriate graphs numbers include. need show data different forms (e.g. need show histogram boxplot variable). also don’t need include numbers given R output use analysis. also don’t need “show” (prove) skewness outliers using numbers, just use graphs display skewness outliers.Carefully decide appropriate graphs numbers include. need show data different forms (e.g. need show histogram boxplot variable). also don’t need include numbers given R output use analysis. also don’t need “show” (prove) skewness outliers using numbers, just use graphs display skewness outliers.Interpret give meaning graphs numbers choose include report. include algebraic calculations much technical detail.Interpret give meaning graphs numbers choose include report. include algebraic calculations much technical detail.Including Numbers: Never include R numerical output commands. Summarize needed output nicely formatted Word table just integrate numbers writing. include tables, label numerically (Table 1, Table 2, etc) give title. Number order appear paper refer tables number (“Table 1 displays summary statistics income.”).Including Numbers: Never include R numerical output commands. Summarize needed output nicely formatted Word table just integrate numbers writing. include tables, label numerically (Table 1, Table 2, etc) give title. Number order appear paper refer tables number (“Table 1 displays summary statistics income.”).Including Graphs: Resize graphs appropriately fit nicely written report. Large graphs take page , little, writing page impede flow report reduce readability. Label graphs numerically (Figure 1, etc.) occur paper, give title refer number. See stats lab manual chapter 1 need help copying plots Word/google doc.Including Graphs: Resize graphs appropriately fit nicely written report. Large graphs take page , little, writing page impede flow report reduce readability. Label graphs numerically (Figure 1, etc.) occur paper, give title refer number. See stats lab manual chapter 1 need help copying plots Word/google doc.explain every step taken study. example, need include statement “used R create histogram income observed distribution right skewed”. Instead just say ``distribution income skewed right (Figure 1)“.explain every step taken study. example, need include statement “used R create histogram income observed distribution right skewed”. Instead just say ``distribution income skewed right (Figure 1)“.Avoid using weak phrases like “average height men higher average women.” Use numbers bolster explanation: “average height men three inches average women (68.5 vs. 65.5 inches).”Avoid using weak phrases like “average height men higher average women.” Use numbers bolster explanation: “average height men three inches average women (68.5 vs. 65.5 inches).”precision data dictate precision statistics. general, statistics can one two significant digits data. example, height recorded nearest inch mean height reported 65.5 (65.49) rather R value 65.49268.precision data dictate precision statistics. general, statistics can one two significant digits data. example, height recorded nearest inch mean height reported 65.5 (65.49) rather R value 65.49268.Sometimes question posed study ambiguous may one way correctly answer question. grading reports paper, concerned logic conclusions support claim using data statistical evidence.Sometimes question posed study ambiguous may one way correctly answer question. grading reports paper, concerned logic conclusions support claim using data statistical evidence.","code":""},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"tutorial-1-embark-on-your-data-journey","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5 Tutorial 1: Embark on Your Data Journey","text":"","code":""},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"introduction","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.1 Introduction","text":"tutorial introduces basic arithmetic operations, data types, data manipulation functions R.","code":""},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"basic-arithmetic-in-r","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.2 Basic Arithmetic in R","text":"Arithmetic operations R straightforward, results immediately displayed console.However, make results accessible manipulable future use, can store variables.Now can use variables later code","code":"\n2 + 3  # Addition[1] 5\n5 - 2  # Subtraction[1] 3\n2 * 3  # Multiplication[1] 6\n6 / 2  # Division[1] 3\n# Performing operations and storing results in variables\naddition_result <- 2 + 3  # Addition\nsubtraction_result <- 5 - 2  # Subtraction\nmultiplication_result <- 2 * 3  # Multiplication\ndivision_result <- 6 / 2  # Division\naddition_result[1] 5"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"data-types-vector-and-dataframe","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3 Data Types: Vector and DataFrame","text":"","code":""},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"vector","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.1 Vector","text":"vector 1D array R. can create vector using c() function.","code":"\nx <- c(1, 2, 3)\nx[1] 1 2 3"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"using-sequencing","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.1.1 Using Sequencing","text":"can also create vector using sequences. example, following code create vector containing numbers 1 10.","code":"\ny <- 1:10\ny [1]  1  2  3  4  5  6  7  8  9 10"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"dataframe","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.2 DataFrame","text":"DataFrame 2D table R. can create DataFrame using data.frame() function.","code":"\ndf <- data.frame(Name = c(\"Alice\", \"Bob\"), Age = c(25, 30))\ndf   Name Age\n1 Alice  25\n2   Bob  30"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"creating-a-simple-dataset","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.3 Creating a Simple Dataset","text":"can create simple dataset follows:","code":"\ndataset <- data.frame(ID = 1:5, Score = c(90, 85, 88, 92, 89))\ndataset  ID Score\n1  1    90\n2  2    85\n3  3    88\n4  4    92\n5  5    89"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"using-sample-function","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.4 Using sample() Function","text":"generate random combinations vector, use sample() function.","code":"\nsample(x = 1:10, size = 10, replace = FALSE) [1]  8  7  2  9 10  6  5  1  4  3"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"using-head-function","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.3.5 Using head() Function","text":"","code":"\nhead(dataset)  ID Score\n1  1    90\n2  2    85\n3  3    88\n4  4    92\n5  5    89"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"vector-and-data-indexing-using","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.4 Vector and Data Indexing Using []","text":"","code":""},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"vector-indexing","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.4.1 Vector Indexing","text":"can index vector using square brackets [].","code":"\nx[2]  # Access the 2nd element of vector x[1] 2"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"dataframe-indexing","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.4.2 DataFrame Indexing","text":"can index DataFrame using square brackets [].","code":"\ndataset[1,]  # Access the 1st row  ID Score\n1  1    90\ndataset[,1]  # Access the 1st column[1] 1 2 3 4 5"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"reading-data-from-a-url","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.5 Reading Data from a URL","text":"read data URL, can use read.csv() function, read_csv() function readr package.","code":"\nurl <- \"https://www.lock5stat.com/datasets2e/EducationLiteracy.csv\"\ndata_from_url <- read.csv(url)"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"inspecting-the-data","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.5.1 Inspecting the Data","text":"get first 6 rows data, use following:get dimensions data, use following:","code":"\nhead(data_from_url)              Country EducationExpenditure Literacy\n1         Afghanistan                  3.1     31.7\n2             Albania                  3.2     96.8\n3             Algeria                  4.3       NA\n4             Andorra                  3.2       NA\n5              Angola                  3.5     70.6\n6 Antigua and Barbuda                  2.6     99.0\ndim(data_from_url)[1] 188   3"},{"path":"tutorial-1-embark-on-your-data-journey.html","id":"conclusion","chapter":"5 Tutorial 1: Embark on Your Data Journey","heading":"5.6 Conclusion","text":"tutorial covered basic arithmetic, data types, data manipulation functions R.","code":""},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","text":"","code":""},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"introduction-1","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.1 Introduction","text":"tutorial aims enhance data manipulation visualization skills introducing ggplot2, one widely-used data visualization packages R.","code":""},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"ggplot2-essentials","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.2 ggplot2 Essentials","text":"","code":""},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"introduction-to-ggplot","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.2.1 Introduction to ggplot","text":"ggplot2 data visualization package built upon principles “Grammar Graphics.” use ggplot, ’ll first need install load package.","code":"\n# install.packages(\"ggplot2\")   # uncomment to install\nlibrary(ggplot2)"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"simple-bar-graph-using-geom_bar","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.2.2 Simple Bar Graph Using geom_bar()","text":"geom_bar() function used create bar graphs. simple usage might look like:","code":"\n# Create some example data\ndata <- data.frame(Category = c(\"A\", \"B\", \"C\"), Count = c(10, 60, 30))\n\n# Create the bar graph\nggplot(data, aes(x=Category, y=Count)) +\n  geom_bar(stat=\"identity\")"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"adding-aesthetics-with-aes","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.2.3 Adding Aesthetics with aes()","text":"aes() function used map variables visual properties (aesthetics) graph.","code":"\n# Create a graph with different colors for each bar\nggplot(data, aes(x=Category, y=Count, fill=Category)) +\n  geom_bar(stat=\"identity\")"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"facet-plots-using-facet_wrap","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.2.4 Facet Plots Using facet_wrap()","text":"facet_wrap() function splits data subplots based factor variable.","code":"\n# Create more complex data\ndata2 <- data.frame(Category = c(\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"),\n                    Count = c(10, 20, 30, 40, 50, 60),\n                    Type = c(\"big\", \"small\", \"big\", \"small\", \"big\", \"small\"))\n\n# Create the facet plot\nggplot(data2, aes(x=Category, y=Count, fill=Type)) +\n  geom_bar(stat=\"identity\") +\n  facet_wrap(~Type)"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"working-with-tables-and-proportions","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.3 Working with Tables and Proportions","text":"","code":""},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"using-table-function","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.3.1 Using table() Function","text":"table() function R generates table frequencies different combinations categorical variables.rep() function R replicates specified elements input vector number times provided times argument.","code":"\n# Frequency table\n# Replicating the gender and choice data\nrep_gender <- rep(c(\"Male\", \"Female\", \"Female\", \"Female\", \"Male\"), times = 20)\nrep_choice <- rep(c(\"No\", \"No\", \"Yes\", \"No\", \"Yes\"), times = 20)\n\n# Generating the enlarged frequency table\ndata <- data.frame(gender = rep_gender, choice = rep_choice)\nhead(data)  gender choice\n1   Male     No\n2 Female     No\n3 Female    Yes\n4 Female     No\n5   Male    Yes\n6   Male     No\ntable_data <- table(rep_gender, rep_choice)\ntable_data          rep_choice\nrep_gender No Yes\n    Female 40  20\n    Male   20  20"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"using-prop.table-to-get-proportions","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.3.2 Using prop.table() to Get Proportions","text":"","code":"\n# Proportion table\nprop_table_data <- prop.table(table_data)\nprop_table_data          rep_choice\nrep_gender  No Yes\n    Female 0.4 0.2\n    Male   0.2 0.2"},{"path":"tutorial-2-dive-deeper-into-data-visualization-and-statistics-in-r.html","id":"combining-all-together","chapter":"6 Tutorial 2: Dive Deeper into Data Visualization and Statistics in R","heading":"6.4 Combining All Together","text":"Let’s visualize data using ggplot, geom_bar, facet_wrap appropriate labels.","code":"\nggplot(data, aes(x = gender, fill = choice)) + \n  geom_bar() + \n  labs(y=\"Proportion\", title = \"Choice by gender\") + \n  scale_fill_manual(values=c(\"#4169E1\", \"#FFC72C\")) +\n  facet_wrap(~choice)"},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","text":"","code":""},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"introduction-2","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.1 Introduction","text":"tutorial, introduce dplyr package, crucial tool R data manipulation. learn various dplyr functions group_by, summarise, filter.","code":""},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"dplyr-essentials","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2 dplyr Essentials","text":"","code":""},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"introduction-to-dplyr","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.1 Introduction to dplyr","text":"dplyr package data manipulation, offering set useful functions perform operations like filtering, summarizing, grouping data. use dplyr, ’ll first need install load package.","code":"\n# install.packages(\"dplyr\")   # uncomment to install\nlibrary(dplyr)"},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"using-group_by-function","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.2 Using group_by() Function","text":"group_by() function used group data based one multiple columns.","code":"\n# Using inbuilt dataset 'mtcars'\ndata(mtcars)\nhead(mtcars)                   mpg cyl disp  hp drat    wt  qsec vs am\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0\n                  gear carb\nMazda RX4            4    4\nMazda RX4 Wag        4    4\nDatsun 710           4    1\nHornet 4 Drive       3    1\nHornet Sportabout    3    2\nValiant              3    1\n# Grouping by number of gears\ngrouped_data <- mtcars %>% group_by(gear)"},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"summarization-using-summarise","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.3 Summarization using summarise()","text":"grouping, summarise() can help create summary statistics group.","code":"\n# Continuing with the 'mtcars' dataset\nsummary_stats <- grouped_data %>%\n  summarise(\n    Mean_MPG = mean(mpg),\n    Max_MPG = max(mpg),\n    Min_MPG = min(mpg)\n  )\n\nsummary_stats# A tibble: 3 × 4\n   gear Mean_MPG Max_MPG Min_MPG\n  <dbl>    <dbl>   <dbl>   <dbl>\n1     3     16.1    21.5    10.4\n2     4     24.5    33.9    17.8\n3     5     21.4    30.4    15  "},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"data-filtering-using-filter","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.4 Data Filtering using filter()","text":"filter() function filters rows based certain condition.","code":"\n# Filter cars with 4 gears\nfiltered_data <- mtcars %>% filter(gear == 4)"},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"identifying-outliers-with-filter","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.5 Identifying Outliers with filter()","text":"can use filter() identify outliers based calculated fences boundaries.","code":"\n# For demonstration, calculate lower and upper fence for mpg\nQ1 <- quantile(mtcars$mpg, 0.25)\nQ3 <- quantile(mtcars$mpg, 0.75)\nIQR <- Q3 - Q1\nlower_fence <- Q1 - 1.5 * IQR\nupper_fence <- Q3 + 1.5 * IQR\n\noutliers <- filter(mtcars, mpg < lower_fence | mpg > upper_fence)\noutliers                mpg cyl disp hp drat    wt qsec vs am gear\nToyota Corolla 33.9   4 71.1 65 4.22 1.835 19.9  1  1    4\n               carb\nToyota Corolla    1"},{"path":"tutorial-3-dive-deeper-into-data-manipulation-with-dplyr-in-r.html","id":"combining-all-together-1","chapter":"7 Tutorial 3: Dive Deeper into Data Manipulation with dplyr in R","heading":"7.2.6 Combining All Together","text":"mastering dplyr functions, can significantly streamline data manipulation tasks R. grouping summarizing data filtering specific information, dplyr offers powerful toolkit data manipulation.tutorial covers group_by, summarise, filter functions dplyr package demonstrates use built-dataset mtcars.","code":"\n# Combining group_by and summarise\nmtcars %>% \n  group_by(gear) %>% \n  summarise(Mean_MPG = mean(mpg), N = n())# A tibble: 3 × 3\n   gear Mean_MPG     N\n  <dbl>    <dbl> <int>\n1     3     16.1    15\n2     4     24.5    12\n3     5     21.4     5"},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"tutorial-4-latex-equations-in-rmarkdown","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8 Tutorial 4: LaTeX Equations in RMarkdown","text":"","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"welcome-to-latex-mastery","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.1 Welcome to LaTeX Mastery!","text":"Hey , aspiring LaTeX pros! Ready make equations look sleek Tesla? Let’s get started!","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"inline-equations","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.2 Inline Equations","text":"quick math snippets, use single $ like $y = + b * x$.Example: equation \\(y = + b * x\\) represents linear model.","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"display-style-equations","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.3 Display-Style Equations","text":"give equation spotlight, encase double $$:","code":"$$\nE = mc^2\n$$"},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"mathematical-symbols","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.4 Mathematical Symbols","text":"","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"summation-and-indices","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.4.1 Summation and Indices","text":"stats, often sum things :\n- $$ \\sum_{=1}^{n} x_i $$","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"fractions","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.4.2 Fractions","text":"Simple fraction: $$ \\frac{}{b} $$","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"greek-letters-and-subscripts","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.4.3 Greek Letters and Subscripts","text":"Common hypothesis testing statistical theory:Mean group: $$ \\mu_Y $$, $$ \\mu_N $$Sample means: $$ \\bar{x}_N $$, $$ \\bar{x}_Y $$Proportions: $$ \\hat{p} $$","code":""},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"matrices-and-vectors","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.5 Matrices and Vectors","text":"Matrices breeze LaTeX:","code":"\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}"},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"hypothesis-testing","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.6 Hypothesis Testing","text":"hypothesis testing, might define null alternative hypotheses:","code":"\\begin{align*}\n\\begin{array}{ll}\nH_0: & \\mu_N=\\mu_Y \\\\\nH_a: & \\mu_N>\\mu_Y\n\\end{array}\n\\end{align*}"},{"path":"tutorial-4-latex-equations-in-rmarkdown.html","id":"more-on-statistical-symbols","chapter":"8 Tutorial 4: LaTeX Equations in RMarkdown","heading":"8.7 More on Statistical Symbols","text":"Standard error: $$ SE $$Population proportion: $$ p $$Margin error: $$ \\pm $$Confidence level: $$ 95\\% $$’s now! Ready LaTeX like pro?[link template: Download Template ]","code":""},{"path":"short-report-1.html","id":"short-report-1","chapter":"9 Short Report 1","heading":"9 Short Report 1","text":"Short Report 1 Deadline: 5 pm Friday, 02/02/2024.Proposal Deadline: 11:59 pm Sunday, 01/28/2024.","code":""},{"path":"short-report-1.html","id":"introduction-3","chapter":"9 Short Report 1","heading":"9.1 Introduction","text":"lab report individual assignment. discussions data R code classmates allowed, forming questions answering data done independently. Please follow Report Guidelines available course helper webpage starting report.","code":""},{"path":"short-report-1.html","id":"data-retrieval","chapter":"9 Short Report 1","heading":"9.2 Data Retrieval","text":"Use dataset women.csv analysis. can load data R session using following code:","code":"\nwomen <- read.csv(\"https://raw.githubusercontent.com/deepbas/stat120datasets/main/women.csv\", \n                  sep = \",\", header = FALSE, skip = 1)\n\ncolnames(women) <- c(\"No\", \"Country\", \"Level.of.development\", \"European.Union.Membership\", \n                     \"Currency\", \"Women.Entrepreneurship.Index\", \"Entrepreneurship.Index\", \n                     \"Inflation.rate\", \"Female.Labor.Force.Participation.Rate\",\n                     \"Overall.Entrepreneurship\")"},{"path":"short-report-1.html","id":"data-description","chapter":"9 Short Report 1","heading":"9.3 Data Description","text":"dataset named women titled Women Entrepreneurship Labor Force, stored women serves rich compendium, capturing pivotal insights landscape female participation entrepreneurship across various countries, especially within OECD. Sourced Women Entrepreneurship Index Global Entrepreneurship Index report 2015, comprehensive dataset offers categorical quantitative variables.","code":""},{"path":"short-report-1.html","id":"categorical-variables","chapter":"9 Short Report 1","heading":"9.3.1 Categorical Variables:","text":"Country: Denotes specific nation data point belongs.Level Development: variable categorizes countries based stage economic growth - whether ‘Developed’ ‘Developing’.European Union Membership: indicates whether country member European Union .Currency: Specifies official currency used within respective country.Overall Entrepreneurship: derived binary categorical variable indicating relative level entrepreneurship country. Countries Entrepreneurship Index 42.7 labeled ‘High’, signifying higher level entrepreneurship activity, whereas threshold labeled ‘Low’.","code":""},{"path":"short-report-1.html","id":"quantitative-variables","chapter":"9 Short Report 1","heading":"9.3.2 Quantitative Variables:","text":"Women Entrepreneurship Index: numerical value year 2015 mirrors overall environment facilitates impedes women launching businesses country.Entrepreneurship Index: numerical metric year 2015, reflecting overall entrepreneurship ecosystem country.Inflation Rate: provides inflation rate year 2015.Female Labor Force Participation Rate: metric 2015 showcases percentage female working-age population actively participating workforce.dataset spans myriad countries, established economies like Austria, Belgium, France, Germany emerging economies Argentina, China, India, Mexico. nation’s entry dataset sheds light respective entrepreneurial conditions, inflationary pressures, level active participation women labor force.essence, dataset provides robust foundation -depth analyses, especially keen discerning patterns, trends, disparities across economic, gender, social dimensions, leveraging information draw meaningful conclusions.","code":""},{"path":"short-report-1.html","id":"required-analyses","chapter":"9 Short Report 1","heading":"9.4 Required Analyses:","text":"Address following areas statistical analysis report, ensuring correctness analysis clarity written communication:Categorical Variable Relationship:\nInvestigate relationship two categorical variables. analysis include two-way table stacked bar graph. Comment observed relationships describe nature.Categorical Variable Relationship:Investigate relationship two categorical variables. analysis include two-way table stacked bar graph. Comment observed relationships describe nature.Categorical-Quantitative Variable Relationship:\nExamine relationship one categorical variables quantitative variable. Ensure provide summary statistics graphical comparisons quantitative variable across level chosen categorical variable/s.Categorical-Quantitative Variable Relationship:Examine relationship one categorical variables quantitative variable. Ensure provide summary statistics graphical comparisons quantitative variable across level chosen categorical variable/s.Quantitative Variable Relationship:\nExplore relationship two quantitative variables. analysis include summary statistics graphical comparisons quantitative variable level categorical variables.Quantitative Variable Relationship:Explore relationship two quantitative variables. analysis include summary statistics graphical comparisons quantitative variable level categorical variables.Randomized Hypothesis Test:\nConduct randomized hypothesis test assess difference mean quantitative variable across two categorical levels. Ensure include relevant R code summary outputs appendix.Randomized Hypothesis Test:Conduct randomized hypothesis test assess difference mean quantitative variable across two categorical levels. Ensure include relevant R code summary outputs appendix.","code":""},{"path":"short-report-1.html","id":"submission-details","chapter":"9 Short Report 1","heading":"9.5 Submission Details","text":"Submit report single PDF file Gradescope. Ensure R-code included appendix main body report. including plots numerical summaries main content acceptable, R code generates hidden.","code":""},{"path":"short-report-1.html","id":"to-hide-the-r-code-in-your-report","chapter":"9 Short Report 1","heading":"9.5.1 To hide the R code in your report:","text":"Use chunk option echo = FALSE prevent code displaying still execute . ideal hiding code showing output (e.g., plots summaries).Use chunk option echo = FALSE prevent code displaying still execute . ideal hiding code showing output (e.g., plots summaries).Alternatively, can use include = FALSE hide code prevent output shown document. useful want execute preparatory code without showing results report.Alternatively, can use include = FALSE hide code prevent output shown document. useful want execute preparatory code without showing results report.RStudio’s R Markdown, insert new R chunk Ctrl + Alt + Cmd + Option + . Choose appropriate chunk option based specific needs section report. example, hide code execute , use chunk header {r echo=FALSE}.","code":""},{"path":"short-report-1.html","id":"report-structure","chapter":"9 Short Report 1","heading":"9.6 Report Structure","text":"statistics, experts often share work articles magazines (called journals) books. main type article called ‘primary paper’. ’s like story researcher , , found . Since working data (‘data analysis’) big part statistics, ’s important students, even beginner classes, learn write style.","code":""},{"path":"short-report-1.html","id":"abstract","chapter":"9 Short Report 1","heading":"9.6.1 Abstract","text":"short section (5% paper’s length) quickly summarize work. cover reason analysis, main question ’re addressing, statistical methods used, findings, believe findings mean. Essentially, reading just abstract, someone grasp essence entire paper.","code":""},{"path":"short-report-1.html","id":"introduction-4","chapter":"9 Short Report 1","heading":"9.6.2 Introduction","text":"Start setting scene analysis: provide background mention previous related studies, available. Clearly state main focus objective data analysis. Explain focus important interesting. Briefly outline methods approaches took, highlighting conducted experimental observational study.","code":""},{"path":"short-report-1.html","id":"methods","chapter":"9 Short Report 1","heading":"9.6.3 Methods","text":"Detail techniques used gather analyze data. description clear enough someone else replicate analysis. Specify data collected, statistical tests performed, relevant setups. can reference manual -depth statistical test details, avoid including complex mathematical formulas. Write past tense, describing entire analysis approach though conducted independently. aim provide concise overview analysis method, step--step breakdown.","code":""},{"path":"short-report-1.html","id":"results","chapter":"9 Short Report 1","heading":"9.6.4 Results","text":"section present main findings data analysis. Describe key patterns, trends, notable differences observed. visuals like charts graphs illustrate results, ’s essential explain verbally . State primary data trends support statistical outcomes brackets. Direct reader relevant figures tables. Remember, section presenting findings ; interpretations broader implications reserved following Discussion section.","code":""},{"path":"short-report-1.html","id":"discussion-and-conclusion","chapter":"9 Short Report 1","heading":"9.6.5 Discussion and Conclusion","text":"Start recapping main findings linking initial questions hypotheses. Examine results context existing knowledge research. Delve broader implications, consider results fit larger landscape. Address potential issues analysis like violation assumptions, outliers, bias, errors impact validity conclusions. Reflect ethical constraints tied study potential influence.","code":""},{"path":"short-report-1.html","id":"grading-rubric","chapter":"9 Short Report 1","heading":"9.7 Grading Rubric","text":"","code":""},{"path":"short-report-2.html","id":"short-report-2","chapter":"10 Short Report 2","heading":"10 Short Report 2","text":"Short Report 1 Deadline: 10 pm Friday, 03/01/2024.Proposal Deadline: 11:59 pm Sunday, 02/25/2024.","code":""},{"path":"short-report-2.html","id":"heres-the-link-to-the-proposal-google-form-httpsforms.glehgjmgdmjya6qwzhw9","chapter":"10 Short Report 2","heading":"10.0.0.1 Here’s the link to the proposal google form, https://forms.gle/HGjMgDmjya6QwZhw9","text":"","code":""},{"path":"short-report-2.html","id":"introduction-5","chapter":"10 Short Report 2","heading":"10.1 Introduction","text":"lab report individual assignment. discussions data R code classmates allowed, forming questions answering data done independently. Please follow Report Guidelines available course helper webpage starting report.","code":""},{"path":"short-report-2.html","id":"data-retrieval-1","chapter":"10 Short Report 2","heading":"10.2 Data Retrieval","text":"","code":"\nlibrary(palmerpenguins)\nlibrary(ggplot2)\nlibrary(dplyr)\npenguins <- penguins %>%  tidyr::drop_na() # drop any missing values"},{"path":"short-report-2.html","id":"data-description-1","chapter":"10 Short Report 2","heading":"10.3 Data Description","text":"Ready dive fascinating world Antarctic penguins? dataset, drawn palmerpenguins package, offers detailed look 333 penguins across 8 variables, capturing diversity creatures across different islands. data encompasses various measurements like bill length, flipper length, body mass, along categorical data species, sex, year observation. rich dataset serves excellent foundation exploratory data analysis hypothesis testing. Let’s embark analytical journey uncover hidden stories penguins.","code":""},{"path":"short-report-2.html","id":"required-analyses-1","chapter":"10 Short Report 2","heading":"10.4 Required Analyses:","text":"Formulate three research questions pave way hypothesis testing using statistical tests ANOVA, z-tests, t-tests, Chi-square tests, linear regression parameter significance tests. Accompany tests confidence interval quantify key parameters, providing insights population based findings. Whether differences statistically significant , analysis illuminate various aspects penguin population. example, find two groups statistically significant difference CI quantify different population. don’t find statistically significant difference, get CI overall population parameter (separated groups didn’t find difference).","code":""},{"path":"short-report-2.html","id":"expectations","chapter":"10 Short Report 2","heading":"10.4.1 Expectations","text":"Remember, EDA (Exploratory Data Analysis) crucial finding p-value. Incorporate basic descriptive statistics graphs support analyses.Remember, EDA (Exploratory Data Analysis) crucial finding p-value. Incorporate basic descriptive statistics graphs support analyses.Highlight statistically significant findings detailed EDA, using specific statistics /confidence intervals articulate relationships variables.Highlight statistically significant findings detailed EDA, using specific statistics /confidence intervals articulate relationships variables.Examine assumptions necessary chosen inference methods.Examine assumptions necessary chosen inference methods.vigilant outliers quantitative data EDA. Decide whether include exclude based influence analysis.vigilant outliers quantitative data EDA. Decide whether include exclude based influence analysis.introduction, go beyond merely stating source data. Delve background information provided dataset enrich report’s context.introduction, go beyond merely stating source data. Delve background information provided dataset enrich report’s context.","code":""},{"path":"short-report-2.html","id":"submission-details-1","chapter":"10 Short Report 2","heading":"10.5 Submission Details","text":"Submit report single PDF file Gradescope. Ensure R-code included appendix main body report. including plots numerical summaries main content acceptable, R code generates hidden.","code":""},{"path":"short-report-2.html","id":"to-hide-the-r-code-in-your-report-1","chapter":"10 Short Report 2","heading":"10.5.1 To hide the R code in your report:","text":"Use chunk option echo = FALSE prevent code displaying still execute . ideal hiding code showing output (e.g., plots summaries).Use chunk option echo = FALSE prevent code displaying still execute . ideal hiding code showing output (e.g., plots summaries).Alternatively, can use include = FALSE hide code prevent output shown document. useful want execute preparatory code without showing results report.Alternatively, can use include = FALSE hide code prevent output shown document. useful want execute preparatory code without showing results report.RStudio’s R Markdown, insert new R chunk Ctrl + Alt + Cmd + Option + . Choose appropriate chunk option based specific needs section report. example, hide code execute , use chunk header {r echo=FALSE}.","code":""},{"path":"short-report-2.html","id":"report-structure-1","chapter":"10 Short Report 2","heading":"10.6 Report Structure","text":"statistics, experts often share work articles magazines (called journals) books. main type article called ‘primary paper’. ’s like story researcher , , found . Since working data (‘data analysis’) big part statistics, ’s important students, even beginner classes, learn write style.","code":""},{"path":"short-report-2.html","id":"abstract-1","chapter":"10 Short Report 2","heading":"10.6.1 Abstract","text":"short section (5% paper’s length) quickly summarize work. cover reason analysis, main question ’re addressing, statistical methods used, findings, believe findings mean. Essentially, reading just abstract, someone grasp essence entire paper.","code":""},{"path":"short-report-2.html","id":"introduction-6","chapter":"10 Short Report 2","heading":"10.6.2 Introduction","text":"Start setting scene analysis: provide background mention previous related studies, available. Clearly state main focus objective data analysis. Explain focus important interesting. Briefly outline methods approaches took, highlighting conducted experimental observational study.","code":""},{"path":"short-report-2.html","id":"methods-1","chapter":"10 Short Report 2","heading":"10.6.3 Methods","text":"Detail techniques used gather analyze data. description clear enough someone else replicate analysis. Specify data collected, statistical tests performed, relevant setups. can reference manual -depth statistical test details, avoid including complex mathematical formulas. Write past tense, describing entire analysis approach though conducted independently. aim provide concise overview analysis method, step--step breakdown.","code":""},{"path":"short-report-2.html","id":"results-1","chapter":"10 Short Report 2","heading":"10.6.4 Results","text":"section present main findings data analysis. Describe key patterns, trends, notable differences observed. visuals like charts graphs illustrate results, ’s essential explain verbally . State primary data trends support statistical outcomes brackets. Direct reader relevant figures tables. Remember, section presenting findings ; interpretations broader implications reserved following Discussion section.","code":""},{"path":"short-report-2.html","id":"discussion-and-conclusion-1","chapter":"10 Short Report 2","heading":"10.6.5 Discussion and Conclusion","text":"Start recapping main findings linking initial questions hypotheses. Examine results context existing knowledge research. Delve broader implications, consider results fit larger landscape. Address potential issues analysis like violation assumptions, outliers, bias, errors impact validity conclusions. Reflect ethical constraints tied study potential influence.","code":""},{"path":"short-report-2.html","id":"grading-rubric-1","chapter":"10 Short Report 2","heading":"10.7 Grading Rubric","text":"","code":""},{"path":"practice-problems-1.html","id":"practice-problems-1","chapter":"11 Practice Problems 1","heading":"11 Practice Problems 1","text":"","code":""},{"path":"practice-problems-1.html","id":"problem-1","chapter":"11 Practice Problems 1","heading":"11.1 Problem 1","text":"Run following chunk. Comment output.dimension dataset called ‘example_data’?","code":"\nexample_data = data.frame(ID = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n                          Greeting = c(rep(\"Hello\", 5), rep(\"Goodbye\",5)),\n                          Male = rep(c(TRUE, FALSE), 5),\n                          Weight = runif(n=10, 50, 300))\nexample_data   ID Greeting  Male    Weight\n1   1    Hello  TRUE 252.72369\n2   2    Hello FALSE 113.18590\n3   3    Hello  TRUE  99.35283\n4   4    Hello FALSE 108.05614\n5   5    Hello  TRUE 173.28966\n6   6  Goodbye FALSE 152.34627\n7   7  Goodbye  TRUE 260.88657\n8   8  Goodbye FALSE 123.09743\n9   9  Goodbye  TRUE 259.61073\n10 10  Goodbye FALSE 122.17259dim(example_data)\n[1] 10  4\nnrow(example_data)\n[1] 10\nncol(example_data)\n[1] 4"},{"path":"practice-problems-1.html","id":"problem-2","chapter":"11 Practice Problems 1","heading":"11.2 Problem 2","text":"Read dataset EducationLiteracy Lock5 second edition book.Print header (.e. first 6 cases default) dataset part .dimension dataset ?Answer: 188 rows 3 columns.type variables Country, EducationExpenditure, Literacy?like use education expenditure predict literacy rate countries, variable explanatory variable one response?","code":"\n# read in the data\nlibrary(readr)\neducation_lock5 <- read_csv(\"https://www.lock5stat.com/datasets2e/EducationLiteracy.csv\")\nhead(education_lock5)# A tibble: 6 × 3\n  Country             EducationExpenditure Literacy\n  <chr>                              <dbl>    <dbl>\n1 Afghanistan                          3.1     31.7\n2 Albania                              3.2     96.8\n3 Algeria                              4.3     NA  \n4 Andorra                              3.2     NA  \n5 Angola                               3.5     70.6\n6 Antigua and Barbuda                  2.6     99  \ndim(education_lock5)[1] 188   3"},{"path":"practice-problems-2.html","id":"practice-problems-2","chapter":"12 Practice Problems 2","heading":"12 Practice Problems 2","text":"","code":""},{"path":"practice-problems-2.html","id":"problem-1-1","chapter":"12 Practice Problems 2","heading":"12.1 Problem 1","text":"","code":""},{"path":"practice-problems-2.html","id":"gettysburg-random-sample","chapter":"12 Practice Problems 2","heading":"12.1.1 Gettysburg random sample","text":"Let’s take simple random sample (SRS) Gettysburg words. “population” contained \nspreadsheet GettysburgPopulationCounts.csv. Carefully load data R:position variable enumerates list words population (address).(). SampleRun following command obtain SRS 10 words 268 population:tells position (row number) sampled words. sampled positions? sampled positions different folks class?(b). Get words lengthsWe subset data set pop obtain sampled rows listed samp. using square bracket notation `dataset[row number, column number/name]. Run following command find sampled words sizes:Compute sample meanThe word lengths part (b) data sample. can compute sample mean using calculator, using R. Let’s try R (find faster!). First save quantitative variable size new variable called mysize:find mean values:sample mean (truly random sample) compare sample mean non-random sample?Answer: true mean 4.29. two means likely vary. Since many non-random samples generally overestimated population mean length, possible (guaranteed) one non-random sample gave mean length greater random sample’s mean length.","code":"\npop <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/GettysbergPopulationCounts.csv\")\nhead(pop)  position size  word\n1        1    4  Four\n2        2    5 score\n3        3    3   and\n4        4    5 seven\n5        5    5 years\n6        6    3  ago,\nsamp <- sample(1:268, size=10)\nsamp [1]  13 121  42  87 204 122  59   9 206 267\npop[samp,]    position size      word\n13        13    9 continent\n121      121    3      men,\n42        42    4      that\n87        87    4      that\n204      204    4      from\n122      122    6    living\n59        59    1         a\n9          9    7   brought\n206      206    7   honored\n267      267    3       the\nmysize <- pop[samp, \"size\"]\nmysize [1] 9 3 4 4 4 6 1 7 7 3\nmean(mysize)[1] 4.8"},{"path":"practice-problems-3.html","id":"practice-problems-3","chapter":"13 Practice Problems 3","heading":"13 Practice Problems 3","text":"","code":""},{"path":"practice-problems-3.html","id":"case-study-1","chapter":"13 Practice Problems 3","heading":"13.1 Case Study 1","text":"Consider following case study:\n“Researchers want find new diet affects weight gain among underweight subjects. experiment two treatment conditions, new diet standard diet. study, researchers recruited 200 subjects grouped 100 pairs based shared characteristics age, gender, weight, height, lifestyle, . 20-year-old female within weight range 90-110 pounds height range 60-63 inches paired another 20-year-old female falls weight height categories. 100 pairs made, subject pair randomly assigned treatment group (administered new diet 2 months) subject pair assigned control group (assigned follow standard diet two months). end time time period 2 months, researchers measure total weight gain subject.”Observed data:\nresearchers found 60 100 subjects new diet group showed substantial improvement, compared 43 100 subjects standard diet group.\n(b). Classify variable categorical quantitative.(c). variable regard explanatory response?(d). observational study experiment? Justify answer.(e). experiment, randomized comparative experiment matched pairs experiment?(f). Construct two-way table based results experiment.Two-way table:","code":""},{"path":"practice-problems-3.html","id":"case-study-2","chapter":"13 Practice Problems 3","heading":"13.2 Case Study 2","text":"Consider following case study:\n“psychology class, researchers want know method study yields higher exam scores. class 50 students agree participate. student first study Exam 1 using traditional textbook reading take exam. Afterward, students study Exam 2 using interactive online modules take exam. order study techniques kept eliminate impact subject matter difficulty. Exam scores outcome interest.”(b). Classify variable categorical quantitative.(c). variable regard explanatory response?(d). observational study experiment? Justify answer.Answer: experiment researchers imposing treatments (study techniques) subjects observe effects exam scores.(e). experiment, randomized comparative experiment matched pairs experiment?(g). Construct hypothetical two-way table based experiment.","code":""},{"path":"practice-problems-3.html","id":"case-study-3","chapter":"13 Practice Problems 3","heading":"13.3 Case Study 3","text":"\n“Researchers aim investigate effect new high-intensity interval training (HIIT) program new nutritional supplement muscle growth fat loss. subjects experiment include males females varying ages 18-35, recreational gym-goers. Researchers pair 240 subjects 120 pairs based similar characteristics age, gender, body mass index, baseline fitness levels. pair, one subject assigned follow new HIIT program along nutritional supplement period 3 months. subject follow standard workout routine without nutritional supplement. metrics interest muscle mass gained body fat percentage lost.”\n","code":""},{"path":"practice-problems-3.html","id":"observed-data","chapter":"13 Practice Problems 3","heading":"13.3.1 Observed data:","text":"completion 3 months, researchers found 82 120 subjects HIIT program showed statistically significant improvements muscle mass fat loss, compared 54 120 subjects standard workout group.(). Identify experimental units study.Answer:experimental units study individual subjects participating experiment.(b). Classify variable categorical quantitative.Answer:Age: QuantitativeGender: CategoricalBody Mass Index: QuantitativeBaseline Fitness Level: QuantitativeType workout program (HIIT standard): CategoricalNutritional supplement (Yes ): CategoricalMuscle mass gained: QuantitativeBody fat percentage lost: Quantitative(c). variables regard explanatory response?Answer:Explanatory variables: Type workout program (HIIT standard), Nutritional supplement (Yes )Response variables: Muscle mass gained, Body fat percentage lost(d). observational study experiment? Justify answer.Answer:experiment. Researchers actively manipulating conditions (workout program nutritional supplement) subjects exposed measuring outcome (muscle mass gained body fat percentage lost).(e). experiment, randomized comparative experiment matched pairs experiment?Answer:matched pairs experiment. Subjects paired based similar characteristics, within pair, one subject assigned treatment group control group.(f). Construct two-way table based results experiment.Answer:","code":""},{"path":"practice-problems-3.html","id":"case-study-4","chapter":"13 Practice Problems 3","heading":"13.4 Case Study 4","text":"Consider following case study:\n“Swimming dolphins can certainly fun, also therapeutic patients suffering clinical depression? investigate possibility, researchers recruited 30 subjects aged 18-65 clinical diagnosis mild moderate depression. Subjects required discontinue use antidepressant drugs psychotherapy four weeks prior experiment, throughout experiment. 30 subjects went island coast Honduras, randomly assigned one two treatment groups. groups engaged amount swimming snorkeling day, one group (animal care program) presence bottlenose dolphins group (outdoor nature program) . end two weeks, subjects’ level depression evaluated, beginning study, determined whether showed substantial improvement (reducing level depression) end study (Antonioli Reveley, 2005).”\n","code":""},{"path":"practice-problems-3.html","id":"observed-data-1","chapter":"13 Practice Problems 3","heading":"13.4.1 Observed data","text":"researchers found 10 15 subjects dolphin therapy group showed substantial improvement, compared 3 15 subjects control group.(). Identify experimental units study.Answer: experimental units study 30 subjects.(b). Classify variable categorical quantitative.Answer: variables study can classified follows:\nCategorical: Treatment Group (Dolphin Control)\nQuantitative: Age, Level Depression (Beginning End Study)(c). variable regard explanatory response?Answer: explanatory variable Treatment Group response variable Level Depression.(d). observational study experiment? Justify answer.Answer: experiment researchers randomly assigned subjects two treatment groups, observed effect treatment (presence dolphins) response variable (level depression).(e). Construct two-way table based results experiment.Answer:Two-way table:","code":""},{"path":"practice-problems-4.html","id":"practice-problems-4","chapter":"14 Practice Problems 4","heading":"14 Practice Problems 4","text":"","code":""},{"path":"practice-problems-4.html","id":"problem-1-flowers-v.-mississippi","chapter":"14 Practice Problems 4","heading":"14.1 Problem 1: Flowers v. Mississippi","text":"data set APM_DougEvensCases.csv contains data 1517 potential black white jurors 66 cases Doug Evans primary prosecutor 1992 2017. jurors available Doug Evans strike using “peremptory strikes” jury selection phase.(). Inspect dataRead dataLook first three rows data setTo get data one variable, use command dataset$variable. example, jurors$struck_state gives us data values struck_state variable, tells us juror struck state jury pool. can see first 10 entries variable:(b). Table counts proportionsThe summary command used data frame gives summaries variableThe table command gives distribution counts single categorical variable. obtain count table struck_state need toWe can add prop.table command turn counts proportions:proportion eligible jurors struck state jury pool?(c). Bar graph one variableWe can create data frame count_data containing counts corresponding categories., use ggplot2 create bar plot categories x-axis counts y-axis. column names count_data automatically assigned Var1 Freq. can change column names category count, example, :geom_bar(stat = \"identity\") function used create bars, set y-axis label using labs().may simply use geom_bar count data available.(d). Two-way tablesFirst 10 entries race struck_state variable isThe table command also gives two-way tables two variables included. two-way table juror race state struck status:many jurors white struck state?(e). Conditional proportions: state strike status juror raceThe prop.table command gives conditional proportions two-way table. plug two-way table prop.table margin=1 get proportions grouped row variable:eligible black jurors, 57.9% struck state.proportion eligible white jurors struck state?evidence association juror race state strikes?(f). Stacked bar graph two variablesWe can visualize conditional distribution part (e) stacked bar graph created using ggplot2 graphing package. First, load package’s functions library command:Now can use geom_bar command package. get conditional distribution struck_state given race:basic syntax function let ggplot know data set name (jurors), specify grouping conditional variable x-axis (race) aes (aesthetic) argument. fill variable response variable (struck_state). add (+) geom_bar geometry get bar graph fill position specified. Adding informative label title complete graph.\n(g). Conditional distribution race grouped strike statusWe can “flip” response grouping variables easily (think makes sense ). specify margin=2 get proportions grouped column variable:Notice proportions add one column. eligible jurors struck state, 71.6% black.stacked bar graph distribution isWhat proportion eligible jurors struck state black? white?","code":"\njurors <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/APM_DougEvansCases.csv\")\n# dimension of dataset\ndim(jurors)[1] 1517    6\njurors[c(1,2,3), ]  trial__id  race        struck_state defendant_race\n1         4 Black Not struck by State          White\n2         4 Black     Struck by State          White\n3         4 White Not struck by State          White\n       same_race                     struck_by\n1 different race Juror chosen to serve on jury\n2 different race           Struck by the state\n3      same race Juror chosen to serve on jury\njurors$struck_state[1:10] [1] \"Not struck by State\" \"Struck by State\"    \n [3] \"Not struck by State\" \"Not struck by State\"\n [5] \"Struck by State\"     \"Not struck by State\"\n [7] \"Struck by State\"     \"Not struck by State\"\n [9] \"Not struck by State\" \"Not struck by State\"\nsummary(jurors)   trial__id         race           struck_state      \n Min.   :  4.0   Length:1517        Length:1517       \n 1st Qu.: 52.0   Class :character   Class :character  \n Median : 82.0   Mode  :character   Mode  :character  \n Mean   :112.6                                        \n 3rd Qu.:170.0                                        \n Max.   :301.0                                        \n defendant_race      same_race          struck_by        \n Length:1517        Length:1517        Length:1517       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \ncounts <- table(jurors$struck_state)\ncounts\nNot struck by State     Struck by State \n               1084                 433 \nprop.table(counts)\nNot struck by State     Struck by State \n          0.7145682           0.2854318 \ncount_data <- data.frame(counts)\ncount_data                 Var1 Freq\n1 Not struck by State 1084\n2     Struck by State  433\ncolnames(count_data) = c(\"category\", \"count\")\ncount_data             category count\n1 Not struck by State  1084\n2     Struck by State   433\n# Create a bar plot using ggplot2\nlibrary(ggplot2)  # load the package\nggplot(count_data, aes(x = category, y = count)) +\n  geom_bar(stat = \"identity\") +\n  labs(y = \"count\")\nggplot(jurors, aes(x = struck_state)) + geom_bar() + ylab(\"Count\")\njurors[(1:10),(2:3)]    race        struck_state\n1  Black Not struck by State\n2  Black     Struck by State\n3  White Not struck by State\n4  White Not struck by State\n5  Black     Struck by State\n6  White Not struck by State\n7  Black     Struck by State\n8  White Not struck by State\n9  White Not struck by State\n10 White Not struck by State\nmytable <- table(jurors$race, jurors$struck_state)\nmytable       \n        Not struck by State Struck by State\n  Black                 225             310\n  White                 859             123\nprop.table(mytable, margin = 1)       \n        Not struck by State Struck by State\n  Black           0.4205607       0.5794393\n  White           0.8747454       0.1252546\nlibrary(ggplot2)\nggplot(jurors, aes(x = race, fill = struck_state)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"State strikes by juror race\", y = \"proportion\", \n       x = \"eligible juror race\", fill = \"struck by state?\")\nprop.table(mytable, margin = 2)       \n        Not struck by State Struck by State\n  Black           0.2075646       0.7159353\n  White           0.7924354       0.2840647\nggplot(jurors, aes(x = struck_state, fill = race)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"Juror race by state strikes\", y = \"proportion\", \n       fill = \"eligible juror race\", x = \"struck by state?\")"},{"path":"practice-problems-4.html","id":"problem-2-graduate-programs-acceptance-and-sex","chapter":"14 Practice Problems 4","heading":"14.2 Problem 2: Graduate programs acceptance and sex","text":"grad school program acceptance rates associated sex? look classic data set Berkeley grad school applications 1973 (Science, 1975). data cases applicants four graduate programs Berkeley 1973. variable result tells us applicant accepted graduate program, sex tells us sex applicant (male female), program tells us program type (programs 1,2,3 4).(). Table counts proportionsWhat proportion applicants accepted?(b). Two-way tablesThe table command also gives two-way tables two variables included. two-way table result sex:many applicants involved females accepted?(c). Conditional proportions: acceptance given sexThe prop.table command gives conditional proportions two-way table. First let’s save two-way table object named mytable:use prop.table get distribution result conditioned (grouped) applicant’s sex:value 1 command tell’s R want row proportions (denominator proportion row total).proportion female accepted?proportion males accepted?(d). Bar graph one variableWe can create data frame count_data1 containing counts corresponding categories., use ggplot2 create bar plot categories x-axis counts y-axis. column names count_data automatically assigned Var1 Freq. can change column names category count, example, :geom_bar(stat = \"identity\") function used create bars, set y-axis label using labs().(e). Stacked bar graph two variablesNow can use geom_bar command package. get conditional distribution result given sex:basic syntax function let ggplot know data set name (grad), specify grouping conditional variable x-axis (sex) aes (aesthetic) argument. fill variable response variable (result). add (+) geom_bar geometry get bar graph fill position specified. Adding informative label title complete graph.(f). Subsetting program typeFinally, repeat previous analysis result sex, time divide (subset) data set program type. need know values program coded:use filter command available dplyr package get applicants program 1:Repeat filter command get data set program 2 call new data set grad.p2. Verify number rows dataset matches number program 2 applicants original data set.(g). Result sex program 1.distribution result conditioned applicant’s sex program 1 data set shown .Get table conditional proportions (percentages) stacked bar graph.(h). Result sex program 2.Repeat part (g) time use program 2 data set. Compare two bar graphs (g) (h) explain show females higher acceptance rate accounting program type (1 2).Answer: programs 1 2, see female applicants slightly higher rate acceptance\nmale applicants. accounting program type, now see female applicants higher acceptance rate male applicants. Without accounting program type, opposite true\n(see parts (c) (e)).? confounding affect program type associated result sex:females prefer apply programs 3 4 males prefer programs 1 2 (3 \n4).\n44% females applied program 3 40% program 4\n38% males applied program 1 26% program 2\n44% females applied program 3 40% program 438% males applied program 1 26% program 2-Programs 3 4 much harder get programs 1 2\n- 64% applicants program 1 accepted 63% applicants program 2 accepted\n- 6% applicants program 4 accepted 34% applicants program 3 acceptedSo since majority females applied toughest programs (measured acceptance rates),\noverall rate acceptance lower females compared males. break \nrates program type, see females higher acceptance rates males (see \nvisual part ()).(). bar graph three variablesIf simply want graph relationship result sex type program, can avoid subsetting data using facet_wrap command ggplot2. one simple addition stacked bar graph part (e):Verify command creates side--side stacked bar graphs match graphs parts (g) (h) programs 1 2.Answer: graphs match.","code":"\ngrad <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/BerkeleyGrad.csv\")\nprop.table(table(grad$result))\n   accept    reject \n0.4260119 0.5739881 \ntable(grad$sex, grad$result)        \n         accept reject\n  female    262    587\n  male     1022   1143\nmytable <- table(grad$sex, grad$result)\nprop.table(mytable, 1)        \n            accept    reject\n  female 0.3085984 0.6914016\n  male   0.4720554 0.5279446\ncounts1 <- table(grad$result)\ncount_data1 <- data.frame(counts1)\ncolnames(count_data1) = c(\"category\", \"count\")\ncount_data1  category count\n1   accept  1284\n2   reject  1730\n# Create a bar plot using ggplot2\nlibrary(ggplot2)  # load the package\nggplot(count_data1, aes(x = category, y = count)) +\n  geom_bar(stat = \"identity\") +\n  labs(y = \"count\")\nlibrary(ggplot2) # don't need if you already entered it for example 1\nggplot(grad, aes(x = sex, fill = result)) + \n  geom_bar(position = \"fill\") + \n  labs(y=\"Proportion\", title = \"result by sex\", fill = \"result?\", x = \"sex\")\ntable(grad$program)\nprogram1 program2 program3 program4 \n     933      585      782      714 \nlibrary(dplyr)\ngrad.p1 <- filter(grad, program == \"program1\")  # gets rows where program equal program1\nhead(grad.p1)   program  sex result\n1 program1 male accept\n2 program1 male accept\n3 program1 male accept\n4 program1 male accept\n5 program1 male accept\n6 program1 male accept\ndim(grad.p1)[1] 933   3\n# enter R code for (f) here\ngrad.p2 <- filter(grad, program == \"program2\") # gets rows where program equal program1\nhead(grad.p2)   program  sex result\n1 program2 male accept\n2 program2 male accept\n3 program2 male accept\n4 program2 male accept\n5 program2 male accept\n6 program2 male accept\nggplot(grad.p1, aes(x = sex, fill = result)) +\n geom_bar(position = \"fill\") +\n labs(y=\"Proportion\", title = \"result by sex for program 1\",\n fill = \"result?\", x = \"sex\")\nprop.table(table(grad.p1$sex, grad.p1$result),1)        \n            accept    reject\n  female 0.8240741 0.1759259\n  male   0.6193939 0.3806061\n# enter R code for (h) here\nggplot(grad.p2, aes(x = sex, fill = result)) +\n geom_bar(position = \"fill\") +\n labs(y=\"Proportion\", title = \"result by sex for program 2\",\n fill = \"result?\", x = \"sex\")\nprop.table(table(grad.p2$sex, grad.p2$result),1)        \n            accept    reject\n  female 0.6800000 0.3200000\n  male   0.6285714 0.3714286\nprop.table(table(grad$sex, grad$program), 1)        \n           program1   program2   program3   program4\n  female 0.12720848 0.02944641 0.44169611 0.40164900\n  male   0.38106236 0.25866051 0.18799076 0.17228637\nprop.table(table(grad$program, grad$result), 1)          \n               accept     reject\n  program1 0.64308682 0.35691318\n  program2 0.63076923 0.36923077\n  program3 0.34398977 0.65601023\n  program4 0.06442577 0.93557423\nggplot(grad, aes(x = sex, fill = result)) + \n  geom_bar(position = \"fill\") + \n  labs(y=\"Proportion\", \n       title = \"result by sex for each program\", \n       fill = \"result?\", \n       x = \"sex\") + \n  facet_wrap(~program)"},{"path":"practice-problems-5.html","id":"practice-problems-5","chapter":"15 Practice Problems 5","heading":"15 Practice Problems 5","text":"","code":""},{"path":"practice-problems-5.html","id":"problem-1-sleep","chapter":"15 Practice Problems 5","heading":"15.1 Problem 1: Sleep","text":"histogram shows distribution hours sleep per night large sample students.","code":"\nlibrary(ggplot2)\nsleep <- read.csv(\"http://math.carleton.edu/Stats215/Textbook/SleepStudy.csv\")\nggplot(sleep, aes(x=AverageSleep)) +\n  geom_histogram(fill=\"steelblue\", bins = 30) +\n  labs(title = \"Distribution of Sleep Hours\", x = \"Hours of Sleep\")"},{"path":"practice-problems-5.html","id":"a-estimate-the-average-hours-of-sleep-per-night.","chapter":"15 Practice Problems 5","heading":"15.1.1 (a) Estimate the average hours of sleep per night.","text":"Answer: mean around 8 hours","code":""},{"path":"practice-problems-5.html","id":"b-use-the-95-rule-to-estimate-the-standard-deviation-for-this-data.","chapter":"15 Practice Problems 5","heading":"15.1.2 (b) Use the 95% rule to estimate the standard deviation for this data.","text":"Answer: data 6 10, mean around 8 (due roughly symmetric\ndistribution). two standard deviations 2 hours sleep, making one standard deviation \n1 hours sleep.Let’s check rule! actual mean SD:","code":"\nmean(sleep$AverageSleep)[1] 7.965929\nsd(sleep$AverageSleep)[1] 0.9648396"},{"path":"practice-problems-5.html","id":"problem-2-z-scores-for-test-scores","chapter":"15 Practice Problems 5","heading":"15.2 Problem 2: Z-scores for Test Scores","text":"ACT test population mean 21 standard deviation 5. SAT population mean 1500 standard deviation 325. earned 28 ACT 2100 SAT.","code":""},{"path":"practice-problems-5.html","id":"a-which-test-did-you-do-better-on","chapter":"15 Practice Problems 5","heading":"15.2.1 (a) Which test did you do better on?","text":"Answer:ACT: z-score score 28 z = (28 - 21)/5 = 1.4.SAT: z-score score 2100 z = (2100 - 1500)/325 = 1.85.SAT score 1.85 standard deviations average ACT score 1.4 standard\ndeviations . better SAT.","code":"\nz_ACT <- (28 - 21) / 5\nz_SAT <- (2100 - 1500) / 325\nz_ACT[1] 1.4\nz_SAT[1] 1.846154"},{"path":"practice-problems-5.html","id":"b-for-each-test-find-the-interval-that-is-likely-to-contain-about-95-of-all-test-scores.","chapter":"15 Practice Problems 5","heading":"15.2.2 (b) For each test, find the interval that is likely to contain about 95% of all test scores.","text":"Answer:ACT: Two standard deviations 2(5) = 10. 95% ACT scores 21 - 10 = 11\n21 + 10 = 31. claim assumes ACT scores follow bell-shaped distribution.SAT: Two standard deviations 2(325) = 650. 95% SAT scores 1500 - 650 =\n850 1500 + 650 = 2150. claim assumes SAT scores follow bell-shaped distribution.","code":"\nACT_lower <- 21 - 2 * 5\nACT_upper <- 21 + 2 * 5\nSAT_lower <- 1500 - 2 * 325\nSAT_upper <- 1500 + 2 * 325\nc(ACT_lower, ACT_upper)[1] 11 31\nc(SAT_lower, SAT_upper)[1]  850 2150"},{"path":"practice-problems-5.html","id":"problem-3-5-number-summaries","chapter":"15 Practice Problems 5","heading":"15.3 Problem 3: 5 number summaries","text":"given vector observations indicate whether resulting data appear symmetric, skewed right, skewed left.(2, 10, 15, 20, 69, 34, 23, 2, 45)Answer: Skewed right. longer right tail left since max -Q3 >> Q1 - min","code":"\nmy_vector <- c(2, 10, 15, 20, 69, 34, 23, 2, 45)\nsummary(my_vector)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00   10.00   20.00   24.44   34.00   69.00 \nggplot(data.frame(x=my_vector), aes(x)) + geom_boxplot()"},{"path":"practice-problems-5.html","id":"problem-4-hot-dog","chapter":"15 Practice Problems 5","heading":"15.4 Problem 4: Hot dog","text":"boxplot shows number hot dogs eaten winners Nathan’s Famous hot dog eating contests 2002-2011.","code":"\nhotdogs <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HotDogs.csv\")\nggplot(hotdogs, aes(x = \"\", y = HotDogs)) +\n  geom_boxplot() +\n  labs(title = \"Number of Hot Dogs Consumed\", y = \"Number of Hot Dogs\") "},{"path":"practice-problems-5.html","id":"a-use-the-boxplot-to-estimate-the-5-number-summary-and-iqr-for-this-data.-verify-that-there-are-no-outliers-in-this-data.","chapter":"15 Practice Problems 5","heading":"15.4.1 (a) Use the boxplot to estimate the 5 number summary and IQR for this data. Verify that there are no outliers in this data.","text":"Answer:","code":"\nhotdog_q1 <- quantile(hotdogs$HotDogs, 0.25); hotdog_q125% \n 54 \nhotdog_q3 <- quantile(hotdogs$HotDogs, 0.75); hotdog_q375% \n 65 \nhotdog_iqr <- IQR(hotdogs$HotDogs); hotdog_iqr[1] 11\nlower_fence <- hotdog_q1 - 1.5 * hotdog_iqr; lower_fence 25% \n37.5 \nupper_fence <- hotdog_q3 + 1.5 * hotdog_iqr; upper_fence 75% \n81.5 \nlibrary(dplyr)\noutliers <- filter(hotdogs, HotDogs < lower_fence | HotDogs > upper_fence)\noutliers[1] Year    HotDogs\n<0 rows> (or 0-length row.names)"},{"path":"practice-problems-5.html","id":"problem-5-hollywood-movies-world-gross","chapter":"15 Practice Problems 5","heading":"15.5 Problem 5: Hollywood Movies World Gross","text":"Let’s visit WorldGross analysis Hollywood movies data set:","code":"\nmovies <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HollywoodMovies2011.csv\")"},{"path":"practice-problems-5.html","id":"a-draw-a-boxplot-of-worldgross.","chapter":"15 Practice Problems 5","heading":"15.5.1 (a) Draw a boxplot of WorldGross.","text":"Answer:many movies identified outliers world gross?","code":"\nggplot(movies, aes(x = WorldGross, y = \"\")) +\n  geom_boxplot() +\n  labs(title = \"World Gross of Hollywood Movies\", x = \"World Gross (in millions)\", y =\"\") "},{"path":"practice-problems-5.html","id":"b-calculating-boxplot-values","chapter":"15 Practice Problems 5","heading":"15.5.2 (b) Calculating boxplot values","text":"Use boxplot outlier rule find “fence” (cutoff) outlier non-outlier WorldGross. determine value (WorldGross) upper “whisker” (non-outlier) extends .Answer:Create new dataset called movies_no_outliers contains rows movies_no_na WorldGross values within range defined lower upper fences.Answer:","code":"\nlibrary(tidyr)\nmovies_no_na <- drop_na(movies)   # drop missing values\nq1_world_gross <- quantile(movies_no_na$WorldGross, 0.25)\nq3_world_gross <- quantile(movies_no_na$WorldGross, 0.75)\niqr_world_gross <- IQR(movies_no_na$WorldGross)\nlower_fence_world_gross <- q1_world_gross - 1.5 * iqr_world_gross\nupper_fence_world_gross <- q3_world_gross + 1.5 * iqr_world_gross\n\noutliers <- filter(movies_no_na, WorldGross < lower_fence_world_gross | WorldGross > upper_fence_world_gross)\noutliers                                          Movie\n1   Harry Potter and the Deathly Hallows Part 2\n2                          The Hangover Part II\n3                       Twilight: Breaking Dawn\n4                Transformers: Dark of the Moon\n5                                           Rio\n6                Rise of the Planet of the Apes\n7                                    The Smurfs\n8                               Kung Fu Panda 2\n9  Pirates of the Caribbean:\\nOn Stranger Tides\n10                           Mission Impossible\n11                            Sherlock Holmes 2\n12                                         Thor\n13                                       Cars 2\n                LeadStudio RottenTomatoes AudienceScore\n1              Warner Bros             96            92\n2       Legendary Pictures             35            58\n3              Independent             26            68\n4      DreamWorks Pictures             35            67\n5         20th Century Fox             71            73\n6         20th Century Fox             83            87\n7  Sony Pictures Animation             23            50\n8     DreamWorks Animation             82            80\n9                   Disney             34            61\n10               Paramount             93            86\n11             Warner Bros             60            79\n12                  Disney             77            80\n13                   Pixar             38            56\n               Story     Genre TheatersOpenWeek\n1            Rivalry   Fantasy             4375\n2             Comedy    Comedy             3615\n3               Love   Romance             4061\n4              Quest    Action             4088\n5              Quest Animation             3826\n6            Revenge    Action             3648\n7  Fish Out Of Water Animation             3395\n8            Rivalry Animation             3925\n9              Quest    Action             4155\n10           Pursuit    Action             3448\n11           Pursuit    Action             3703\n12     Monster Force    Action             3955\n13 Fish Out Of Water Animation             4115\n   BOAverageOpenWeek DomesticGross ForeignGross WorldGross\n1              38672        381.01       947.10   1328.111\n2              23775        254.46       327.00    581.464\n3              34012        260.80       374.00    634.800\n4              23937        352.39       770.81   1123.195\n5              10252        143.62       341.02    484.634\n6              15024        176.70       304.52    481.226\n7              10489        142.61       419.54    562.158\n8              12142        165.25       497.78    663.024\n9              21697        241.07       802.80   1043.871\n10              8672        197.80       336.70    534.500\n11             10704        179.04       261.00    440.040\n12             16618        181.03       267.48    448.512\n13             16072        191.45       360.40    551.850\n   Budget Profitability OpeningWeekend\n1     125     10.624888         169.19\n2      80      7.268300          85.95\n3     110      5.770909         138.12\n4     195      5.759974          97.85\n5      90      5.384822          39.23\n6      93      5.174473          54.81\n7     110      5.110527          35.61\n8     150      4.420160          47.66\n9     250      4.175484          90.15\n10    145      3.686207          29.55\n11    125      3.520320          39.63\n12    150      2.990080          65.72\n13    200      2.759250          66.14\nlibrary(dplyr)\nmovies_no_outliers <- filter(movies_no_na, WorldGross >= lower_fence_world_gross & WorldGross <= upper_fence_world_gross)"},{"path":"practice-problems-5.html","id":"d-side-by-side-boxplot","chapter":"15 Practice Problems 5","heading":"15.5.3 (d) Side-by-side boxplot","text":"can compare boxplots WorldGross across Genre categories:type graph illustrate well relationship WorldGross Genre?type graph illustrate well relationship WorldGross Genre?","code":"\nggplot(movies, aes(x = Genre, y = WorldGross)) +\n  geom_boxplot() +\n  labs(title = \"World Gross by Genre\", x = \"Genre\", y = \"World Gross (in millions)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"},{"path":"practice-problems-6.html","id":"practice-problems-6","chapter":"16 Practice Problems 6","heading":"16 Practice Problems 6","text":"","code":""},{"path":"practice-problems-6.html","id":"problem-1-2","chapter":"16 Practice Problems 6","heading":"16.1 Problem 1","text":"","code":""},{"path":"practice-problems-6.html","id":"beer-example","chapter":"16 Practice Problems 6","heading":"16.1.1 Beer Example","text":"study 16 Ohio State University students looked relationship number beers student consumes blood alcohol content (BAC) 30 minutes last beer. regression information R predict BAC number beers consumed given .relationship?\ndirection?\nstrength?\nform?\ndirection?strength?form?","code":"\nlibrary(ggplot2); library(dplyr)\nbac <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/BAC.csv\")\nggplot(data = bac, aes(x = Beers, y = BAC)) + geom_point(shape = 19) + labs(title = \"Beer and BAC\", x = \"Number of beers\", y = \"Blood Alcohol Content\") + theme_minimal()"},{"path":"practice-problems-6.html","id":"a-computing-correlation","chapter":"16 Practice Problems 6","heading":"16.1.2 (a) Computing correlation","text":"Compute correlation account missing values.Note: missing values (NA’s) either variables involved correlation calculation, use use = \"complete.obs\" extra argument cor function.","code":"\ncor(bac$BAC, bac$Beers, use = \"complete.obs\")[1] 0.8943381"},{"path":"practice-problems-6.html","id":"b-fitting-a-regression-line","chapter":"16 Practice Problems 6","heading":"16.1.3 (b) Fitting a regression line","text":"use lm(y ~ x, data=mydata) function fit linear (regression) model response y given explanatory variable x. command creates linear model object needs assigned name, call bac.lm. can get slope intercept typing object name:","code":"\nbac.lm <- lm(BAC ~ Beers, data=bac)\nbac.lm\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nCoefficients:\n(Intercept)        Beers  \n   -0.01270      0.01796  "},{"path":"practice-problems-6.html","id":"c-write-down-the-fitted-regression-equation-to-predict-bac-from-number-of-beers.","chapter":"16 Practice Problems 6","heading":"16.1.4 (c) Write down the fitted regression equation to predict BAC from number of beers.","text":"can add regression line scatterplot part () creating plot using abline command:","code":"\nggplot(data = bac, aes(x = Beers, y = BAC)) + \n  geom_point(shape = 19) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + \n  labs(title = \"Beer and BAC\", x = \"Number of beers\", y = \"Blood Alcohol Content\") + \n  theme_minimal()"},{"path":"practice-problems-6.html","id":"d-interpret-the-slope-in-context.","chapter":"16 Practice Problems 6","heading":"16.1.5 (d) Interpret the slope in context.","text":"","code":""},{"path":"practice-problems-6.html","id":"e-interpret-the-intercept-in-context-if-it-makes-sense-to-do-so.","chapter":"16 Practice Problems 6","heading":"16.1.6 (e) Interpret the intercept in context, if it makes sense to do so.","text":"","code":""},{"path":"practice-problems-6.html","id":"f-if-your-friend-at-ohio-state-drank-2-beers-what-would-you-predict-their-bac-to-be","chapter":"16 Practice Problems 6","heading":"16.1.7 (f) If your friend at Ohio State drank 2 beers, what would you predict their BAC to be?","text":"Answer: predicted BAC 0.0233.\\[\n\\widehat{BAC} = -0.0127 + 0.0180(2) = 0.0233.\n\\]","code":"\nBAC.hat <- -0.0127 + 0.0180*(2) \nBAC.hat[1] 0.0233"},{"path":"practice-problems-6.html","id":"g-find-the-residual-for-the-student-in-the-dataset-who-drank-2-beers-and-had-a-bac-of-0.03.","chapter":"16 Practice Problems 6","heading":"16.1.8 (g) Find the residual for the student in the dataset who drank 2 beers and had a BAC of 0.03.","text":"Answer: residual 0.0067.\\[\nBAC - \\widehat{BAC} = .03 - .0233=0.0067\n\\]","code":"\n0.03 - (-0.0127 + 0.0180*(2)) [1] 0.0067"},{"path":"practice-problems-6.html","id":"h-getting-residuals-in-r","chapter":"16 Practice Problems 6","heading":"16.1.9 (h) Getting residuals in R","text":"can use resid command get residuals case data set:","code":"\n# Residuals \nresiduals <- data.frame(Beers = bac$Beers, Residuals = resid(bac.lm))\nresiduals   Beers    Residuals\n1      5  0.022881795\n2      2  0.006773080\n3      9  0.041026747\n4      8 -0.011009491\n5      3 -0.001190682\n6      7 -0.018045729\n7      3  0.028809318\n8      5 -0.017118205\n9      3 -0.021190682\n10     5 -0.027118205\n11     4  0.010845557\n12     6  0.004918033\n13     5  0.007881795\n14     7 -0.023045729\n15     1  0.004736842\n16     4 -0.009154443"},{"path":"practice-problems-6.html","id":"i-getting-r2-value","chapter":"16 Practice Problems 6","heading":"16.1.10 (i) Getting \\(R^2\\) value","text":"can use summary command lm object get detailed print linear model, along \\(R^2\\) value model:","code":"\nsummary(bac.lm)\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.027118 -0.017350  0.001773  0.008623  0.041027 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.012701   0.012638  -1.005    0.332    \nBeers        0.017964   0.002402   7.480 2.97e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02044 on 14 degrees of freedom\nMultiple R-squared:  0.7998,    Adjusted R-squared:  0.7855 \nF-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06"},{"path":"practice-problems-6.html","id":"j-making-a-residuals-plot","chapter":"16 Practice Problems 6","heading":"16.1.11 (j) Making a residuals plot","text":"regression BAC Beers residuals plot plots model’s residuals y-axis explanatory (“predictor”) x-axis. add horizontal reference line (detrended regression line) geom_hline() command:Interpret: one case 9 beers large residual (much higher BAC predicted), since clear pattern (trend) plot looks like regression model adequately describes relationship number beers BAC.magnitude scatter around horizontal 0-line residuals plot greater , less , magnitude scatter around regression line scatterplot?","code":"\n# code for residual plot\nggplot(data = residuals, aes(x = Beers, y = Residuals)) +\n           geom_point(shape = 19) +\n           geom_hline(yintercept = 0, color = \"blue\") +\n           labs(title = \"Residuals Plot\",\n                x = \"Number of beers drank\",\n                y = \"Residuals\") +\n           theme_minimal()"},{"path":"practice-problems-6.html","id":"k-identifying-points","chapter":"16 Practice Problems 6","heading":"16.1.12 (k) Identifying points","text":"find rows number Beers 9, can use filter function dplyr package.row number case negative residual? eyeball graph see negative residual less -0.02:find row number case negative residual, can identify residuals less -0.02, pinpoint one also drank 5 beers:","code":"\n# Use `filter` to find rows where Beers equals 9\nfiltered_data <- filter(bac, Beers == 9)\nfiltered_data  X ID_OSU Gender Weight Beers  BAC\n1 3      3 female    110     9 0.19\n# Use `filter` to identify rows with residuals less than -0.02 and 5 beers\nfiltered_resid <- filter(bac, resid(bac.lm) < -0.02 & Beers == 5)\nfiltered_resid   X ID_OSU Gender Weight Beers  BAC\n1 10     10   male    275     5 0.05"},{"path":"practice-problems-6.html","id":"l-checking-outlier-influence","chapter":"16 Practice Problems 6","heading":"16.1.13 (l) Checking outlier influence","text":"can examine influence removing specific cases model using subset parameter lm function. instance, remove row 3:removing case 3, slope changed? Explain change occurred.removing case 3, \\(R^2\\) changed? Explain change occurred.","code":"\n# Fit a linear model without row 3\nbac.lm2 <- lm(BAC ~ Beers, data = bac, subset = -3)\n# Compare the two models\nsummary(bac.lm2)\nCall:\nlm(formula = BAC ~ Beers, data = bac, subset = -3)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.023685 -0.010068 -0.003685  0.011985  0.027208 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 2.481e-05  1.088e-02   0.002    0.998    \nBeers       1.455e-02  2.216e-03   6.568  1.8e-05 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01624 on 13 degrees of freedom\nMultiple R-squared:  0.7684,    Adjusted R-squared:  0.7506 \nF-statistic: 43.14 on 1 and 13 DF,  p-value: 1.802e-05\nsummary(bac.lm)\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.027118 -0.017350  0.001773  0.008623  0.041027 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.012701   0.012638  -1.005    0.332    \nBeers        0.017964   0.002402   7.480 2.97e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02044 on 14 degrees of freedom\nMultiple R-squared:  0.7998,    Adjusted R-squared:  0.7855 \nF-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06"},{"path":"practice-problems-6.html","id":"m-adding-a-categorical-variable-to-your-plot","chapter":"16 Practice Problems 6","heading":"16.1.14 (m) Adding a categorical variable to your plot","text":"color-code points categorical variable like Gender, can use ggplot2 package follows:associations similar? (form, strength, direction)","code":"\nggplot(bac, aes(x = Beers, y = BAC, color = Gender)) + \n  geom_point() "},{"path":"practice-problems-6.html","id":"n-regression-lines-by-groups","chapter":"16 Practice Problems 6","heading":"16.1.15 (n) Regression lines by groups","text":"investigate relationship Beers BAC different genders, can fit separate linear models.can also investigate mean standard deviations Blood Alcohol Content (BAC) Males Females using following R functions:","code":"\nggplot(bac, aes(x = Beers, y = BAC, color = Gender)) + geom_point() + geom_smooth(method = \"lm\", se=FALSE)\n# summary statistics of BAC by gender using dplyr group_by and summarize\nbac %>% group_by(Gender) %>% \n  summarize(mean = mean(BAC),\n            sd = sd(BAC))# A tibble: 2 × 3\n  Gender   mean     sd\n  <chr>   <dbl>  <dbl>\n1 female 0.0825 0.0521\n2 male   0.065  0.0359"},{"path":"practice-problems-6.html","id":"for-females","chapter":"16 Practice Problems 6","heading":"16.1.15.1 For Females:","text":"","code":"\n# Use `filter` to get female data\nbac_female <- filter(bac, Gender == \"female\")\n\n# Fit the model for females\nbac_lm_female <- lm(BAC ~ Beers, data = bac_female)\nsummary(bac_lm_female)\nCall:\nlm(formula = BAC ~ Beers, data = bac_female)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.034000 -0.008583  0.003667  0.014167  0.023667 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -0.015667   0.019008  -0.824  0.44135   \nBeers        0.020667   0.003641   5.676  0.00129 **\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0223 on 6 degrees of freedom\nMultiple R-squared:  0.843, Adjusted R-squared:  0.8168 \nF-statistic: 32.21 on 1 and 6 DF,  p-value: 0.001289"},{"path":"practice-problems-6.html","id":"for-males","chapter":"16 Practice Problems 6","heading":"16.1.15.2 For Males:","text":"regression line females? males?gender largest slope? suggest relationship number beers BAC gender?Answer: slope females slightly higher. shows effect one beer predicted BAC females larger males (0.021 increase vs. 0.015 increase).","code":"\n# Use `filter` to get male data\nbac_male <- filter(bac, Gender == \"male\")\n\n# Fit the model for males\nbac_lm_male <- lm(BAC ~ Beers, data = bac_male)\nsummary(bac_lm_male)\nCall:\nlm(formula = BAC ~ Beers, data = bac_male)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.016918 -0.007088  0.001093  0.005099  0.017742 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.009785   0.010323  -0.948 0.379786    \nBeers        0.015341   0.001947   7.881 0.000221 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0115 on 6 degrees of freedom\nMultiple R-squared:  0.9119,    Adjusted R-squared:  0.8972 \nF-statistic: 62.11 on 1 and 6 DF,  p-value: 0.0002211"},{"path":"practice-problems-6.html","id":"problem-2-inkjet-example","chapter":"16 Practice Problems 6","heading":"16.2 Problem 2: Inkjet Example","text":"following Inkjet dataset deals 20 observations following 6 variables:Model Model name printerPPM Printing rate (pages per minute) benchmark set print jobsPhotoTime Time (seconds) print \\(4 \\times 6\\) color photosPrice Typical retail price (dollars)CostBW Cost per page (cents) printing black & whiteCostColor Cost per page (cents) printing color","code":"\nlibrary(ggplot2)\nlibrary(dplyr)\ninkjet <- read.csv(\"https://www.lock5stat.com/datasets2e/InkjetPrinters.csv\") \nknitr::kable(inkjet)\nggplot(data = inkjet, aes(x = Price, y = CostColor)) + \n     geom_point(shape = 19) +\n     labs(title = \"Price and Cost to print a page in Color\",\n          x = \"Price (in dollars)\",\n          y = \"Cost per page (in cents)\") +\n     theme_minimal()"},{"path":"practice-problems-6.html","id":"a-is-there-a-relationship","chapter":"16 Practice Problems 6","heading":"16.2.1 (a) Is there a relationship?","text":"use lm(y ~ x, data=mydata) function fit linear (regression) model response y given explanatory variable x.","code":"+ direction?\n+ strength?\n+ form?\ninkjet.lm <- lm(CostColor ~ Price, data=inkjet)\nsummary(inkjet.lm)\nCall:\nlm(formula = CostColor ~ Price, data = inkjet)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5517 -0.8050  0.2874  1.2708  5.5267 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15.351445   1.138390  13.485 7.55e-11 ***\nPrice       -0.022781   0.006274  -3.631  0.00191 ** \n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.316 on 18 degrees of freedom\nMultiple R-squared:  0.4228,    Adjusted R-squared:  0.3908 \nF-statistic: 13.19 on 1 and 18 DF,  p-value: 0.00191"},{"path":"practice-problems-6.html","id":"b-write-down-the-fitted-regression-equation-to-predict-cost-per-page-based-on-the-price.","chapter":"16 Practice Problems 6","heading":"16.2.2 (b) Write down the fitted regression equation to predict cost per page based on the price.","text":"Answer: \\(\\widehat{CostColor} = 15.3514 - 0.02278 * \\text{Price}\\)","code":""},{"path":"practice-problems-6.html","id":"c-interpret-the-slope-in-context.","chapter":"16 Practice Problems 6","heading":"16.2.3 (c) Interpret the slope in context.","text":"Answer: dollar increase price inkjet printer, decrease cost print color 0.02278 cents.","code":""},{"path":"practice-problems-6.html","id":"d-interpret-the-intercept-in-context-if-it-makes-sense-to-do-so.","chapter":"16 Practice Problems 6","heading":"16.2.4 (d) Interpret the intercept in context, if it makes sense to do so.","text":"Answer: price printer costs 0 dollars, cost print color 15.3514 cents. extrapolation ’s nonsensical talk printer costing 0 dollars context.","code":""},{"path":"practice-problems-6.html","id":"f-if-you-buy-an-injet-printers-worth-200-dollars-what-would-you-estimate-the-cost-per-page-in-cents","chapter":"16 Practice Problems 6","heading":"16.2.5 (f) If you buy an injet printers worth 200 dollars, what would you estimate the cost per page (in cents)?","text":"Answer: cost per page 10.80 cents.","code":"\n15.3514 - 0.02278*200[1] 10.7954"},{"path":"practice-problems-6.html","id":"g-what-is-the-value-of-r2-the-coefficient-of-determination-what-does-it-mean","chapter":"16 Practice Problems 6","heading":"16.2.6 (g) What is the value of \\(R^2\\), the coefficient of determination? What does it mean?","text":"Answer: value \\(R^2\\) 0.4228. means 42.28% variability cost print color explained price inkjet printer.","code":""},{"path":"practice-problems-6.html","id":"h-what-is-the-value-of-r-the-correlation-coefficient","chapter":"16 Practice Problems 6","heading":"16.2.7 (h) What is the value of \\(r\\), the correlation coefficient?","text":"Answer: value \\(r\\) - 0.65.Note: ’s important note \\(R^2\\) \\(r\\) related directly convertible just taking square root, especially multiple regression scenarios. square root \\(R^2\\) equals \\(r\\) simple linear regression models, even , sign \\(r\\) depends sign slope.","code":"\n- sqrt(0.4228)[1] -0.6502307"},{"path":"practice-problems-7.html","id":"practice-problems-7","chapter":"17 Practice Problems 7","heading":"17 Practice Problems 7","text":"","code":""},{"path":"practice-problems-7.html","id":"problem-1-using-search-engines-on-the-internet","chapter":"17 Practice Problems 7","heading":"17.1 Problem 1: Using Search Engines on the Internet","text":"2012 survey random sample 2253 US adults found 1,329 reported using search engine (Google) every day find information Internet.","code":""},{"path":"practice-problems-7.html","id":"a.-find-the-relevant-proportion-and-give-the-correct-notation-with-it.","chapter":"17 Practice Problems 7","heading":"17.1.1 a). Find the relevant proportion and give the correct notation with it.","text":"Answer: \\(\\hat{p} = 1329/2253\\)","code":"\np.hat <- 1329/2253\np.hat[1] 0.5898802"},{"path":"practice-problems-7.html","id":"b.-is-your-answer-to-part-a-a-parameter-or-a-statistic","chapter":"17 Practice Problems 7","heading":"17.1.2 b). Is your answer to part (a) a parameter or a statistic?","text":"","code":""},{"path":"practice-problems-7.html","id":"c.-give-notation-for-and-define-the-population-parameter-that-we-estimate-using-the-result-of-part-a.","chapter":"17 Practice Problems 7","heading":"17.1.3 c). Give notation for and define the population parameter that we estimate using the result of part (a).","text":"","code":""},{"path":"practice-problems-7.html","id":"problem-2-bootstrapping-mean","chapter":"17 Practice Problems 7","heading":"17.2 Problem 2: Bootstrapping mean","text":"Let’s visualize distribution sample mean. following vector X containing \\(6\\) data points:start creating 500 bootstrap samples data. Bootstrapping resampling technique sample replacement original data, usually number observations original dataset, create ‘new’ samples. process mimics sampling variability inherent collecting data. bootstrap sample, calculate mean.calculating bootstrap sample means, visualize distribution using dot plot. plot give us sense sampling distribution mean - showing us mean likely fall much can vary.Answer: ’s close.","code":"\nX <- c(20, 24, 19, 23, 22, 16)  # our data\nbootstrapped_means <- sapply(1:500, function(i) mean(sample(X, replace = TRUE)))\n\n# Or using replicate which is more concise for this case:\nbootstrapped_means <- replicate(500, mean(sample(X, replace = TRUE)))\n\n# To get a data frame similar to the tibble you created with purrr:\nbootstrapped_means_df <- data.frame(\n  iteration = 1:500,\n  mean = bootstrapped_means\n)\nlibrary(ggplot2)\nggplot(bootstrapped_means_df, aes(x = mean)) +\n  geom_dotplot(dotsize = 0.7, \n               stackratio = 0.9, \n               binwidth = .13, \n               color = \"gold\", \n               fill = \"blue\") +\n  ggtitle(\"\") + xlab(\"\") + ylab(\"\") +\n  scale_x_continuous(limits = c(17, 24), \n                     expand = c(0, 0), \n                     breaks = seq(17, 24, 1)) +\n  labs(title = \"Bootstrap distribution of sample mean\")"},{"path":"practice-problems-7.html","id":"problem-3-simulation-of-a-sample-proportion","chapter":"17 Practice Problems 7","heading":"17.3 Problem 3: Simulation of a Sample Proportion","text":"According PEW survey, \\(66\\%\\) U.S. adult citizens casted ballot 2020 election. Suppose take random sample \\(n=100\\) eligible U.S. voters computed sample proportion voted.Let’s plot sample proportion R.Similarly, can generate 5 random samples size \\(n= 100\\) plot sample proportions.Continuing , can generate 500 random samples size \\(n= 100\\) plot sample proportions.Answer: center distribution close 0.66.Answer:\nstandard error close.","code":"\n# Define parameters\npop.prop <- .66 # Population proportion\nn.size <- 100  # sample size\nmean(sample.prop500)[1] 0.66298"},{"path":"practice-problems-7.html","id":"d-now-lets-repeat-partc-with-sample-size-20-instead-of-100-by-generating-and-plotting-500-sample-proportions.","chapter":"17 Practice Problems 7","heading":"17.3.1 (d) Now, let’s repeat part(c) with sample size 20 instead of 100 by generating and plotting 500 sample proportions.","text":"Answer: shape slightly left skewed, still centered 0.66 variability (SD 0.10). distribution discrete looking just sample proportions possible n=20 (e.g. 20/20, 19/20, 18/20, etc).","code":"\nmean(sample.prop500_size10)[1] 0.6603\nsd(sample.prop500_size10)[1] 0.1024202"},{"path":"practice-problems-7.html","id":"d-now-suppose-the-population-proportion-is-p0.90-instead-of-p0.66-in-part-e.-keep-n20.","chapter":"17 Practice Problems 7","heading":"17.3.2 (d) Now suppose the population proportion is \\(p=0.90\\) instead of \\(p=0.66\\) in part (e). Keep n=20.","text":"Answer: shape much left skewed p=0.66. Center around 0.90 SD around 0.07. Note increasing population proportion closer 1 results decrease SD samples give proportion near 1.","code":"\nmean(sample.prop500_size10_large_p)[1] 0.8989\nsd(sample.prop500_size10_large_p)[1] 0.06412499"},{"path":"practice-problems-8.html","id":"practice-problems-8","chapter":"18 Practice Problems 8","heading":"18 Practice Problems 8","text":"","code":""},{"path":"practice-problems-8.html","id":"problem-1-textbook-prices","chapter":"18 Practice Problems 8","heading":"18.1 Problem 1: Textbook Prices","text":"Prices random sample 10 textbooks (rounded nearest dollar) shown:\\[ \\$132 \\quad \\$87 \\quad \\$185 \\quad \\$52 \\quad \\$23 \\quad \\$147 \\quad \\$125 \\quad \\$93 \\quad \\$85 \\quad \\$72 \\]","code":""},{"path":"practice-problems-8.html","id":"a.-what-is-the-sample-mean-verify-using-r-code.","chapter":"18 Practice Problems 8","heading":"18.1.1 (a). What is the sample mean? Verify using r-code.","text":"","code":"\nprices <- c(132,87, 185, 52, 23, 147, 125, 93, 85, 72)\nmean(prices)[1] 100.1"},{"path":"practice-problems-8.html","id":"b.-describe-carefully-how-we-could-use-cards-to-create-one-bootstrap-statistic-from-this-sample.-be-specific.","chapter":"18 Practice Problems 8","heading":"18.1.2 (b). Describe carefully how we could use cards to create one bootstrap statistic from this sample. Be specific.","text":"Answer: use 10 cards write 10 sample values cards. mix draw one record value put back. Mix , draw another, record value, put back. 10 times get “replacement” sample size 10. compute sample mean bootstrap sample.","code":""},{"path":"practice-problems-8.html","id":"c.-we-can-easily-instruct-r-to-do-this-with-a-simple-code-provided-below.-will-the-mean-of-this-resample-be-same-as-the-original-sample-what-about-the-standsrd-deviation","chapter":"18 Practice Problems 8","heading":"18.1.3 (c). We can easily instruct R to do this with a simple code provided below. Will the mean of this resample be same as the original sample? What about the standsrd deviation?","text":"mean resample original sample? standard deviation?Answer: mean resample, created using bootstrapping, , , less mean original sample, depending values randomly chosen resampling process. Bootstrapping involves randomly selecting observations original sample replacement, ’s chance resample might higher values, lower values, mix similar original sample.standard deviation, also depends composition resampled data. resample ends values close (less variability), standard deviation might lower original sample. Conversely, resample wider spread values, standard deviation higher. However, many bootstrap samples, average standard deviation tend close standard deviation original sample.","code":"\nresample <- sample(prices, replace = TRUE)\nresample [1]  72  85  93  87  72  93 125  23  93  23"},{"path":"practice-problems-8.html","id":"d.-where-will-be-bootstrap-distribution-be-centered-what-shape-do-we-expect-it-to-have","chapter":"18 Practice Problems 8","heading":"18.1.4 (d). Where will be bootstrap distribution be centered? What shape do we expect it to have?","text":"Answer: centered approximately sample mean 100.1 expect roughly bellshaped (may bit skewed since sample size 10 smallish).","code":""},{"path":"practice-problems-8.html","id":"e.-the-function-boot-from-carletonstats-r-package-creates-a-bootstrap-distribution-from-the-original-sample-of-10-textbook-prices.-what-is-the-standard-error-of-this-bootrtrap-distribution.-will-this-standard-error-be-smaller-or-larger-than-the-standard-deviation-of-the-original-sample-explain.","chapter":"18 Practice Problems 8","heading":"18.1.5 (e). The function boot from CarletonStats R package creates a bootstrap distribution from the original sample of 10 textbook prices. What is the standard error of this bootrtrap distribution. Will this standard error be smaller or larger than the standard deviation of the original sample? Explain.","text":"Answer: standard error typically smaller standard deviation original sample standard error estimating variability sample mean, individual observations. sample mean tends less variability individual data points, especially averaged across multiple samples.","code":"\nlibrary(CarletonStats)\nboot(prices)\n    ** Bootstrap interval for mean \n\n Observed  prices : 100.1 \n Mean of bootstrap distribution: 100.1573 \n Standard error of bootstrap distribution: 14.14495 \n\n Bootstrap percentile interval\n 2.5% 97.5% \n 72.6 128.3 \n\n        *--------------*"},{"path":"practice-problems-8.html","id":"problem-2-statkey-atlanta-commute-distance","chapter":"18 Practice Problems 8","heading":"18.2 Problem 2: Statkey Atlanta Commute Distance","text":"Go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Single Mean, Median, St.Dev”. Change data set Atlanta Commute (Distance). data set gives random sample 500 worker commute distances (miles) metropolitan Atlanta","code":""},{"path":"practice-problems-8.html","id":"a.-use-the-original-sample-pane-to-determine-the-shape-of-these-500-commuter-distances-along-with-their-mean-and-standard-deviation.-write-down-these-stats-using-correct-notation.","chapter":"18 Practice Problems 8","heading":"18.2.1 (a). Use the “Original Sample” pane to determine the shape of these 500 commuter distances, along with their mean and standard deviation. Write down these stats using correct notation.","text":"Answer: sample mean \\(\\bar{x} = 18.16\\) sample standard deviation \\(s = 13.798\\).","code":""},{"path":"practice-problems-8.html","id":"b.-click-generate-1-sample-to-create-one-bootstrap-sample-from-this-data.-explain-how-this-sample-was-generated.-use-the-bootstrap-sample-pane-to-find-the-bootstrap-statistic-that-was-computed-from-this-sample.-what-value-is-this-bootstrap-statistic-repeat-this-a-couple-times.","chapter":"18 Practice Problems 8","heading":"18.2.2 (b). Click “Generate 1 Sample” to create one bootstrap sample from this data. Explain how this sample was generated. Use the “Bootstrap Sample” pane to find the bootstrap statistic that was computed from this sample. What value is this bootstrap statistic? Repeat this a couple times.","text":"Answer: bootstrap sample obtained resampling 500 observed commute distances \nreplacement. Basically randomly select 500 distances data (replacement).","code":""},{"path":"practice-problems-8.html","id":"c.-now-click-the-generate-1000-samples-to-get-1000-bootstrap-sample-means.-is-the-bootstrap-distribution-centered-at-the-population-or-sample-mean-commute-distance","chapter":"18 Practice Problems 8","heading":"18.2.3 (c). Now click the “Generate 1000 Samples” to get 1000 bootstrap sample means. Is the bootstrap distribution centered at the population or sample mean commute distance?","text":"Answer: bootstrap distribution always centered around statistic bootstrapped. centered around sample mean commute distance 18.16 miles. population mean\ncommute distance unknown!","code":""},{"path":"practice-problems-8.html","id":"d.-what-is-the-bootstrap-se-for-the-sample-mean","chapter":"18 Practice Problems 8","heading":"18.2.4 (d). What is the bootstrap SE for the sample mean?","text":"","code":""},{"path":"practice-problems-8.html","id":"e.-compute-a-95-confidence-interval-for-the-average-commute-distance-in-metropolitan-atlanta.","chapter":"18 Practice Problems 8","heading":"18.2.5 (e). Compute a 95% confidence interval for the average commute distance in metropolitan Atlanta.","text":"","code":""},{"path":"practice-problems-8.html","id":"f.-interpret-your-answer-to-e-in-context.","chapter":"18 Practice Problems 8","heading":"18.2.6 (f). Interpret your answer to (e) in context.","text":"","code":""},{"path":"practice-problems-8.html","id":"problem-3-statkey-global-warming","chapter":"18 Practice Problems 8","heading":"18.3 Problem 3: Statkey Global Warming","text":"percentage Americans believe global warming? survey 2,251 randomly selected individuals\nconducted October 2010 found 1,328 answered Yes question “solid evidence global\nwarming?” compute bootstrap confidence interval proportion Americans believe \nglobal warming, go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Single Proportion”.","code":""},{"path":"practice-problems-8.html","id":"a.-enter-the-data-for-this-survey-by-clicking-the-edit-data-button.-enter-2251-as-the-sample-size-and-1328-as-the-count.-what-is-the-sample-proportion-of-people-who-believe-in-global-warming-use-correct-notation","chapter":"18 Practice Problems 8","heading":"18.3.1 (a). Enter the data for this survey by clicking the “Edit Data” button. Enter 2251 as the sample size and 1328 as the count. What is the sample proportion of people who believe in global warming? Use correct notation!","text":"","code":""},{"path":"practice-problems-8.html","id":"b.-generate-1-bootstrap-sample.-explain-how-this-sample-was-generated.-use-the-bootstrap-sample-pane-to-find-the-bootstrap-statistic-that-was-computed-from-this-sample.-what-value-is-this-bootstrap-statistic-repeat-this-a-couple-times.","chapter":"18 Practice Problems 8","heading":"18.3.2 (b). Generate 1 bootstrap sample. Explain how this sample was generated. Use the “Bootstrap Sample” pane to find the bootstrap statistic that was computed from this sample. What value is this bootstrap statistic? Repeat this a couple times.","text":"","code":""},{"path":"practice-problems-8.html","id":"c.-generate-1000-samples-to-get-1000-bootstrap-sample-proportions.-is-the-bootstrap-distribution-centered-at-the-population-or-sample-proportion-describe-the-shape-and-center-of-this-bootstrap-distribution","chapter":"18 Practice Problems 8","heading":"18.3.3 (c). Generate 1000 samples to get 1000 bootstrap sample proportions. Is the bootstrap distribution centered at the population or sample proportion? Describe the shape and center of this bootstrap distribution","text":"Answer: shape symmetric around center value 0.59, sample proportion population proportion (unknown).","code":""},{"path":"practice-problems-8.html","id":"d.-compute-a-95-confidence-interval-for-the-proportion-of-americans-who-believe-in-global-warming","chapter":"18 Practice Problems 8","heading":"18.3.4 (d). Compute a 95% confidence interval for the proportion of Americans who believe in global warming","text":"","code":""},{"path":"practice-problems-8.html","id":"e.-interpret-your-interval-from-part-d.","chapter":"18 Practice Problems 8","heading":"18.3.5 (e). Interpret your interval from part (d).","text":"","code":""},{"path":"practice-problems-8.html","id":"f.-does-this-data-support-a-claim-that-a-majority-of-americans-believe-there-is-solid-evidence-of-global-warming-explain.","chapter":"18 Practice Problems 8","heading":"18.3.6 (f). Does this data support a claim that a majority of Americans believe there is solid evidence of global warming? Explain.","text":"Answer: Yes, data support claim since confident least 50% Americans believe global warming since lower bound CI 57%.","code":""},{"path":"practice-problems-8.html","id":"problem-4.-statkey-global-warming-by-political-party","chapter":"18 Practice Problems 8","heading":"18.4 Problem 4. Statkey Global Warming by Political Party","text":"belief global warming differ political party? question “solid evidence global warming?” asked, sample proportion answering “yes” 79% among Democrats 38% among\nRepublicans. compute bootstrap confidence interval difference proportion Democrats\nRepublicans believe global warming, go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Difference Proportions”.","code":""},{"path":"practice-problems-8.html","id":"a.-enter-the-data-for-this-survey-by-clicking-the-edit-data-button.-one-big-assumption-we-will-make-is-that-the-sample-sizes-for-both-groups-dems-and-reps-were-each-1000.-enter-the-democrat-data-into-the-group-1-boxes-count-of-790-and-size-of-1000-and-the-republican-data-into-the-group-2-boxes-count-of-380-and-size-of-1000.-verify-that-the-sample-proportions-for-the-two-groups-are-79-and-38.-what-is-the-difference-in-the-two-sample-proportions-use-correct-notation.","chapter":"18 Practice Problems 8","heading":"18.4.1 (a). Enter the data for this survey by clicking the “Edit Data” button. One big assumption we will make is that the sample sizes for both groups (Dems and Reps) were each 1000. Enter the Democrat data into the “Group 1” boxes (count of 790 and size of 1000) and the Republican data into the “Group 2” boxes (count of 380 and size of 1000). Verify that the sample proportions for the two groups are 79% and 38%. What is the difference in the two sample proportions? Use correct notation.","text":"","code":""},{"path":"practice-problems-8.html","id":"b.-generate-1-bootstrap-sample.-explain-how-this-sample-was-generated-give-this-some-thought-now-that-you-have-two-samples-of-data.-use-the-bootstrap-sample-pane-to-find-the-bootstrap-statistic-that-was-computed-from-this-sample.-what-value-is-this-bootstrap-statistic-repeat-this-a-couple-times.","chapter":"18 Practice Problems 8","heading":"18.4.2 (b). Generate 1 bootstrap sample. Explain how this sample was generated (give this some thought now that you have two samples of data). Use the “Bootstrap Sample” pane to find the bootstrap statistic that was computed from this sample. What value is this bootstrap statistic? Repeat this a couple times.","text":"Answer: One bootstrap sample obtained group 1 sample (resampling observed “believe/believe” responses replacement) separate bootstrap sample obtained group 2 sample. difference bootstrap proportions group computed bootstrap difference statistic.","code":""},{"path":"practice-problems-8.html","id":"c.-generate-1000-samples-to-get-1000-bootstrap-sample-proportion-differences.-describe-the-shape-and-center-of-this-bootstrap-distribution","chapter":"18 Practice Problems 8","heading":"18.4.3 (c). Generate 1000 samples to get 1000 bootstrap sample proportion differences. Describe the shape and center of this bootstrap distribution","text":"Answer: shape symmetric around center value 0.41 (sample difference proportions).","code":""},{"path":"practice-problems-8.html","id":"d.-compute-a-95-confidence-interval-for-the-difference-between-the-proportion-of-democrats-and-republicans-who-believe-in-global-warming.","chapter":"18 Practice Problems 8","heading":"18.4.4 (d). Compute a 95% confidence interval for the difference between the proportion of Democrats and Republicans who believe in global warming.","text":"","code":""},{"path":"practice-problems-8.html","id":"e.-interpret-your-interval-from-part-d-in-context-and-without-using-the-word-difference-i.e.-give-a-directional-claim-that-uses-words-like-more-or-less","chapter":"18 Practice Problems 8","heading":"18.4.5 (e). Interpret your interval from part (d) in context and without using the word difference!! (i.e. give a directional claim that uses words like “more” or “less”)","text":"","code":""},{"path":"practice-problems-8.html","id":"f.-to-compute-this-interval-we-assumed-that-1000-people-were-sampled-from-each-subpopulation-dems-and-reps.-suppose-this-sample-size-was-just-500-people-for-each-group.-would-your-95-confidence-interval-be-wider-or-shorter-than-the-one-computed-in-part-d-explain.","chapter":"18 Practice Problems 8","heading":"18.4.6 (f). To compute this interval, we assumed that 1000 people were sampled from each subpopulation (Dems and Reps). Suppose this sample size was just 500 people for each group. Would your 95% confidence interval be wider or shorter than the one computed in part (d)? Explain.","text":"","code":""},{"path":"practice-problems-8.html","id":"problem-5-credit-loan-data","chapter":"18 Practice Problems 8","heading":"18.5 Problem 5: Credit Loan Data","text":"data set CreditData.csv contains records 1000 loans either defaulted (BadLoan) default (GoodLoan). 300 loans defaulted 700 . Let’s consider 300 loans defaulted random sample loans default 700 non-defaulting loans random sample loans don’t default.","code":"\ncredit <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/CreditData.csv\")\ntable(credit$Good.Loan)\n BadLoan GoodLoan \n     300      700 "},{"path":"practice-problems-8.html","id":"a-visualize-age-vs.-default","chapter":"18 Practice Problems 8","heading":"18.5.1 (a) Visualize age vs. default","text":"variable Age..years gives age person received loan. Construct side--side boxplot age Good.Loan compute sample means group.mean ages group?\nClick answerAnswer: 34.0 years bad loan group 36.2 years good loan group.Describe distribution ages group. outliers overly influential value(s) sample mean(s)?\nClick answerAnswer: age distributions somewhat right skewed outliers identified boxplot rule. aren’t extremely unusual cases.\n","code":"\n# Boxplot using ggplot2\nggplot(credit, aes(x = Good.Loan, y = Age.in.years)) +\n  geom_boxplot()\n# Mean age for each Good.Loan category using dplyr\ncredit %>%\n  group_by(Good.Loan) %>%\n  summarize(mean_age = mean(Age.in.years))# A tibble: 2 × 2\n  Good.Loan mean_age\n  <chr>        <dbl>\n1 BadLoan       34.0\n2 GoodLoan      36.2"},{"path":"practice-problems-8.html","id":"b-bootstrap-ci-for-a-difference-in-means","chapter":"18 Practice Problems 8","heading":"18.5.1.1 (b) Bootstrap CI for a difference in means","text":"boot(y ~ x, data=) command generates 10000 bootstrap samples true difference means y two groups x. command contained CarletonStats package. use compute bootstrap distribution difference mean ages two default groups:Give difference sample mean ages reported output. Use correct notation.\nClick answerAnswer: average age people bad loan 2.3 years less average age people good loan.\nGive 95% confidence interval difference mean ages using percentile method\nClick answerAnswer: percentile interval -3.8 -0.7 years.\nCompute 95% confidence interval difference mean ages using bootstrap SE. similar CI percentile method?Answer: CI using SE -3.8 -0.7. intervals similar.\\[\n-2.26095 \\pm 2(0.77852) = (-3.81799,  -0.70391)\n\\]","code":"\nlibrary(CarletonStats)\nboot(Age.in.years ~ Good.Loan, data=credit)\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : BadLoan - GoodLoan = -2.26095 \n Mean of bootstrap distribution: -2.25588 \n Standard error of bootstrap distribution: 0.77369 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-3.7586786 -0.7085595 \n\n        *--------------*\n-2.26095 - 2*(0.77852)[1] -3.81799\n-2.26095 + 2*(0.77852)[1] -0.70391"},{"path":"practice-problems-8.html","id":"c-interpret","chapter":"18 Practice Problems 8","heading":"18.5.1.2 (c) Interpret","text":"","code":""},{"path":"practice-problems-8.html","id":"problem-6-credit-data-continued","chapter":"18 Practice Problems 8","heading":"18.6 Problem 6 : Credit data continued","text":"variable Telephone tells us individual phone number loan file. Let’s look proportion individuals phone number type loan (default ).","code":""},{"path":"practice-problems-8.html","id":"a-data-clean-up","chapter":"18 Practice Problems 8","heading":"18.6.0.1 (a) Data clean up","text":"entries Telephone column either none yes, registered customers name.","code":"\ntable(credit$Telephone)\n                                    none \n                                     596 \nyes, registered under the customers name \n                                     404 \n# Modify the Telephone variable levels using dplyr and forcats\ncredit <- credit %>%\n  mutate(Telephone = recode(Telephone,\n                            \"none\" = \"no\",\n                            \"yes, registered under the customers name\" = \"yes\"))\n# Convert the Telephone variable to a factor\ncredit$Telephone <- as.factor(credit$Telephone)\n# Display the levels of the modified Telephone variable\nlevels(credit$Telephone)[1] \"no\"  \"yes\""},{"path":"practice-problems-8.html","id":"b-phone-rate-by-default-type","chapter":"18 Practice Problems 8","heading":"18.6.0.2 (b) Phone rate by default type","text":"get distribution phone numbers (yes ) default type (good vs bad loan):proportion bad loans phone number account?\nClick answerAnswer: 37.7% bad loans phone number.\nproportion good loans phone number account?\nClick answerAnswer: 41.6% good loans phone number.\nsample difference proportion good loans bad loans phone number? Use correct notation number.\nClick answerAnswer: get \\(\\hat{p}_{good} - \\hat{p}_{bad} =0.4157143 - 0.3766667 = 0.0390476\\).","code":"\nprop.table(table(credit$Good.Loan, credit$Telephone),1)          \n                  no       yes\n  BadLoan  0.6233333 0.3766667\n  GoodLoan 0.5842857 0.4157143\nlibrary(ggplot2)\nggplot(credit, aes(x=Good.Loan, fill=Telephone)) + geom_bar(position=\"fill\")\n0.4157143 - 0.3766667[1] 0.0390476"},{"path":"practice-problems-8.html","id":"c-using-the-boot-command-with-a-categorical-response","chapter":"18 Practice Problems 8","heading":"18.6.0.3 (c) Using the boot command with a categorical response","text":"order get bootstrap distribution sample difference proportions, need recode “response” variable Telephone 1 indicating “yes” response 0 indicating “” response. done ifelse command:reads “Telephone equals yes assign 1, else assign 0”. 0’s 1’s assigned variable called Telephone_binary now data frame (checked View(credit) command).Check work make sure Telephone_binary records want recordThe mean 0/1 coded variable computes proportion “yes” responses:Note: examples Lab Manual already 0/1 recoding done lab manual data sets. thought might want learn recoding case plan use command , non-lab manual data sets!","code":"\ncredit$Telephone_binary<- ifelse(credit$Telephone == \"yes\", 1, 0)\nhead(credit[,c(\"Telephone\", \"Telephone_binary\")])  Telephone Telephone_binary\n1       yes                1\n2        no                0\n3        no                0\n4        no                0\n5        no                0\n6       yes                1\ntable(credit$Telephone)\n no yes \n596 404 \ntable(credit$Telephone_binary)\n  0   1 \n596 404 \nmean(credit$Telephone_binary)[1] 0.404\n404/1000  # proportion of yes[1] 0.404"},{"path":"practice-problems-8.html","id":"d-95-confidence-interval-for-the-difference-in-phone","chapter":"18 Practice Problems 8","heading":"18.6.0.4 (d) 95% confidence interval for the difference in phone","text":"can now use 0/1 version telephone boot command (like example 1) compute 95% bootstrap confidence interval difference population proportion good loans bad loans phone number.Even though language used output says “statistic” computing difference “proportions”!!Give 95% confidence interval difference population proportion bad loans good loans phone number using percentile method\nClick answerAnswer: percentile interval Bad \\(-\\) Good -0.105 0.028.\nGive 95% confidence interval difference population proportion bad loans good loans phone number using bootstrap SE. similar CI percentile method?\nClick answerAnswer: SE method gives interval Bad \\(-\\) Good -0.107 0.028 similar percentile interval.","code":"\nboot(Telephone_binary ~ Good.Loan, data=credit)\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : BadLoan - GoodLoan = -0.03905 \n Mean of bootstrap distribution: -0.03886 \n Standard error of bootstrap distribution: 0.03389 \n\n Bootstrap percentile interval\n       2.5%       97.5% \n-0.10380952  0.02904762 \n\n        *--------------*\n-0.03905 - 2* 0.03373 [1] -0.10651\n-0.03905 + 2* 0.[1] -0.03905"},{"path":"practice-problems-8.html","id":"e-interpret","chapter":"18 Practice Problems 8","heading":"18.6.0.5 (e) Interpret","text":"","code":""},{"path":"practice-problems-9.html","id":"practice-problems-9","chapter":"19 Practice Problems 9","heading":"19 Practice Problems 9","text":"","code":""},{"path":"practice-problems-9.html","id":"problem-1-a-muslim-president","chapter":"19 Practice Problems 9","heading":"19.0.1 Problem 1: A Muslim president?","text":"survey 1,527 American adults conducted June 2015 stated 60% vote qualified Muslim presidential candidate. survey goes say “… margin sampling error +/- 3 percentage points 95% confidence level.”","code":""},{"path":"practice-problems-9.html","id":"problem-2-biomass-in-tropical-forests","chapter":"19 Practice Problems 9","heading":"19.0.2 Problem 2: Biomass in Tropical Forests","text":"Using random sample 4079 inventory plots, scientists found sample average 11,600 tons carbon per square kilometer standard error 1000 tons. Give 95% confidence interval mean amount carbon per square kilometer tropical forests. Clearly interpret meaning confidence interval.","code":""},{"path":"practice-problems-9.html","id":"problem-3-change-in-gun-ownership","chapter":"19 Practice Problems 9","heading":"19.0.3 Problem 3: Change in gun ownership?","text":"2016 study described Guardian found random sample US adults 1994 found female rate gun ownership 9%. similar random sample 2015 found rate female gun ownership rose 12%. Though given article, let’s assume SE difference two sample proportions 2%.","code":""},{"path":"practice-problems-9.html","id":"problem-4-interpreting-a-confidence-interval","chapter":"19 Practice Problems 9","heading":"19.0.4 Problem 4: Interpreting a Confidence Interval","text":"Using sample 24 deliveries described “Diary Pizza Girl” Slice website, find 95% confidence interval mean tip given pizza delivery $2.18 $3.90. following correct interpretation interval? Indicate correct interpretations.","code":""},{"path":"practice-problems-10.html","id":"practice-problems-10","chapter":"20 Practice Problems 10","heading":"20 Practice Problems 10","text":"-class Midterm!!","code":""},{"path":"practice-problems-11.html","id":"practice-problems-11","chapter":"21 Practice Problems 11","heading":"21 Practice Problems 11","text":"","code":""},{"path":"practice-problems-11.html","id":"problem-1-extrasensory-perception-esp","chapter":"21 Practice Problems 11","heading":"21.0.1 Problem 1: Extrasensory Perception (ESP)","text":"ESP test, one person writes one letters , B, C, D, E tries telepathically communicate choice partner. partner tries guess letter selected.(c). sample proportion correct provide greatest evidence people ESP: (assume sample size every case.)","code":""},{"path":"practice-problems-11.html","id":"problem-2-sleep-vs-caffeine","chapter":"21 Practice Problems 11","heading":"21.0.2 Problem 2: Sleep vs Caffeine","text":"experiment, students given words memorize, randomly assigned either take 90 minute nap take caffeine pill. couple hours later, tested recall ability. wish test see sample provides evidence difference mean number words people can recall depending whether take nap caffeine.Answer:\\[H_0: \\mu_1 = \\mu_2\\]\n\\[H_a: \\mu_1 \\neq \\mu_2\\]","code":""},{"path":"practice-problems-11.html","id":"problem-3-hand-dominance-and-gender","chapter":"21 Practice Problems 11","heading":"21.1 Problem 3: Hand Dominance and Gender","text":"Researchers curious find significant difference proportion left-handed individuals males females. conduct survey among sample population determine hand dominance gender.Given collected data, answer following questions.(). proportion males left-handed?Answer:(b). proportion females right-handed?Answer:(c). Among left-handed person survey, proportion male?Answer:(d). Formulate null alternative hypotheses testing whether proportion left-handed individuals males females different.Answer:Null Hypothesis \\(\\left(H_0\\right)\\) : proportion left-handed individuals males females.","code":""},{"path":"practice-problems-12.html","id":"practice-problems-12","chapter":"22 Practice Problems 12","heading":"22 Practice Problems 12","text":"","code":""},{"path":"practice-problems-12.html","id":"problem-1-revisited","chapter":"22 Practice Problems 12","heading":"22.0.1 Problem 1 Revisited:","text":"Answer:Answer:","code":""},{"path":"practice-problems-12.html","id":"problem-2-sleep-or-caffeine-for-memory","chapter":"22 Practice Problems 12","heading":"22.1 Problem 2: Sleep or Caffeine for Memory","text":"experiment, 24 students given words memorize, randomly assigned take 90 minute nap take caffeine pill (12 group). tested recall ability. test see sample provides evidence difference mean number words people can recall depending whether take nap caffeine. hypotheses :\\[\nH_0: \\mu_S - \\mu_C = 0 \\ \\ H_A: \\mu_S - \\mu_C \\neq 0\n\\]sample mean difference \\(\\bar{x}_S - \\bar{x}_C = 3\\). want know difference sample means statistically discernible.","code":""},{"path":"practice-problems-12.html","id":"a-explain-how-to-generate-a-randomization-distribution-for-barx_s---barx_c-that-is-consistent-with-h_0-mu_s---mu_c-0.","chapter":"22 Practice Problems 12","heading":"22.1.0.1 (a) Explain how to generate a randomization distribution for \\(\\bar{x}_S - \\bar{x}_C\\) that is consistent with \\(H_0: \\mu_S - \\mu_C = 0\\).","text":"","code":""},{"path":"practice-problems-12.html","id":"b-navigate-to-the-statkey-website.","chapter":"22 Practice Problems 12","heading":"22.1.0.2 (b) Navigate to the Statkey website.","text":"Select Test Difference Means option Randomization Hypothesis Tests. Change data set Leniency Smiles Sleep Caffeine Words. Note original sample data sample mean difference 3 words.Generate 1 Sample null randomization distribution. difference average word recall two groups sample? Repeat couple times.Generate 1000 Samples times (get least 3000 resamples). unusual getting difference means 3 words?","code":""},{"path":"practice-problems-12.html","id":"c-compute-the-randomization-p-value","chapter":"22 Practice Problems 12","heading":"22.1.0.3 (c) Compute the randomization p-value","text":"Select Two-Tail button top plot. Change positive x-axis value observed difference 3.0. p-value 2 times proportion resamples difference 3 . p-value?","code":""},{"path":"practice-problems-12.html","id":"d-interpret-conclusion","chapter":"22 Practice Problems 12","heading":"22.1.0.4 (d) Interpret + Conclusion","text":"Interpret p-value. p-value support alternative hypothesis (think difference means 3 statistically discernible) inconclusive? Explain.","code":""},{"path":"practice-problems-12.html","id":"e-redo-in-rstudio","chapter":"22 Practice Problems 12","heading":"22.1.0.5 (e) Redo in Rstudio","text":"First get data Lock website check important summary stats:Table 22.1: Summary Statistics Words Recalled Treatment GroupThen load CarletonStats package run permTest(y ~ x, data=) command y quantitative (0/1 coded) response x defines two groups comparing.observed difference reported -3?p-value? Statkey p-value? neighbors p-value? ?","code":"\nSleepCaffeine <- read.csv(\"http://math.carleton.edu/Stats215/Textbook/SleepCaffeine.csv\")\n# Create a boxplot using ggplot2\nggplot(SleepCaffeine, aes(x = Group, y = Words)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Words by Group\")\n# Summary statistics using dplyr for 'Words'\nSleepCaffeine %>%\n  group_by(Group) %>%\n  summarize(\n    min = min(Words, na.rm = TRUE),\n    q1 = quantile(Words, 0.25, na.rm = TRUE),\n    median = median(Words, na.rm = TRUE),\n    mean = mean(Words, na.rm = TRUE),\n    q3 = quantile(Words, 0.75, na.rm = TRUE),\n    max = max(Words, na.rm = TRUE),\n    sd = sd(Words, na.rm = TRUE)\n  )  %>% knitr::kable(caption=\"Summary Statistics of Words Recalled by Treatment Group\")\nset.seed(123)\nlibrary(CarletonStats)\npermTest(Words ~ Group, data=SleepCaffeine)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  Caffeine :  12.25      Sleep :  15.25 \n Observed difference: -3 \n\n Mean of permutation distribution: 0.01573 \n Standard error of permutation distribution: 1.49817 \n P-value:  0.0492 \n\n    *-------------*"},{"path":"practice-problems-12.html","id":"problem-3-resident-vs-non-resident-tuition","chapter":"22 Practice Problems 12","heading":"22.2 Problem 3: Resident vs Non-resident Tuition","text":"lab manual data set Tuition2006 random sample state colleges universities U.S. want know average tuition charged non-residents higher residents state colleges universities:\\[\nH_0: \\mu_{Non-res} - \\mu_{Res} = 0 \\ \\ H_A: \\mu_{Non-res} - \\mu_{Res} > 0\n\\]","code":""},{"path":"practice-problems-12.html","id":"a-paired-data","chapter":"22 Practice Problems 12","heading":"22.2.0.1 (a) Paired Data","text":"Read data. Note case (school) response value resident non-resident tuition variables. makes paired data example. Contrast word recall example case (student) one response (word recall) treatment (caffeine/sleep).","code":"\ntuition <- read.csv(\"http://math.carleton.edu/Stats215/RLabManual/Tuition2006.csv\")\nhead(tuition)  X        Institution  Res NonRes  Diff\n1 1 Univ of Akron (OH) 4200   8800 -4600\n2 2  Athens State (AL) 1900   3600 -1700\n3 3    Ball State (IN) 3400   8600 -5200\n4 4  Bloomsburg U (PA) 3200   7000 -3800\n5 5     UC Irvine (CA) 3400  12700 -9300\n6 6 Central State (OH) 2600   5700 -3100"},{"path":"practice-problems-12.html","id":"b-permutation-test-for-paired-data","chapter":"22 Practice Problems 12","heading":"22.2.0.2 (b) Permutation test for paired data","text":"Let’s compute difference non-resident resident tuition (NR minus R):Table 22.2: Summary Statistics Difference Residential Non-residential TuitionWhat average difference tuition costs?observed mean difference statistically significant? test use command permTestPaired:alt greater used function permTestPaired(~ B) computes paired differences “” minus “B”.p-value test?Answer: Less 0.0001Is observed mean difference statistically significant?Answer: Yes, observed mean difference least $3584 rarely occur just chance provides us strong evidence mean tuition amount non-residents higher residents population state colleges universities (2006).","code":"\nlibrary(dplyr)\ntuition <- tuition %>%\n  mutate(diff = NonRes - Res)\n\n# Summary statistics of 'diff'\ntuition %>%\n  summarize(\n    min = min(diff, na.rm = TRUE),\n    q1 = quantile(diff, 0.25, na.rm = TRUE),\n    median = median(diff, na.rm = TRUE),\n    mean = mean(diff, na.rm = TRUE),\n    q3 = quantile(diff, 0.75, na.rm = TRUE),\n    max = max(diff, na.rm = TRUE),\n    sd = sd(diff, na.rm = TRUE)\n  ) %>% knitr::kable(caption=\"Summary Statistics of Difference in Residential and Non-residential Tuition\")\n# Histogram of 'diff'\nggplot(tuition, aes(x = diff)) +\n  geom_histogram(binwidth = 1300, fill = \"turquoise\", color = \"black\") +\n  labs(title = \"Histogram of Tuition Differences\", x = \"Difference (NonRes - Res)\", y = \"Frequency\")\nset.seed(123)\npermTestPaired(NonRes ~ Res,data = tuition, alt = \"greater\")\n    ** Permutation test **\n\n Permutation test with alternative: greater \n Observed mean\n  NonRes :  2821.053     Res :  6405.263 \n Observed difference: 3584.211 \n\n Mean of permutation distribution: 4.69679 \n Standard error of permutation distribution: 950.3981 \n P-value:  1e-04 \n\n    *-------------*"},{"path":"practice-problems-12.html","id":"problem-4-evaluating-drugs-to-fight-cocaine-addition","chapter":"22 Practice Problems 12","heading":"22.3 Problem 4: Evaluating Drugs to Fight Cocaine Addition","text":"randomized experiment treating cocaine addiction, 48 cocaine addicts trying quit randomly assigned take either desipramine (new drug), Lithium (existing drug). response variable whether person relapsed (means person unable break cycle addiction returned using cocaine.) testing see desipramine better lithium treating cocaine addiction. results shown two-way table.","code":""},{"path":"practice-problems-12.html","id":"a-using-p_d-for-the-true-proportion-of-desipramine-users-who-relapse-and-p_l-for-the-true-proportion-of-lithium-users-who-relapse-write-the-null-and-alternative-hypotheses.","chapter":"22 Practice Problems 12","heading":"22.3.0.1 (a) Using \\(p_D\\) for the true proportion of desipramine users who relapse and \\(p_L\\) for the true proportion of lithium users who relapse, write the null and alternative hypotheses.","text":"Answer: \\(H_0: p_D - p_L =0\\) vs. \\(H_A: p_D - p_L < 0\\)","code":""},{"path":"practice-problems-12.html","id":"b-compute-the-appropriate-sample-statistic-needed-to-assess-the-hypotheses-above.","chapter":"22 Practice Problems 12","heading":"22.3.0.2 (b) Compute the appropriate sample statistic needed to assess the hypotheses above.","text":"Answer: see \\(\\hat{p}_D = \\dfrac{10}{24} = 0.417\\) \\(\\hat{p}_L = \\dfrac{18}{24} = 0.75\\) \\(\\hat{p}_D -\\hat{p}_L = 0.417 - 0.75 = -0.333\\). sure compute difference since need one number (observed difference) test hypotheses, two separate numbers. also compute difference \\(L-D\\) get +0.333.","code":""},{"path":"practice-problems-12.html","id":"c-how-might-we-compute-a-randomization-sample-for-this-data","chapter":"22 Practice Problems 12","heading":"22.3.0.3 (c) How might we compute a randomization sample for this data?","text":"Answer: Since drug doesn’t matter, combine 48 patients together see 28 relapsed 20 didn’t. see happens random chance, randomly divide two groups compute difference proportions relapses two groups. difference proportions statistic.","code":""},{"path":"practice-problems-12.html","id":"d-navigate-to-the-statkey-website.","chapter":"22 Practice Problems 12","heading":"22.3.0.4 (d) Navigate to the Statkey website.","text":"Select Test Difference Proportions option Randomization Hypothesis Tests. Click Edit Data let Group 1 “Desipramine” 2 “Lithium”, enter relapse counts 10 18 sample sizes 24. Check null hypothesis matches (). Generate couple thousand samples. Describe resulting distribution. centered?Answer: resulting distribution, shown Figure 1, bell-shaped centered value null hypothesis, zero.","code":""},{"path":"practice-problems-12.html","id":"e-compute-and-interpret-the-p-value-for-this-test.","chapter":"22 Practice Problems 12","heading":"22.3.0.5 (e) Compute and interpret the p-value for this test.","text":"Answer: left-tail test computing difference D - L, see StatKey p-value (proportion randomization samples difference -.333 smaller) 2 (Figure 1). 2% time see least 33% fewer relapse cases using despramine lithium just due chance difference relapse rates two treatments.Note two key features “context” interpretation 2%: assumes null true (treatment difference) uses observed statistic (data) used compute p-value (rate despramine relapse .33 rate lithium).","code":""},{"path":"practice-problems-12.html","id":"f-make-a-formal-decision-reject-or-not-using-a-5-significance-level-then-restate-your-conclusion-in-context-for-the-problem-do-not-use-words-like-reject-or-hypothesis.","chapter":"22 Practice Problems 12","heading":"22.3.0.6 (f) Make a formal decision (reject or not) using a 5% significance level, then restate your conclusion in context for the problem (do not use words like “reject” or “hypothesis”).","text":"Answer: reject null hypothesis since p-value 2% less 5%. can conclude despramine better helping people kick cocaine habit.\nNote “context” conclusion: Just state conclusion english, need talk value p-value “just chance.”","code":""},{"path":"practice-problems-12.html","id":"h-use-statkey-to-compute-and-interpret-a-95-bootstrap-confidence-interval-for-the-difference-in-the-relapse-proportion-for-the-two-treatments.-explain-how-this-ci-agrees-with-your-test-conclusion-in-f.","chapter":"22 Practice Problems 12","heading":"22.3.0.7 (h) Use Statkey to compute and interpret a 95% bootstrap confidence interval for the difference in the relapse proportion for the two treatments. Explain how this CI agrees with your test conclusion in (f).","text":"Answer: 95% confident relapse rate despramine 8.3 58.3 percent less relapse rate lithium. completely agrees test conclusion despramine better treatment cocaine addiction. (Figure 2 shows bootstrap distribution centered sample difference -0.333.)","code":""},{"path":"practice-problems-13.html","id":"practice-problems-13","chapter":"23 Practice Problems 13","heading":"23 Practice Problems 13","text":"","code":""},{"path":"practice-problems-13.html","id":"problem-1-cost-per-page-vs-price-of-inkjet-printers","chapter":"23 Practice Problems 13","heading":"23.1 Problem 1: Cost per page vs price of Inkjet printers","text":"association CostColor Price appears strong! conduct permutation test. Let \\(\\rho\\) denote true correlation two variables.\\[H_0: \\rho=0 \\text { versus } H_A: \\rho \\neq 0\\]","code":"\nlibrary(ggplot2)\ninkjet <- read.csv(\"https://www.lock5stat.com/datasets2e/InkjetPrinters.csv\") \nggplot(data = inkjet, aes(x = Price, y = CostColor)) + \n     geom_point(shape = 19) +\n     labs(title = \"Price and Cost to print a page in Color\",\n          x = \"Price (in dollars)\",\n          y = \"Cost per page (in cents)\") +\n     theme_minimal()\nlibrary(CarletonStats)\npermTestCor(CostColor~Price, data= inkjet)"},{"path":"practice-problems-13.html","id":"a-observation-and-conclusion","chapter":"23 Practice Problems 13","heading":"23.1.1 (a) Observation and Conclusion","text":"observed correlation? conclusion draw test?Answer: Since p-value less significance level, means observed correlation -0.6502 highly unlikely occur just random chance null hypothesis. case, reject null hypothesis conclude statistically discernible non-zero population correlation cost color price inkjet printers.","code":""},{"path":"practice-problems-13.html","id":"problem-2-new-teaching-method-effectiveness","chapter":"23 Practice Problems 13","heading":"23.2 Problem 2: New Teaching Method Effectiveness","text":"school testing new teaching method math. randomly assign 40 students either new method (NM) traditional method (TM), 20 group. 3 months, students take standardized math test. want test difference mean test scores NM TM groups. hypotheses :\\[H_0: \\mu_{N M}-\\mu_{T M}=0 \\mathrm{H}_A: \\mu_{NM} - \\mu_{TM} \\neq 0\\]\nsample mean difference \\(\\bar{x}_{NM} - \\bar{x}_{TM} = 8.9\\). want know difference sample means statistically discernible.","code":""},{"path":"practice-problems-13.html","id":"a-randomization-distribution","chapter":"23 Practice Problems 13","heading":"23.2.1 (a) Randomization Distribution","text":"Describe generate randomization distribution \\(\\bar{x}_{NM} - \\bar{x}_{TM}\\) consistent \\(H_0: \\mu_{NM} - \\mu_{TM} = 0\\).Answer: generate randomization distribution sample proportion difference, randomly reassign teaching method (new traditional) classes. null hypothesis, proportion students passing either teaching method. reassignment, compute sample proportion difference plot dotplot.","code":""},{"path":"practice-problems-13.html","id":"b-calculating-the-p-value","chapter":"23 Practice Problems 13","heading":"23.2.1.1 (b) Calculating the p-value","text":"Using statistical software, generate randomization distribution difference means calculate p-value two-tailed test. observed difference 8.9 points statistically discernible?Answer: p-value proportion resamples difference 8.9 . Depending generated randomization distribution, p-value 0.0002. means interpreted terms likely observe difference 8.9 greater null hypothesis, 0.02%.","code":"\nlibrary(CarletonStats)\nteaching <- read_csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/teaching_method.csv\")\npermTest(Math_Test_Score~Group, data= teaching)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  New_Method :  91.05    Traditional_Method :  82.15 \n Observed difference: 8.9 \n\n Mean of permutation distribution: -0.01886 \n Standard error of permutation distribution: 1.75017 \n P-value:  1e-04 \n\n    *-------------*"},{"path":"practice-problems-13.html","id":"c-interpretation-and-conclusion","chapter":"23 Practice Problems 13","heading":"23.2.1.2 (c) Interpretation and Conclusion","text":"Interpret p-value state conclusion regarding difference mean test scores new teaching method traditional teaching method groups.Answer: Since p-value less chosen significance level (e.g., 0.05), results statistically discernible, reject null hypothesis favor alternative. indicate evidence suggesting new teaching method effective traditional method.","code":""},{"path":"practice-problems-13.html","id":"problem-3-type-i-and-type-ii-error-rates","chapter":"23 Practice Problems 13","heading":"23.3 Problem 3: Type I and Type II Error Rates","text":"Consider example new teaching method compared traditional teaching method. Suppose school administration wants minimize chances making Type Type II errors deciding whether adopt new teaching method.","code":""},{"path":"practice-problems-13.html","id":"a-type-i-error","chapter":"23 Practice Problems 13","heading":"23.3.1 (a) Type I Error","text":"Explain Type error context example, describe consequences making error.Answer: Type error occurs reject null hypothesis ’s actually true. context, means conclude new teaching method effective traditional method , reality, difference. consequences making Type error include investing time resources new teaching method isn’t actually effective, leading inefficient allocation resources.","code":""},{"path":"practice-problems-13.html","id":"b-type-ii-error","chapter":"23 Practice Problems 13","heading":"23.3.2 (b) Type II Error","text":"Explain Type II error context example, describe consequences making error.Answer: Type II error occurs fail reject null hypothesis ’s actually false. context, means conclude difference new teaching method traditional method , reality, new method effective. consequences making Type II error include missing opportunity improve students’ learning outcomes adopting effective teaching method.","code":""},{"path":"practice-problems-13.html","id":"c-adjusting-the-significance-level","chapter":"23 Practice Problems 13","heading":"23.3.3 (c) Adjusting the Significance Level","text":"school administration believes making Type error much worse making Type II error, adjustments made significance level account ? Explain reasoning.Answer: decrease chance making Type error, school administration choose smaller significance level, 0.01 instead typical 0.05. using smaller significance level, require stronger evidence (smaller p-value) reject null hypothesis, thus reducing probability making Type error.","code":""},{"path":"practice-problems-13.html","id":"d-balancing-error-rates","chapter":"23 Practice Problems 13","heading":"23.3.4 (d) Balancing Error Rates","text":"Discuss school administration balance Type Type II error rates evaluating effectiveness new teaching method. factors consider?Answer: Balancing Type Type II error rates involves considering consequences type error desired level confidence results. administration weigh risks benefits adopting new teaching method versus maintaining traditional method. also consider factors cost feasibility implementing new method, well potential impact student learning outcomes. Ultimately, administration choose significance level sample size balance risks associated Type Type II errors taking account practical constraints priorities.","code":""},{"path":"practice-problems-13.html","id":"extra-problem-4-job-interview-success","chapter":"23 Practice Problems 13","heading":"23.4 (Extra) Problem 4: Job Interview Success","text":"study investigated success rate job applicants used career coaching service (CCS) compared didn’t (NCCS). 120 applicants, 60 used CCS 60 . want test difference proportion successful applicants CCS NCCS groups. 60 applicants used career coaching service (CCS), 42 successful 18 unsuccessful. 60 applicants use career coaching service (NCCS), 30 successful 30 unsuccessful. hypotheses :\\[H_0: p_{C C S}-p_{N C C S}=0 H_A: p_{C C S}-p_{N C C S} \\neq 0\\]\nsample proportion difference \\(\\hat{p}{CCS} - \\hat{p}{NCCS} = 0.20\\). want know difference sample proportions statistically discernible.Randomization Distribution\nDescribe generate randomization distribution \\(\\hat{p}_{CCS} - \\hat{p}_{NCCS}\\) consistent \\(H_0: p_{CCS} - p_{NCCS} = 0\\).Answer: generate randomization distribution sample proportion difference, randomly reassign group (CCS NCCS) job applicants. null hypothesis, proportion successful applicants groups. reassignment, compute sample proportion difference plot dotplot.Calculating p-valueUsing statistical software, generate randomization distribution difference proportions calculate p-value two-tailed test. observed difference 0.20 statistically discernible?Answer: Using Statkey generate randomization distribution difference proportions observing p-value two-tailed test, can compare p-value chosen significance level (e.g., 0.05) determine observed difference 0.20 statistically discernible. p-value less significance level, observed difference statistically discernible; otherwise, . p-value based randomization distribution null hypothesis \\(2 \\times 0.018 = 0.036\\). , observed difference 0.020 statistically discernible.Interpretation Conclusion\nInterpret p-value state conclusion regarding difference proportion successful job applicants CCS NCCS groups.Answer: Since p-value less significance level, means observed difference 0.20 occur low chance null hypothesis. case, reject null hypothesis conclude statistically discernible difference proportion successful job applicants CCS NCCS groups.","code":""},{"path":"practice-problems-14.html","id":"practice-problems-14","chapter":"24 Practice Problems 14","heading":"24 Practice Problems 14","text":"","code":""},{"path":"practice-problems-14.html","id":"problem-1-gender-stereotypes-in-children---study-4","chapter":"24 Practice Problems 14","heading":"24.1 Problem 1: Gender stereotypes in children - study 4","text":"data example comes study 4 described Science article: https://www.science.org/doi/10.1126/science.aah6524. study involved asking children interest level game researcher described “children really, really smart.” higher value variable interest, interested child playing game.","code":"\nstudy4 <- read.csv(\"http://math.carleton.edu/kstclair/data/Stereo4.csv\")\nhead(study4)    study subj gender   age    interest race     race2\n1 Study 4   65   girl age 6  0.37953534    5     white\n2 Study 4   66   girl age 6 -0.78071539    5     white\n3 Study 4   67   girl age 6 -0.47631654    5     white\n4 Study 4   68   girl age 6 -0.07234632    5     white\n5 Study 4   69    boy age 6 -0.70319450    6 non-white\n6 Study 4   70   girl age 6  0.52467564    5     white\n  eduave income        ses        age2\n1     16  90000 -0.1543908 age 6 and 7\n2     16 125000  0.2298424 age 6 and 7\n3     18  25000 -0.3446883 age 6 and 7\n4     17 125000  0.4914816 age 6 and 7\n5     19 125000  1.0147600 age 6 and 7\n6     12  65000 -1.4753998 age 6 and 7"},{"path":"practice-problems-14.html","id":"a-interest-in-5-year-olds---test","chapter":"24 Practice Problems 14","heading":"24.1.0.1 (a) Interest in 5 year olds - test","text":"Let’s compare mean interest level 5 year old boys girls. Generate randomization distribution test:\\[\nH_0: \\mu_{B5} - \\mu_{G5} = 0 \\ \\ H_0: \\mu_{B5} - \\mu_{G5} \\neq 0\n\\]SE randomization distribution?z-score observed difference means using distribution? Interpret value.Answer: distribution center 0 SE 0.26. z-score \n\\[\nz = \\dfrac{-0.13341 - 0}{0.26051} = -0.51\n\\]\nmeans observed difference -0.133 0.51 SEs hypothesized difference 0.large small observed difference sample means need reject null hypothesis using 5% significance level.Answer: Since distribution bell-shaped, can use fact 5% sample differences 2 SE’s /center difference 0. sample difference extreme lead two-sided p-value less significance level 5%. data, 2 SE’s sample difference 0.521 observed difference extreme 0.521 lead rejecting null hypothesis difference.","code":"\nlibrary(CarletonStats)\nlibrary(ggplot2)\nlibrary(dplyr)\nstudy4age5 <- filter(study4, age2 == \"age 5\")\nggplot(study4age5, aes(x=gender, y=interest)) + \n  geom_boxplot()\npermTest(interest ~ gender, data = study4age5)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  -0.1043526      girl :  0.02905667 \n Observed difference: -0.13341 \n\n Mean of permutation distribution: -0.00092 \n Standard error of permutation distribution: 0.263 \n P-value:  0.6145 \n\n    *-------------*\n-0.13341/0.26051[1] -0.5121109\n2*0.26051[1] 0.52102"},{"path":"practice-problems-14.html","id":"b-interest-in-5-year-olds---ci","chapter":"24 Practice Problems 14","heading":"24.1.0.2 (b) Interest in 5 year olds - CI","text":"Consider 95% (bootstrap) CI true difference mean interest \\(\\mu_{B5} - \\mu_{G5}\\).interval contain difference 0?Compute bootstrap distribution. CI capture 0?bootstrap SE? similar randomization distribution SE?","code":"\nset.seed(7)\nboot(interest ~ gender, data = study4age5)\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : boy - girl = -0.13341 \n Mean of bootstrap distribution: -0.13776 \n Standard error of bootstrap distribution: 0.25939 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-0.6459180  0.3652884 \n\n        *--------------*"},{"path":"practice-problems-14.html","id":"c-interest-in-6-and-7-year-olds---test","chapter":"24 Practice Problems 14","heading":"24.1.0.3 (c) Interest in 6 and 7 year olds - test","text":"Redo part () age group age 6 7.SE randomization distribution?z-score observed difference means using distribution? Interpret value.Answer: distribution center 0 SE 0.225. z-score \\[\nz = \\dfrac{0.53505 - 0}{0.22539 } = 2.37\n\\]\nmeans observed difference 0.535 2.37 SEs hypothesized difference 0.large small observed difference sample means need reject null hypothesis using 5% significance level.Answer: Since distribution bell-shaped, can use fact 5% sample differences 2 SE’s /center difference 0. sample difference extreme lead two-sided p-value less significance level 5%. data, 2 SE’s sample difference 0.451 observed difference extreme 0.451 lead rejecting null hypothesis difference.","code":"\nstudy4age67 <- filter(study4, age2 == \"age 6 and 7\")\nggplot(study4age67, aes(x=gender, y=interest)) + \n  geom_boxplot()\npermTest(interest ~ gender, data = study4age67)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  0.2163512   girl :  -0.3186948 \n Observed difference: 0.53505 \n\n Mean of permutation distribution: -0.00312 \n Standard error of permutation distribution: 0.22035 \n P-value:  0.0112 \n\n    *-------------*\n0.53505/0.22539[1] 2.373885\n2*0.22539[1] 0.45078"},{"path":"practice-problems-14.html","id":"d-interest-in-6-and-7-year-olds---ci","chapter":"24 Practice Problems 14","heading":"24.1.0.4 (d) Interest in 6 and 7 year olds - CI","text":"Redo part (b) 6 7 year olds.interval contain difference 0?Compute bootstrap distribution. CI capture 0?bootstrap SE? similar randomization distribution SE?","code":"\nboot(interest ~ gender, data = study4age67)\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : boy - girl = 0.53505 \n Mean of bootstrap distribution: 0.53468 \n Standard error of bootstrap distribution: 0.20659 \n\n Bootstrap percentile interval\n     2.5%     97.5% \n0.1259895 0.9348764 \n\n        *--------------*"},{"path":"practice-problems-14.html","id":"e-interest-in-5-year-olds","chapter":"24 Practice Problems 14","heading":"24.1.0.5 (e) Interest in 5 year olds","text":"Redo randomization test bootstrap CI 5 year olds, time omit outlier boy case low interest level. Recall use command:omit case, add argument subset = -39 permTest boot commands used () (b).observed difference get closer 0 case omitted? Explain changes.SEs distributions (bootstrap randomization) get smaller larger case omitted? Explain change.Compute z-score observed difference means using randomization distribution. value futher closer z-score 0 case omitted? Explain changes.p-value get smaller larger (doesn’t change) case omitted? Explain changes.","code":"\nggplot(study4age5, aes(x=gender, y=interest)) + \n  geom_boxplot()\n# Identify which rows have 'interest' less than -2 using dplyr\nwhich(study4age5$interest < -2)[1] 39\nset.seed(7)\npermTest(interest ~ gender, data = study4age5, subset = -39)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  0.01417256      girl :  0.02905667 \n Observed difference: -0.01488 \n\n Mean of permutation distribution: -0.00265 \n Standard error of permutation distribution: 0.2469 \n P-value:  0.9516 \n\n    *-------------*\nboot(interest ~ gender, data = study4age5, subset = -39)\n    ** Bootstrap interval for difference of mean \n\n Observed difference of mean : boy - girl = -0.01488 \n Mean of bootstrap distribution: -0.01565 \n Standard error of bootstrap distribution: 0.23826 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-0.4751690  0.4520149 \n\n        *--------------*"},{"path":"practice-problems-15.html","id":"practice-problems-15","chapter":"25 Practice Problems 15","heading":"25 Practice Problems 15","text":"","code":""},{"path":"practice-problems-15.html","id":"problem-1-student-survey","chapter":"25 Practice Problems 15","heading":"25.1 Problem 1: Student Survey","text":"example explores survey dataset MASS package, focus Height Age variables. First, let’s examine survey dataset, paying special attention Height Age:","code":"\nsurvey <- MASS::survey # load the data\nsummary(survey$Age)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.75   17.67   18.58   20.37   20.17   73.00 \nsummary(survey$Height)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  150.0   165.0   171.0   172.4   180.0   200.0      28 "},{"path":"practice-problems-15.html","id":"a.-proportion-below-a-given-value","chapter":"25 Practice Problems 15","heading":"25.1.1 (a). Proportion Below a Given Value","text":"Q1: proportion individuals height 160 cm, based sample?Hint: Calculate mean standard deviation Height variable first.","code":"\n# Mean and standard deviation for Height\nHeight_mean <- mean(survey$Height, na.rm = TRUE)\nHeight_sd <- sd(survey$Height, na.rm = TRUE)\n\n# Proportion below 160 cm\npnorm(160, mean = Height_mean, sd =Height_sd)[1] 0.1043305"},{"path":"practice-problems-15.html","id":"b.-determining-a-specific-percentile","chapter":"25 Practice Problems 15","heading":"25.1.2 (b). Determining a Specific Percentile","text":"Q2: age cutoff lower 75% sample distribution?Hint: Determine mean standard deviation Age variable find age 75th percentile.","code":"\n# Mean and standard deviation for Age\nage_mean <- mean(survey$Age, na.rm = TRUE)\nage_sd <- sd(survey$Age, na.rm = TRUE)\n\n# Age at the 75th percentile\nqnorm(0.75, mean = age_mean, sd = age_sd)[1] 24.74139"},{"path":"practice-problems-15.html","id":"c.-calculating-the-middle-95-percentile-for-age","chapter":"25 Practice Problems 15","heading":"25.1.3 (c). Calculating the Middle 95 Percentile for Age","text":"Q3: age cutoffs define middle 95% sample distribution?Hint: Calculate 5th 95th percentiles Age variable find ages bound middle 95% distribution.","code":"\n# Age at the 25th percentile\nage_25th <- qnorm(0.05, mean = age_mean, sd = age_sd)\nage_25th[1] 9.725181\n# Age at the 75th percentile\nage_75th <- qnorm(0.95, mean = age_mean, sd = age_sd)\nage_75th[1] 31.02385"},{"path":"practice-problems-15.html","id":"problem-2-sat-verbal-scores","chapter":"25 Practice Problems 15","heading":"25.2 Problem 2: SAT Verbal scores","text":"Suppose verbal SAT scores population normally distributed mean \\(\\mu=580\\) standard deviation \\(\\sigma = 70\\). \\(X\\) shorthand verbal SAT score, can write \\(X \\sim N(580,70)\\).","code":""},{"path":"practice-problems-15.html","id":"a-what-proportion-of-scores-are-above-650","chapter":"25 Practice Problems 15","heading":"25.2.0.1 (a) What proportion of scores are above 650?","text":"Answer: 15.9% scores 650.","code":"\npnorm(650,mean=580,sd=70) # proportion below[1] 0.8413447\n1-pnorm(650,mean=580,sd=70) # proportion above[1] 0.1586553"},{"path":"practice-problems-15.html","id":"b-what-is-the-25th-percentile-q1","chapter":"25 Practice Problems 15","heading":"25.2.0.2 (b) What is the 25th percentile (Q1)?","text":"Answer: score 533 25th percentile, meaning 25% scores value.","code":"\nqnorm(.25,mean=580,sd=70)[1] 532.7857"},{"path":"practice-problems-15.html","id":"c-what-is-the-iqr-for-verbal-sat-scores-in-this-population-hint-find-q1-and-q3","chapter":"25 Practice Problems 15","heading":"25.2.0.3 (c) What is the IQR for verbal SAT scores in this population? (Hint: find Q1 and Q3)","text":"Answer: 25th percentile (Q1) 533 75th percentile (Q3) 627. IQR normally distributed variable 94 points.","code":"\nq1 <- qnorm(.25,mean=580,sd=70);q1[1] 532.7857\nq3 <- qnorm(.75,mean=580,sd=70);q3[1] 627.2143\nq3-q1[1] 94.42857"},{"path":"practice-problems-15.html","id":"d-what-score-high-or-low-will-be-deemed-an-outlier-according-the-boxplot-rules-for-outliers","chapter":"25 Practice Problems 15","heading":"25.2.0.4 (d) What score, high or low, will be deemed an outlier according the boxplot rules for outliers?","text":"Answer: Using 1.5IQR’s boxplot rule gives lower fence 392 upper fence 768. score 392 768 called outlier according rule.","code":"\n1.5*94[1] 141\nq1 - 1.5*94[1] 391.7857\nq3 + 1.5*94[1] 768.2143"},{"path":"practice-problems-15.html","id":"e-what-percent-of-the-population-will-be-deemed-an-outlier","chapter":"25 Practice Problems 15","heading":"25.2.0.5 (e) What percent of the population will be deemed an outlier?","text":"Answer: need find proportion scores 392 768. symmetric distribution, find 0.004 tails. 0.8% population deemed outliers according boxplot rule.","code":"\npnorm(392,mean=580,sd=70)[1] 0.003618747\n1-pnorm(768,mean=580,sd=70)[1] 0.003618747"},{"path":"practice-problems-15.html","id":"problem-3-standard-normal","chapter":"25 Practice Problems 15","heading":"25.3 Problem 3: Standard Normal","text":"standard normal distribution mean 0 standard deviation 1.","code":""},{"path":"practice-problems-15.html","id":"a-what-percent-of-sat-scores-are-at-least-1-standard-deviation-above-average","chapter":"25 Practice Problems 15","heading":"25.3.0.1 (a) What percent of SAT scores are at least 1 standard deviation above average?","text":"","code":"\npnorm(1)  # proportion below[1] 0.8413447\n1-pnorm(1) # proportion above[1] 0.1586553"},{"path":"practice-problems-15.html","id":"b-how-many-standard-deviations-away-from-average-is-the-25th-percentile-of-sat-scores","chapter":"25 Practice Problems 15","heading":"25.3.0.2 (b) How many standard deviations away from average is the 25th percentile of SAT scores?","text":"Answer: 25th percentile SAT scores (normally distributed values) 0.67 standard deviations average. also find value using answer (1b):\\[\nz = \\dfrac{533 - 580}{70} = -0.67\n\\]","code":"\nqnorm(.25)[1] -0.6744898\n(533 - 580)/70[1] -0.6714286"},{"path":"practice-problems-16.html","id":"practice-problems-16","chapter":"26 Practice Problems 16","heading":"26 Practice Problems 16","text":"","code":""},{"path":"practice-problems-16.html","id":"problem-1-is-divorce-morally-acceptable","chapter":"26 Practice Problems 16","heading":"26.1 Problem 1: Is Divorce Morally Acceptable?","text":"study, find 67% women random sample view divorce morally acceptable. provide evidence 50% women view divorce morally acceptable? standard error estimate assuming null hypothesis true 0.021.","code":""},{"path":"practice-problems-16.html","id":"a-what-are-the-null-and-alternative-hypotheses-for-this-test","chapter":"26 Practice Problems 16","heading":"26.1.0.1 (a) What are the null and alternative hypotheses for this test?","text":"","code":""},{"path":"practice-problems-16.html","id":"b-what-is-the-standardized-test-statistic","chapter":"26 Practice Problems 16","heading":"26.1.0.2 (b) What is the standardized test statistic?","text":"Answer: observed sample proportion 0.67 standard error 0.021. null true, expect sampling distribution sample mean (approximately) normally distributed center 0.50 SE 0.021. standardized score sample proportion \n\\[\nz = \\dfrac{\\textrm{statistic} - \\textrm{null parameter}}{SE} = \\dfrac{0.67 - 0.50}{0.021} = 8.10\n\\]\nobserved proportion 8.1 SEs hypothesized value 0.5.Note randomization distribution look roughly like (observed proportion denoted red X):","code":"\n(0.67 - 0.5)/0.021[1] 8.095238\nlibrary(ggplot2)\n\n# Create a data frame with a sequence of x values\nx_values <- data.frame(x = seq(0.3, 0.7, length.out = 100))\n\n# Use ggplot2 to plot the normal distribution curve and add the red point\nggplot(x_values, aes(x = x)) +\n  stat_function(fun = dnorm, args = list(mean = 0.5, sd = 0.021), color = \"blue\") +\n  geom_point(aes(x = 0.67, y = 0), color = \"red\", shape = \"X\") +\n  xlab(\"sample proportions\") +\n  ylab(\"density\") +\n  theme_minimal()"},{"path":"practice-problems-16.html","id":"c-use-the-normal-distribution-to-find-the-p-value.","chapter":"26 Practice Problems 16","heading":"26.1.0.3 (c) Use the normal distribution to find the p-value.","text":"Answer: can see normal plot , p-value small alternative looking big sample proportions. p-value proportion times get sample proportion big, bigger , 0.67; equivantly, proportion times get sample proportion least 8.1 SEs hypothesized proportion. report p-value less 0.0001.","code":"\n1-pnorm(8.10,0,1)[1] 2.220446e-16"},{"path":"practice-problems-16.html","id":"d-what-is-the-conclusion-of-the-test","chapter":"26 Practice Problems 16","heading":"26.1.0.4 (d) What is the conclusion of the test?","text":"","code":""},{"path":"practice-problems-16.html","id":"e-use-the-normal-distribution-to-find-a-99-confidence-interval-for-the-proportion-of-all-women-who-view-divorce-as-morally-acceptable.-interpret-your-answer.","chapter":"26 Practice Problems 16","heading":"26.1.0.5 (e) Use the normal distribution to find a 99% confidence interval for the proportion of all women who view divorce as morally acceptable. Interpret your answer.","text":"Answer: Without knowing bootstrap SE, best guess randomization distribution SE given 0.021. 99% confidence interval look like:\n\\[\nstatistic \\pm z^*SE = 0.67 \\pm z^* (0.021)\n\\]\n\\(z^*\\) 99% CI corresponds 99.5th percentile (90% middle + 0.5% left tail). \\(z^* = 2.576\\), get 99% confidence interval 0.616 0.724.","code":"\nqnorm(0.995)[1] 2.575829\n0.67 - 2.576*0.021[1] 0.615904\n0.67 + 2.576*0.021[1] 0.724096"},{"path":"practice-problems-16.html","id":"problem-2-do-men-and-women-differ-in-opinions-about-divorce","chapter":"26 Practice Problems 16","heading":"26.2 Problem 2: Do Men and Women Differ in Opinions about Divorce?","text":"study described , find 71% men view divorce morally acceptable. Use information previous example test whether significant difference men women view divorce. standard error difference proportions null hypothesis proportions equal 0.029.","code":""},{"path":"practice-problems-16.html","id":"a-what-are-the-null-and-alternative-hypotheses-for-this-test-1","chapter":"26 Practice Problems 16","heading":"26.2.0.1 (a) What are the null and alternative hypotheses for this test?","text":"Answer: Using notation (1a), except denoting male/female populations, get\\[\nH_0: p_f = p_m \\ \\ H_A: p_f \\neq p_m\n\\]","code":""},{"path":"practice-problems-16.html","id":"b-what-is-the-standardized-test-statistic-1","chapter":"26 Practice Problems 16","heading":"26.2.0.2 (b) What is the standardized test statistic?","text":"Answer: Suppose look difference \\(p_m - p_f\\). observed difference 0.04 (0.71 - 0.67). value 1.4 SEs hypothesized difference 0:\n\\[\nz = \\dfrac{\\textrm{statistic} - \\textrm{null parameter}}{SE} = \\dfrac{(0.71 - 0.67) - 0}{0.029} = 1.379\n\\]Note randomization distribution difference sample proportions look roughly like (observed proportion difference denoted red X):","code":"\n(0.04 - 0)/0.029[1] 1.37931\nlibrary(ggplot2)\n\n# Create a data frame with a sequence of x values\nx_values <- data.frame(x = seq(-0.1, 0.1, length.out = 100))\n\n# Use ggplot2 to plot the normal distribution curve\nggplot(x_values, aes(x = x)) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 0.029), color = \"blue\") +\n  geom_point(aes(x = 0.04, y = 0), color = \"red\", shape = \"X\") +\n  xlab(\"sample proportions\") +\n  ylab(\"density\") +\n  theme_minimal()"},{"path":"practice-problems-16.html","id":"c-use-the-normal-distribution-to-find-the-p-value.-1","chapter":"26 Practice Problems 16","heading":"26.2.0.3 (c) Use the normal distribution to find the p-value.","text":"Answer: two-tail test. Since observed difference less 2 SEs away 0 know (two-tailed) p-value bigger 0.05. see p-value 2(0.084) = 0.168.","code":"\n1-pnorm(1.379,0,1) # proportion above z=1.379[1] 0.08394738\n2*(1-pnorm(1.379,0,1)) # p-value for two-sided[1] 0.1678948"},{"path":"practice-problems-16.html","id":"d-what-is-the-conclusion-of-the-test-1","chapter":"26 Practice Problems 16","heading":"26.2.0.4 (d) What is the conclusion of the test?","text":"","code":""},{"path":"practice-problems-17.html","id":"practice-problems-17","chapter":"27 Practice Problems 17","heading":"27 Practice Problems 17","text":"","code":""},{"path":"practice-problems-17.html","id":"problem-1-movie-goers-are-more-likely-to-watch-at-home","chapter":"27 Practice Problems 17","heading":"27.1 Problem 1: Movie Goers are More Likely to Watch at Home","text":"random sample 500 movie goers January 2013, 320 said likely wait watch new movie comfort home. Compute interpret 95% confidence interval proportion movie goers likely watch new movie home.Answer: see \\(\\hat{p}=\\frac{320}{500}=0.640\\) (keep least 3 decimal spots ensure accuracy SE calculation!) confidence interval given :\\[\\text { Statistic }\\pm z^{*} S E\\]\\[\\begin{array}{l}\n\\hat{p} \\pm z^{*} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\\n0.64 \\pm 1.96 \\cdot \\sqrt{\\frac{0.64(1-0.64)}{500}} \\\\\n0.64 \\pm 0.042\\\\\n(0.598, 0.682)\n\\end{array}\\]","code":""},{"path":"practice-problems-17.html","id":"problem-2-sample-size-and-margin-of-error-for-movie-goers","chapter":"27 Practice Problems 17","heading":"27.2 Problem 2: Sample Size and Margin of Error for Movie Goers","text":"sample size needed example 2 want margin error within ±2%? (Use sample proportion original sample.)Answer:\\[\\begin{array}{l}\n0.02=z^{*} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\\nn=\\left(\\frac{z^{*}}{0.02}\\right)^{2} \\hat{p}(1-\\hat{p})\\\\\\quad =\\left(\\frac{1.96}{0.02}\\right)^{2} 0.64(1-0.64)=2212.76\n\\end{array}\\]sample size needed want margin error within ±2%, use conservative estimate p = 0.5?Answer:\\[n=\\left(\\frac{1.96}{0.02}\\right)^{2} 0.5(1-0.5)=2401\\]","code":""},{"path":"practice-problems-17.html","id":"problem-3-mendels-green-peas","chapter":"27 Practice Problems 17","heading":"27.3 Problem 3: Mendel’s green peas?","text":"One Gregor Mendel’s famous genetic experiments dealt raising pea plants. According Mendel’s genetic theory, certain set conditions proportion pea plants produce smooth green peas p=3/16 (0.1875). sample n=556 plants experiment 108 smooth green peas. provide evidence problem Mendel’s theory proportion different 3/16? Show details test.Answer: testing \\(H_{0}: p=0.1875\\) vs \\(H_{}: p \\neq 0.1875\\) p represents proportion pea plans smooth green peas. sample proportion \\(\\hat{p}=\\frac{108}{556}=0.1942\\) sample size \\(n=556\\). test statistic :\\[z=\\frac{\\text { Statistic }-\\text { Null }}{S E}=\\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}\\left(1-p_{0}\\right)}{n}}}=\\frac{0.1942-0.1875}{\\sqrt{\\frac{0.1875(1-0.1875)}{556}}}=0.405\\]two-tail test, see area right 0.405 normal distribution 0.343 (1-pnorm(0.405)), p-value 2(0.343) = 0.686.R command : 2*(1-pnorm(0.405))","code":""},{"path":"practice-problems-18.html","id":"practice-problems-18","chapter":"28 Practice Problems 18","heading":"28 Practice Problems 18","text":"","code":""},{"path":"practice-problems-18.html","id":"problem-1-change-in-gun-ownership","chapter":"28 Practice Problems 18","heading":"28.1 Problem 1: Change in gun ownership","text":"2016 study described Guardian found random sample US adults 1994 found female rate gun ownership 9%. similar random sample 2015 found rate female gun ownership rose 12%. section 3.2 handout, assumed SE difference two sample proportions 2%. Show SE computed using appropriate SE formula chapter 6. Assume sample sizes 1994 2015 500.Answer:1994 sample proportion \\(\\hat{p}_{1994} = 0.09\\) 2015 sample proportion \\(\\hat{p}_{2015} = 0.12\\) . SE difference two sample proportions confidence interval given :","code":""},{"path":"practice-problems-18.html","id":"problem-2-accuracy-of-lie-detectors","chapter":"28 Practice Problems 18","heading":"28.2 Problem 2: Accuracy of Lie Detectors","text":"Participants study evaluate accuracy lie detectors divided two groups, one group reading true material group reading false material, connected lie detector. groups received electric shocks add stress. two way table indicates whether participants lying telling truth also whether lie detector indicated lying .","code":""},{"path":"practice-problems-18.html","id":"a-are-the-conditions-met-for-using-the-normal-distribution","chapter":"28 Practice Problems 18","heading":"28.2.1 (a) Are the conditions met for using the normal distribution?","text":"","code":""},{"path":"practice-problems-18.html","id":"b-find-the-three-sample-proportions-for-the-proportion-of-times-the-lie-detector-says-the-person-is-lying-the-proportion-for-the-lying-people-the-proportion-for-the-truthful-people-and-the-pooled-proportion.","chapter":"28 Practice Problems 18","heading":"28.2.2 (b) Find the three sample proportions for the proportion of times the lie detector says the person is lying (the proportion for the lying people, the proportion for the truthful people, and the pooled proportion).","text":"","code":""},{"path":"practice-problems-18.html","id":"c-test-to-see-if-there-is-a-difference-in-the-proportion-of-times-the-lie-detector-says-the-person-is-lying-depending-on-whether-the-person-is-lying-or-telling-the-truth.-show-all-details-of-the-hypothesis-test.","chapter":"28 Practice Problems 18","heading":"28.2.3 (c) Test to see if there is a difference in the proportion of times the lie detector says the person is lying, depending on whether the person is lying or telling the truth. Show all details of the hypothesis test.","text":"Answer:testing \\(H_0:p_L = p_N\\) vs \\(H_a:p_L \\neq p_N\\). test statistic \\[z = \\frac{statistic-null}{SE} = \\frac{(\\hat{p}_L - \\hat{p}_N) - 0}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_l} + \\frac{\\hat{p}(1-\\hat{p})}{n_N}}} = \\frac{0.6458 - 0.5625}{\\sqrt{\\frac{0.6042(1-0.6042)}{48}} + \\frac{0.6042*(1-0.6042)}{48}} = 0.834 \\]two-tail test, area right 0.834 normal distribution 0.202 (1-pnorm(0.834)), p-value 2(0.202) = 0.404. R command : 2*(1-pnorm(0.834))fail reject H0 conclude enough evidence lie detector can tell whether person lying telling truth.","code":"\npL_hat = 31/48\npN_hat = 27/48\npooled_p = 58/96\nnL = 48\nnN = 48\nSE = sqrt(pooled_p*(1-pooled_p)*(1/nL + 1/nN))\nz = (pL_hat - pN_hat) / SE\np_value = 2*(1-pnorm(z))\np_value[1] 0.4038223"},{"path":"practice-problems-18.html","id":"d-calculate-a-95-confidence-interval-for-the-difference-in-proportions-of-people-correctly-identified-by-the-lie-detector.","chapter":"28 Practice Problems 18","heading":"28.2.4 (d) Calculate a 95% confidence interval for the difference in proportions of people correctly identified by the lie detector.","text":"95% confidence interval difference proportions (0.0134, 0.4033). 95% confident proportion lying people correctly identified lie detector 1.3% 40% larger proportion lying people correctly identified lie detector.","code":"\npL_hat <- 31/48\npN_hat <- 21/48\nconf_level = 0.95\nz_star = qnorm(1-(1-conf_level)/2)\nSE <- sqrt(pL_hat*(1-pL_hat)/48 + pN_hat*(1-pN_hat)/48)\nmargin_of_error = z_star * SE\nCI_lower = (pL_hat - pN_hat) - margin_of_error\nCI_upper = (pL_hat - pN_hat) + margin_of_error\nCI = c(CI_lower, CI_upper)\nCI[1] 0.01339606 0.40327061"},{"path":"practice-problems-18.html","id":"problem-3-smoking-and-pregnancy-rate","chapter":"28 Practice Problems 18","heading":"28.3 Problem 3: Smoking and Pregnancy Rate?","text":"smoking negatively affect person’s ability become pregnant? study collected data 678 women trying get pregnant. two-way table shows proportion successfully became pregnant first cycle trying smoking status.","code":""},{"path":"practice-problems-18.html","id":"a.-find-a-90-confidence-interval-for-the-difference-in-proportion-of-women-who-get-pregnant-between-smokers-and-non-smokers.-interpret-the-interval-in-context.","chapter":"28 Practice Problems 18","heading":"28.3.1 (a). Find a 90% confidence interval for the difference in proportion of women who get pregnant, between smokers and non-smokers. Interpret the interval in context.","text":"conditions met using normal distribution (least 10 values cell table). see proportion smokers got pregnant 38/135 = 0.281 proportion non-smokers got pregnant 206/543 = 0.379. confidence interval given :\\[statistic \\pm z^* \\cdot SE \\]\n\\[(\\hat{p}_S - \\hat{p}_N) \\pm z^* \\cdot \\sqrt{\\frac{\\hat{p}_S(1- \\hat{p}_S)}{n_S} + \\frac{\\hat{p}_N(1- \\hat{p}_N)}{n_N}} \\]\\[(0.281 - 0.379) \\pm 1.645\\cdot \\sqrt{\\frac{0.281(1-0.281)}{135} + \\frac{0.379(1-0.379)}{543}} \\]\n\\[-0.098 \\pm 0.072 = (-0.170, -0.026) \\]\n90% sure proportion smokers get pregnant first cycle 0.170 0.026 less proportion non-smokers get pregnant first cycle. Note subtracted way, interval positive values, interpretation .","code":""},{"path":"practice-problems-18.html","id":"b.-now-repeat-the-above-analysis-using-the-hypothesis-test-approach.","chapter":"28 Practice Problems 18","heading":"28.3.2 (b). Now, repeat the above analysis using the hypothesis test approach.","text":"testing \\(H_0:p_S = p_{NS}\\) vs \\(H_a:p_S \\neq p_{NS}\\). test statistic :Based p-value, reject \\(H_0\\) conclude difference proportion women get pregnant smokers non-smokers.","code":"\npS_hat = 38/135\npNS_hat = 206/543\npooled_p2 = (38+206)/(135+543)\nnS = 135\nnNS = 543\nSE2 = sqrt(pooled_p2*(1-pooled_p2)*(1/nS + 1/nNS))\nz2 = (pS_hat - pNS_hat) / SE2\np_value2 = 2*(pnorm(z2))\np_value2[1] 0.03394234"},{"path":"practice-problems-19.html","id":"practice-problems-19","chapter":"29 Practice Problems 19","heading":"29 Practice Problems 19","text":"","code":""},{"path":"practice-problems-19.html","id":"problem-1-florida-lakes-ph","chapter":"29 Practice Problems 19","heading":"29.1 Problem 1: Florida Lakes pH","text":"textbook dataset FloridaLakes contains data 53 lakes Florida. want know average pH lakes Florida different neutral value 7.","code":"\nlakes <- read.csv(\"http://www.lock5stat.com/datasets1e/FloridaLakes.csv\")\nhead(lakes)  ID         Lake Alkalinity  pH Calcium Chlorophyll\n1  1    Alligator        5.9 6.1     3.0         0.7\n2  2        Annie        3.5 5.1     1.9         3.2\n3  3       Apopka      116.0 9.1    44.1       128.3\n4  4 Blue Cypress       39.4 6.9    16.4         3.5\n5  5        Brick        2.5 4.6     2.9         1.8\n6  6       Bryant       19.6 7.3     4.5        44.1\n  AvgMercury NumSamples MinMercury MaxMercury\n1       1.23          5       0.85       1.43\n2       1.33          7       0.92       1.90\n3       0.04          6       0.04       0.06\n4       0.44         12       0.13       0.84\n5       1.20         12       0.69       1.50\n6       0.27         14       0.04       0.48\n  ThreeYrStdMercury AgeData\n1              1.53       1\n2              1.33       0\n3              0.04       0\n4              0.44       0\n5              1.33       1\n6              0.25       1"},{"path":"practice-problems-19.html","id":"a-eda","chapter":"29 Practice Problems 19","heading":"29.1.0.1 (a) EDA","text":"Always plot data get summary stats:sample mean standard deviation? Use appropriate notation.Can use t-inference methods pH variable?","code":"\nlibrary(ggplot2)\nggplot(lakes, aes(pH)) + geom_histogram(bins=10, fill = \"lightblue\", color = \"gold\")\nmean(lakes$pH)[1] 6.590566\nsd(lakes$pH)[1] 1.288449"},{"path":"practice-problems-19.html","id":"b-se-for-the-sample-mean","chapter":"29 Practice Problems 19","heading":"29.1.0.2 (b) SE for the sample mean","text":"Answer: estimated SE sample mean \\(SE_{\\bar{x}} = 0.1770\\).","code":"\nsd(lakes$pH)/sqrt(53)[1] 0.1769821"},{"path":"practice-problems-19.html","id":"c-t-test-statistic","chapter":"29 Practice Problems 19","heading":"29.1.0.3 (c) t-test statistic","text":"Using SE (b) compute t-test statistic testing population mean pH equal, , 7. Write hypotheses show t test statistic calculated. Interpret value context.Answer: hypotheses \\(H_0: \\mu = 7\\) vs \\(H_A: \\mu \\neq 7\\). test stat \\[\nt = \\dfrac{6.591 - 7}{1.288/\\sqrt{53}} = -2.3134\n\\]observed mean 6.591 2.3 SEs hypothesized mean 7.","code":"\n(mean(lakes$pH) - 7)/(sd(lakes$pH)/sqrt(53)) [1] -2.31342"},{"path":"practice-problems-19.html","id":"d-one-sample-t-test","chapter":"29 Practice Problems 19","heading":"29.1.1 (d) One-sample t-test","text":"function t.test(x, mu=) can used one sample test comparing sample mean x hypothesized value given mu=. testing whether population mean equal 7 :t test stat given output? Verify matches answer (c), within reasonable rounding error.Answer: test stat -2.31.p-value test? Interpret value.Answer: p-value 0.025. mean pH lakes 7, see sample mean least 2.31 SEs away 7 2.5% time samples 53 lakes.test conclusion?Answer: statistically significant difference observed mean pH 6.591 hypothesized mean 7 (t=-2.31, df=52, p=0.025).","code":"\nt.test(lakes$pH, mu = 7)\n    One Sample t-test\n\ndata:  lakes$pH\nt = -2.3134, df = 52, p-value = 0.02469\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.235425 6.945707\nsample estimates:\nmean of x \n 6.590566 "},{"path":"practice-problems-19.html","id":"e-one-sample-t-confidence-interval","chapter":"29 Practice Problems 19","heading":"29.1.1.1 (e) One-sample t confidence interval","text":"95% confidence interval population mean pH? Interpret CI.Answer: 95% confident mean pH lakes Florida 6.24 6.95.","code":""},{"path":"practice-problems-19.html","id":"f-qt-and-pt","chapter":"29 Practice Problems 19","heading":"29.1.1.2 (f) qt and pt","text":"Answer: two-sided test, p-value twice proportion test stat \\(t=-2.313\\) t-distribution \\(df=53-1=52\\)95% CI, get 97.5th percentile t-distribution","code":"\n2*pt(-2.313,df=52)[1] 0.02471195\nqt(.975,52)[1] 2.006647"},{"path":"practice-problems-19.html","id":"problem-2-nutrition-study","chapter":"29 Practice Problems 19","heading":"29.2 Problem 2: Nutrition Study","text":"dataset NutritionStudy contains data daily calorie intake variables 315 individuals. want know average daily calorie intake different recommended 2000 calories.","code":"\nlibrary(dplyr)\nNutritionStudy <- read.csv(\"https://www.lock5stat.com/datasets2e/NutritionStudy.csv\")\nglimpse(NutritionStudy)Rows: 315\nColumns: 17\n$ ID            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1…\n$ Age           <int> 64, 76, 38, 40, 72, 40, 65, 58, 35, …\n$ Smoke         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", …\n$ Quetelet      <dbl> 21.4838, 23.8763, 20.0108, 25.1406, …\n$ Vitamin       <int> 1, 1, 2, 3, 1, 3, 2, 1, 3, 3, 1, 2, …\n$ Calories      <dbl> 1298.8, 1032.5, 2372.3, 2449.5, 1952…\n$ Fat           <dbl> 57.0, 50.1, 83.6, 97.5, 82.6, 56.0, …\n$ Fiber         <dbl> 6.3, 15.8, 19.1, 26.5, 16.2, 9.6, 28…\n$ Alcohol       <dbl> 0.0, 0.0, 14.1, 0.5, 0.0, 1.3, 0.0, …\n$ Cholesterol   <dbl> 170.3, 75.8, 257.9, 332.6, 170.8, 15…\n$ BetaDiet      <int> 1945, 2653, 6321, 1061, 2863, 1729, …\n$ RetinolDiet   <int> 890, 451, 660, 864, 1209, 1439, 802,…\n$ BetaPlasma    <int> 200, 124, 328, 153, 92, 148, 258, 64…\n$ RetinolPlasma <int> 915, 727, 721, 615, 799, 654, 834, 8…\n$ Gender        <chr> \"Female\", \"Female\", \"Female\", \"Femal…\n$ VitaminUse    <chr> \"Regular\", \"Regular\", \"Occasional\", …\n$ PriorSmoke    <int> 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, …"},{"path":"practice-problems-19.html","id":"a-eda-1","chapter":"29 Practice Problems 19","heading":"29.2.1 (a) EDA","text":"Always plot data get summary stats:","code":"\nlibrary(ggplot2)\nggplot(NutritionStudy, aes(Calories)) + geom_histogram(fill = \"lightblue\", color = \"gold\")\nmean(NutritionStudy$Calories)[1] 1796.655\nsd(NutritionStudy$Calories)[1] 680.3474"},{"path":"practice-problems-19.html","id":"b-se-for-the-sample-mean-1","chapter":"29 Practice Problems 19","heading":"29.2.2 (b) SE for the sample mean","text":"estimated SE sample mean?Answer:","code":"\nn <- length(NutritionStudy$Calories)\nSE <- sd(NutritionStudy$Calories) / sqrt(n)\nSE[1] 38.33324"},{"path":"practice-problems-19.html","id":"c-t-test-statistic-1","chapter":"29 Practice Problems 19","heading":"29.2.3 (c) t-test statistic","text":"Compute t-test statistic testing population mean calorie intake equal, , 2000.Answer:","code":"\nt_stat <- (mean(NutritionStudy$Calories) - 2000) / SE\nt_stat[1] -5.304676"},{"path":"practice-problems-19.html","id":"d-one-sample-t-test-1","chapter":"29 Practice Problems 19","heading":"29.2.4 (d) One-sample t-test","text":"Perform one-sample t-test test whether population mean calorie intake equal 2000 .Answer:","code":"\nt.test(NutritionStudy$Calories, mu = 2000)\n    One Sample t-test\n\ndata:  NutritionStudy$Calories\nt = -5.3047, df = 314, p-value = 2.135e-07\nalternative hypothesis: true mean is not equal to 2000\n95 percent confidence interval:\n 1721.232 1872.077\nsample estimates:\nmean of x \n 1796.655 "},{"path":"practice-problems-19.html","id":"e-one-sample-t-confidence-interval-1","chapter":"29 Practice Problems 19","heading":"29.2.5 (e) One-sample t confidence interval","text":"95% confidence interval population mean calorie intake?Answer:","code":"\nci <- t.test(NutritionStudy$Calories, mu = 2000)$conf.int\nci[1] 1721.232 1872.077\nattr(,\"conf.level\")\n[1] 0.95"},{"path":"practice-problems-19.html","id":"f-qt-and-pt-1","chapter":"29 Practice Problems 19","heading":"29.2.6 (f) qt and pt","text":"Show compute p-value test (d) using pt command. show confidence interval (e) computed qt value.Answer:","code":"\np_value <- 2 * pt(-abs(t_stat), df = n - 1)\np_value[1] 2.135134e-07\nt_star <- qt(0.975, df = n - 1)\nt_star[1] 1.967548"},{"path":"practice-problems-20.html","id":"practice-problems-20","chapter":"30 Practice Problems 20","heading":"30 Practice Problems 20","text":"-class midterm!!","code":""},{"path":"practice-problems-21.html","id":"practice-problems-21","chapter":"31 Practice Problems 21","heading":"31 Practice Problems 21","text":"","code":""},{"path":"practice-problems-21.html","id":"problem-1-api","chapter":"31 Practice Problems 21","heading":"31.1 Problem 1: API","text":"Academic Performance Index (API) computed California schools. number, ranging low 200 high 1000, reflects school’s performance statewide standardized test (http://api.cde.ca.gov). SRS 200 schools interested school’s performance related wealth students. variable growth measures growth API 1999 2000 (API 2000 - API 1999).","code":"\napi <- read.csv(\"http://people.carleton.edu/~kstclair/data/api.csv\")"},{"path":"practice-problems-21.html","id":"a-categorizing-wealth","chapter":"31 Practice Problems 21","heading":"31.1.0.1 (a) Categorizing wealth","text":"Let’s define school “low wealth” 50% students eligible subsidized meals “high wealth” otherwise. can use ifelse command create variable wealth measures :many schools “low” “high” wealth.wealth API growth related?observed difference mean API growth high low wealth schools. Use correct notation.Can use t-inference methods compare mean growths?","code":"\napi$wealth <- ifelse(api$meals > 50, \"low\",\"high\")\ntable(api$wealth)\nhigh  low \n 102   98 \nlibrary(dplyr)\napi %>% group_by(wealth) %>% summarize(mean(growth), sd(growth))# A tibble: 2 × 3\n  wealth `mean(growth)` `sd(growth)`\n  <chr>           <dbl>        <dbl>\n1 high             25.2         28.8\n2 low              38.8         30.0\nboxplot(growth ~ wealth, data=api, xlab=\"API growth (2000 - 1999)\" , horizontal=T)"},{"path":"practice-problems-21.html","id":"b-se-for-the-sample-mean-difference","chapter":"31 Practice Problems 21","heading":"31.1.0.2 (b) SE for the sample mean difference","text":"Answer: SE mean difference 4.1544:\\[\nSD_{\\bar{x}_h - \\bar{x}_l} = \\sqrt{\\dfrac{28.75380^2}{102} + \\dfrac{29.95048^2}{98}} = 4.1544\n\\]","code":"\nsqrt(28.75380^2/102 +  29.95048^2/98)[1] 4.154404"},{"path":"practice-problems-21.html","id":"c-t-test-statistic-2","chapter":"31 Practice Problems 21","heading":"31.1.0.3 (c) t-test statistic","text":"Answer: hypotheses \\(H_0: \\mu_h - \\mu_l = 0\\) vs \\(H_A: \\mu_h - \\mu_l \\neq 0\\). test stat \\[t = \\dfrac{(25.24510 - 38.82653) - 0}{4.154404} = -3.2692\\]observed mean difference 3.3 SEs hypothesized mean difference 0.","code":"\n((25.24510 - 38.82653) - 0)/4.154404 [1] -3.269164"},{"path":"practice-problems-21.html","id":"d-two-sample-t-test","chapter":"31 Practice Problems 21","heading":"31.1.0.4 (d) Two-sample t-test","text":"evidence mean API growth differs low high wealth schools? Give hypotheses test, run t.test(y ~ x, data=) command conduct t-test give p-value conclusion.t test stat given output? Verify matches answer (c), within reasonable rounding error.p-value test? Interpret value.\nClick answerWhat test conclusion?\nClick answer","code":"\nt.test(growth ~ wealth, data=api)\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -3.2692, df = 196.71, p-value = 0.001273\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -21.774321  -5.388544\nsample estimates:\nmean in group high  mean in group low \n          25.24510           38.82653 "},{"path":"practice-problems-21.html","id":"e-consider-outliers","chapter":"31 Practice Problems 21","heading":"31.1.0.5 (e) Consider outliers","text":"boxplot () shows number outliers high wealth group, two cases particular high. Suppose omitted two () extreme cases running test (d). p-value test smaller larger p-value computed part (d)? Explain.","code":""},{"path":"practice-problems-21.html","id":"f-check-outlier-influence","chapter":"31 Practice Problems 21","heading":"31.1.0.6 (f) Check outlier influence","text":"omit cases find row numbers, subset data:t-test stat change omitting two changes? change direction?Check answer anwer part (e)!\nClick answer","code":"\nwhich(api$growth > 120 )[1]  74 119\napi %>% slice(74,119)  # another dplyr package command           cds stype            name                 sname\n1 5.471911e+13     E Lincoln Element    Lincoln Elementary\n2 1.975342e+13     E Washington Elem Washington Elementary\n  snum                   dname dnum       cname cnum flag\n1 5873 Exeter Union Elementary  226      Tulare   53   NA\n2 2543   Redondo Beach Unified  585 Los Angeles   18   NA\n  pcttest api00 api99 target growth sch.wide comp.imp both\n1      98   693   504     15    189      Yes      Yes  Yes\n2     100   745   615      9    130      Yes      Yes  Yes\n  awards meals ell yr.rnd mobility acs.k3 acs.46 acs.core\n1    Yes    50  18   <NA>        9     18     NA       NA\n2    Yes    41  20   <NA>       16     19     30       NA\n  pct.resp not.hsg hsg some.col col.grad grad.sch avg.ed\n1       93      28  23       27       14        8   2.51\n2       81      11  26       32       16       16   2.99\n  full emer enroll api.stu    pw  fpc wealth\n1   91    9    196     177 30.97 6194   high\n2  100    3    391     313 30.97 6194   high\nt.test(growth ~ wealth, data = api, subset = -c(74,119))\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -4.395, df = 174.97, p-value = 1.916e-05\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -23.571116  -8.961945\nsample estimates:\nmean in group high  mean in group low \n          22.56000           38.82653 "},{"path":"practice-problems-21.html","id":"g-95-confidence-interval","chapter":"31 Practice Problems 21","heading":"31.1.0.7 (g) 95% confidence interval","text":"","code":""},{"path":"practice-problems-21.html","id":"h-interpret-two-sample-ci","chapter":"31 Practice Problems 21","heading":"31.1.0.8 (h) Interpret two-sample CI","text":"Using results without two outliers, interpret 95% CI given output. use word ``difference’’ answer.","code":""},{"path":"practice-problems-21.html","id":"problem-2-matched-pairs","chapter":"31 Practice Problems 21","heading":"31.2 Problem 2: Matched Pairs","text":"study conducted determine effect home meter helping diabetics control blood glucose levels. Researchers like determine home meter effective helping patients reduce blood glucose levels. random sample 36 diabetics blood glucose levels measured taught use meter utilized meter 2 weeks. Researchers observed average decrease (- ) blood glucose level 2.78 mmol/liter standard deviation 6.05 mmol/liter. Analysis results shown :","code":"  Sample mean:  2.78 ; sample standard deviation:  6.05 ; sample size: 36\n  Standard error:  1.0083\n  95 percent confidence interval for true mean:  1.0763  , Infinity\n  Hypothesis test H0: mu =  0  Alternative is  greater\n  t statistic =  2.757 ; degrees of freedom =  35 ; p-value= 0.0046"},{"path":"practice-problems-21.html","id":"a-what-conditions-need-to-be-met-by-this-data-to-use-t-inference-procedures","chapter":"31 Practice Problems 21","heading":"31.2.0.1 (a) What conditions need to be met by this data to use \\(t\\) inference procedures?","text":"Answer: moderate sample size \\(n=36\\) need assume observed differences (-) strongly skewed outliers. assumptions met, t-inference procedures may appropriate.","code":""},{"path":"practice-problems-21.html","id":"b-define-the-unknown-parameter-of-interest-be-very-specific-then-state-the-null-and-alternative-hypotheses-for-this-test.-make-sure-your-hypotheses-agree-with-the-output","chapter":"31 Practice Problems 21","heading":"31.2.0.2 (b) Define the unknown parameter of interest (be very specific), then state the null and alternative hypotheses for this test. Make sure your hypotheses agree with the output!","text":"Answer: Let \\(\\mu\\) represent population mean decrease glucose levels measured treatment (- ). positive value \\(\\mu\\) implies home meter effective reducing blood glucose levels. alternative hypothesis (research statement) \\(\\mu\\) greater 0 null statement \\(\\mu\\) equal 0, meaning benefit using treatment.\n\\[\nH_0:  \\mu = 0 \\textrm{ vs. } H_A: \\mu > 0\n\\]","code":""},{"path":"practice-problems-21.html","id":"c-what-is-the-test-statistic-value-for-this-test-what-does-this-value-indicate","chapter":"31 Practice Problems 21","heading":"31.2.0.3 (c) What is the test statistic value for this test? What does this value indicate?","text":"Answer: test stat value 2.757. mean glucose level decrease sample 2.757 SE’s hypothesized mean decrease 0.","code":""},{"path":"practice-problems-21.html","id":"d-is-there-sufficient-evidence-to-claim-that-the-monitor-is-effective-in-helping-patients-reduce-their-blood-glucose-levels","chapter":"31 Practice Problems 21","heading":"31.2.0.4 (d) Is there sufficient evidence to claim that the monitor is effective in helping patients reduce their blood glucose levels?","text":"Answer: reject \\(H_0\\) \\(p\\)-value small. Since P-value 0.3% quite small, can conclude strong evidence use home meters lowers blood glucose levels, average (\\(H_A\\)).","code":""},{"path":"practice-problems-21.html","id":"e-what-type-of-error-1-or-2-could-you-have-made-in-part-d-if-you-did-make-this-error-what-are-its-implications-for-people-with-diabetes","chapter":"31 Practice Problems 21","heading":"31.2.0.5 (e) What type of error (1 or 2) could you have made in part (d)? If you did make this error, what are its implications for people with diabetes?","text":"Answer: Since rejected, may made type 1 error rejecting null actually true. means claimed home meter useful reducing blood glucose levels, average, fact doesn’t reduce levels. People diabetes encouraged use meters (cost insurance company) help control glucose levels see real benefit.","code":""},{"path":"practice-problems-21.html","id":"f-compute-and-interpret-a-95-confidence-interval-for-the-true-average-decrease-in-blood-glucose-levels.-note-that-this-ci-is-not-given-above-the-ci-given-in-the-output-is-a-one-sided-ci.","chapter":"31 Practice Problems 21","heading":"31.2.0.6 (f) Compute and interpret a 95% confidence interval for the true average decrease in blood glucose levels. (Note that this CI is not given above, the CI given in the output is a ``one-sided” CI.)","text":"Answer: 95% CI population mean decrease glucose level \n\\[\n\\bar{x} \\pm t^*_{n-1} \\dfrac{s}{\\sqrt{n}} = 2.78\\pm 2.042 \\dfrac{6.05}{\\sqrt{36}} = 2.78 \\pm 2.017 = (0.72, 4.84)\n\\]\n\\(t^*\\) based 36-1=35 degrees freedom. Using green table, round df 30 get \\(t^*_{30} = 2.042\\). using R command qt(.975,df=35) get exact value \\(t^*_{35}=2.0301\\).\n95% confident , learning use home meter, average decrease blood glucose population 0.72 4.84 mmol/liter.","code":""},{"path":"practice-problems-22.html","id":"practice-problems-22","chapter":"32 Practice Problems 22","heading":"32 Practice Problems 22","text":"","code":""},{"path":"practice-problems-22.html","id":"problem-1-food-preferences","chapter":"32 Practice Problems 22","heading":"32.1 Problem 1: Food Preferences","text":"Suppose survey, 300 1000 individuals preferred beef, 400 preferred chicken, 300 preferred vegetarian meals. researchers, want test hypothesis proportions individuals preferring type meal equal (\\(p_{beef} = p_{chicken} = p_{vegetarian} = \\frac{1}{3}\\)). Conduct appropriate hypothesis test.","code":""},{"path":"practice-problems-22.html","id":"a-what-are-the-null-and-alternate-hypotheses","chapter":"32 Practice Problems 22","heading":"32.1.1 (a) What are the null and alternate hypotheses?","text":"Answer:\\[\\begin{align*}\nH_0 &: p_{\\text{beef}} = p_{\\text{chicken}} = p_{\\text{vegetarian}} = \\frac{1}{3} \\\\\nH_a &: \\text{least one proportion different}\n\\end{align*}\\]","code":"\n# Observed counts\nobserved_counts <- c(300, 400, 300)\n\n# Expected counts\nexpected_counts <- rep(1000 / 3, 3)\n\n# Chi-square test statistic calculation\nchi_square_stat <- sum((observed_counts - expected_counts)^2 / expected_counts)\nchi_square_stat[1] 20"},{"path":"practice-problems-22.html","id":"b-verify-the-above-chi-square-statistics-calculation-by-hand.","chapter":"32 Practice Problems 22","heading":"32.1.2 (b) Verify the above chi-square statistics calculation by hand.","text":"Answer:degrees freedom corresponding test 2 (categories - 1). , p-value can calculated :can also test R using chisq.test function.chi-square test can also performed using randomization approach. setting simulate.p.value = TRUE chisq.test() function, R simulate p-values based permutations data. can especially useful assumptions chi-square test met, expected counts small.setting B = 10000, function use 10,000 permutations compute simulated p-value. method can provide accurate p-value situations traditional method might questionable due small expected counts. output code, R provide chi-square statistic simulated p-value based 10,000 permutations. Since simulated p-value (0.0001) significantly smaller 0.05, suggests null hypothesis rejected favor alternate hypothesis, meaning evidence suggest least one proportion different others.","code":"\np_value <- 1 - pchisq(chi_square_stat, df = 2)\np_value[1] 4.539993e-05\nchisq_test <- chisq.test(x = observed_counts)\nchisq_test\n    Chi-squared test for given probabilities\n\ndata:  observed_counts\nX-squared = 20, df = 2, p-value = 4.54e-05\nset.seed(7)\nchisq_test_simulated <- chisq.test(x = observed_counts, simulate.p.value = TRUE, B = 10000)\nchisq_test_simulated\n    Chi-squared test for given probabilities with\n    simulated p-value (based on 10000 replicates)\n\ndata:  observed_counts\nX-squared = 20, df = NA, p-value = 9.999e-05"},{"path":"practice-problems-22.html","id":"c-write-the-conclusion-of-the-hypothesis-test.","chapter":"32 Practice Problems 22","heading":"32.1.3 (c) Write the conclusion of the hypothesis test.","text":"Answer:","code":""},{"path":"practice-problems-22.html","id":"problem-2-transportation-preferences","chapter":"32 Practice Problems 22","heading":"32.2 Problem 2: Transportation Preferences","text":"Suppose city survey, 200 800 individuals preferred cars, 400 preferred bicycles, 200 preferred public transportation commuting. want test hypothesis proportions individuals preferring type transportation \\(p_{car} = 0.2, p_{bicycle} = 0.6, p_{public} = 0.2\\). Conduct appropriate hypothesis test.","code":""},{"path":"practice-problems-22.html","id":"a-what-are-the-null-and-alternate-hypotheses-1","chapter":"32 Practice Problems 22","heading":"32.2.1 (a) What are the null and alternate hypotheses?","text":"Answer:\\[\\begin{align*}\nH_0 &: p_{\\text{car}} = 0.2, \\quad p_{\\text{bicycle}} = 0.6, \\quad p_{\\text{public}} = 0.2 \\\\\nH_a &: \\text{least one proportion different}\n\\end{align*}\\]","code":"\n# Observed counts\nobserved_counts <- c(200, 400, 200)\n\n# Expected counts\nexpected_counts <- c(800 * 0.2, 800 * 0.6, 800 * 0.2)\n\n# Chi-square test statistic calculation\nchi_square_stat <- sum((observed_counts - expected_counts)^2 / expected_counts)\nchi_square_stat[1] 33.33333"},{"path":"practice-problems-22.html","id":"b-verify-the-above-chi-square-statistics-calculation-by-hand.-1","chapter":"32 Practice Problems 22","heading":"32.2.2 (b) Verify the above chi-square statistics calculation by hand.","text":"Answer:\\[\\begin{align*}\n\\text{Observed counts} & : O_{\\text{car}} = 200, \\quad O_{\\text{bicycle}} = 400, \\quad O_{\\text{public}} = 200 \\\\\n\\text{Expected counts} & : E_{\\text{car}} = 800 \\cdot 0.2 = 160, \\quad E_{\\text{bicycle}} = 800 \\cdot 0.6 = 480, \\quad E_{\\text{public}} = 800 \\cdot 0.2 = 160 \\\\\n\\chi^2 & = \\sum \\frac{(O - E)^2}{E} \\\\\n& = \\frac{(200 - 160)^2}{160} + \\frac{(400 - 480)^2}{480} + \\frac{(200 - 160)^2}{160} \\\\\n& \\approx 33.333\n\\end{align*}\\]degrees freedom corresponding test 2 (categories - 1). , p-value can calculated :can also test R using chisq.test function.","code":"\np_value <- 1 - pchisq(chi_square_stat, df = 2)\np_value[1] 5.777749e-08\nchisq_test <- chisq.test(x = observed_counts, p = c(0.2, 0.6, 0.2))\nchisq_test\n    Chi-squared test for given probabilities\n\ndata:  observed_counts\nX-squared = 33.333, df = 2, p-value = 5.778e-08"},{"path":"practice-problems-22.html","id":"c-write-the-conclusion-of-the-hypothesis-test.-1","chapter":"32 Practice Problems 22","heading":"32.2.3 (c) Write the conclusion of the hypothesis test.","text":"Answer:reject null hypothesis (\\(\\chi^2 = 33.333, df = 2, p-value < 0.05\\)). statistically discernible evidence proportions individuals preferring type transportation stated null hypothesis.","code":""},{"path":"practice-problems-23.html","id":"practice-problems-23","chapter":"33 Practice Problems 23","heading":"33 Practice Problems 23","text":"","code":""},{"path":"practice-problems-23.html","id":"problem-1-perry-preschool-project","chapter":"33 Practice Problems 23","heading":"33.1 Problem 1: Perry Preschool Project","text":"1962 social experiment, 123 3- 4-year-old children poverty-level families Ypsilanti, Michigan, randomly assigned either treatment group receiving 2 years preschool instruction control group receiving preschool. participants followed adult years. following table shows many group arrested crime time 19 years old. (Time, July 29, 1991).statistically significant difference rate arrest (arrest) two treatment groups.","code":""},{"path":"practice-problems-23.html","id":"a-test-choice","chapter":"33 Practice Problems 23","heading":"33.1.0.1 (a) Test choice","text":"two categorical variables, two levels. either use two sample test compare proportions (groups: treatment, response: arrest outcome) use chi-square test independence. tests give identical results. example, use chi-square test. State hypotheses needed test question .","code":""},{"path":"practice-problems-23.html","id":"b-chi-square-test-with-summarized-data","chapter":"33 Practice Problems 23","heading":"33.1.0.2 (b) Chi-square test with summarized data","text":"example differs example 2 data summarized two-way table. (Example 2 raw categorical variables available.) run chi-square test, first must create matrix counts using cbind command binds together columns counts:use chisq.test command:expected counts large enough trust results?Answer: Yes, 25.conclusion?","code":"\ncounts <- cbind(c(19,32), c(42,30))\ncolnames(counts) <- c(\"arrested\", \"not arrested\") # adds column names\nrownames(counts) <- c(\"preschool\", \"control\")  # adds row names\ncounts          arrested not arrested\npreschool       19           42\ncontrol         32           30\npreschool.test <- chisq.test(counts)\npreschool.test\n    Pearson's Chi-squared test with Yates' continuity\n    correction\n\ndata:  counts\nX-squared = 4.4963, df = 1, p-value = 0.03397\n51/123  # overall arrest rate[1] 0.4146341\n72/123  # overall non arrest rate[1] 0.5853659\npreschool.test$expected          arrested not arrested\npreschool 25.29268     35.70732\ncontrol   25.70732     36.29268"},{"path":"practice-problems-23.html","id":"c-how-different","chapter":"33 Practice Problems 23","heading":"33.1.0.3 (c) How different?","text":"arrest rates differ treatment group? Compute 95% confidence interval difference arrest rates preschool control treatments.Answer: 52% control group arrested 31% preschool group arrested.\\[\n\\hat{p}_{control} = \\dfrac{32}{62} = 0.516129, \\ \\ \\ \\hat{p}_{preschool} = \\dfrac{19}{61} = 0.3114754\n\\]95% difference true arrest rates \\(p_{control} - p_{preschool}\\) \\[\\begin{align*}\n0.516129 - 0.3114754 \\pm & 1.96 \\sqrt{\\dfrac{0.516129(1-0.516129)}{62} + \\dfrac{0.3114754(1-0.3114754)}{61}} \\\\\n0.2046536 \\pm & 1.96(0.0868549) \\\\\n(0.034418, 0.3748892) \\\\\n\\end{align*}\\]95% confident true rate arrest preschool treatment 3.4 37.5 percentage points lower arrest rate control group. evidence preschool treatment lowered risk arrest.","code":"\nprop.table(counts,1)           arrested not arrested\npreschool 0.3114754    0.6885246\ncontrol   0.5161290    0.4838710"},{"path":"practice-problems-23.html","id":"comment","chapter":"33 Practice Problems 23","heading":"33.1.0.4 Comment","text":"chisq.test command uses test stat “correction” categorical variables 2 levels. correction, chi-square test results won’t exactly match two-sample test difference two proportions. turn correct correct=FALSE obtain identical results.","code":"\nchisq.test(counts, correct=FALSE) # exact same as two-sample proportion test\n    Pearson's Chi-squared test\n\ndata:  counts\nX-squared = 5.3059, df = 1, p-value = 0.02125"},{"path":"practice-problems-23.html","id":"problem-2-college-graduates-and-exercise","chapter":"33 Practice Problems 23","heading":"33.2 Problem 2: College graduates and exercise","text":"survey college graduates done study frequently exercised. survey completed 470 graduates. asked lived senior year. Use following data determine whether association exercise campus students’ living arrangements.Answer:\\[\\begin{align*}\nH_0 &: \\text{exercise living arrangements independent }\\\\\nH_A &: \\text{exercise living arrangements dependent }\n\\end{align*}\\]observed expected values chi square test :expected counts greater 5.test statistics calculated :\\[\\begin{align*}\n\\chi^2 & = \\sum \\frac{(O- E)^2}{E}\\\\\n&= \\frac{(32 - 48.83)^2}{48.83} +  \\frac{(30 - 23.94)^2}{23.94} +  \\frac{(28 - 17.23)^2}{17.23} +\\\\\n& \\qquad \\frac{(74 - 97.66)^2}{97.66} + \\frac{(64 - 47.87)^2}{47.87} + \\frac{(42 - 34.47)^2}{34.47} + \\\\\n& \\qquad \\frac{(110 - 81.38)^2}{81.38} + \\frac{(25 - 39.89)^2}{39.89} + \\frac{(15 - 28.72)^2}{28.72} + \\\\\n& \\qquad \\frac{(39 - 27.13)^2}{27.13} + \\frac{(6 - 13.30)^2}{13.30} + \\frac{(5 - 9.57)^2}{9.57} \\\\\n&= 5.80 + 1.53 + 6.73 + 5.73 + 5.44 + 1.64 + 10.06 + 5.56 + 6.55 + 5.19 + 4.01 + 2.18\\\\\n&= 60.42\n\\end{align*}\\]degree freedom \\(\\chi^2\\) \\(df = (4-1)*(3-1) = 6\\).p-value can also calculated asThere significant evidence association exercise living arrangements (\\(\\chi^2 = 60.43\\), df=6, p-value \\(\\approx\\) 0).","code":"\ncounts3 <- cbind(c(32, 74, 110, 39), c(30,64,25,6), c(28,42,15,5))\ncolnames(counts3) <- c(\"No regular exercise\", \"Sporadic exercise\", \"Regular exercise\") \nrownames(counts3) <- c(\"Dormitory\", \"On-Campus Apartment\", \"Off-campus Apartment\", \"At Home\") \nknitr::kable(counts3)\ntest3 <- chisq.test(counts3)\ntest3$observed                     No regular exercise Sporadic exercise\nDormitory                             32                30\nOn-Campus Apartment                   74                64\nOff-campus Apartment                 110                25\nAt Home                               39                 6\n                     Regular exercise\nDormitory                          28\nOn-Campus Apartment                42\nOff-campus Apartment               15\nAt Home                             5\nround(test3$expected,2)                     No regular exercise Sporadic exercise\nDormitory                          48.83             23.94\nOn-Campus Apartment                97.66             47.87\nOff-campus Apartment               81.38             39.89\nAt Home                            27.13             13.30\n                     Regular exercise\nDormitory                       17.23\nOn-Campus Apartment             34.47\nOff-campus Apartment            28.72\nAt Home                          9.57\n(32 - 48.83)^2/48.83 + (30 - 23.94)^2/23.94 + (28 - 17.23)^2/17.23 + (74 - 97.66)^2/97.66 + (64 - 47.87)^2/47.87 + (42 - 34.47)^2/34.47 + (110 - 81.38)^2/81.38 + (25 - 39.89)^2/39.89 + (15 - 28.72)^2/28.72 + (39 - 27.13)^2/27.13+(6 - 13.30)^2/13.30+(5 - 9.57)^2/9.57[1] 60.43885\n5.80 + 1.53 + 6.73 + 5.73 + 5.44 + 1.64 + 10.06 + 5.56 + 6.55 + 5.19 + 4.01 + 2.18[1] 60.42\ntest3\n    Pearson's Chi-squared test\n\ndata:  counts3\nX-squared = 60.439, df = 6, p-value = 3.664e-11\n1 - pchisq(60.43, df = 6)[1] 3.680733e-11"},{"path":"practice-problems-23.html","id":"step-1","chapter":"33 Practice Problems 23","heading":"33.2.1 Step 1:","text":"\\[\\begin{align*}\nH_0 &: \\text{exercise living arrangements independent }\\\\\nH_A &: \\text{exercise living arrangements dependent }\n\\end{align*}\\]","code":""},{"path":"practice-problems-23.html","id":"step-2","chapter":"33 Practice Problems 23","heading":"33.2.2 Step 2:","text":"observed expected values chi square test :expected counts greater 5.","code":"\ntest3$observed                     No regular exercise Sporadic exercise\nDormitory                             32                30\nOn-Campus Apartment                   74                64\nOff-campus Apartment                 110                25\nAt Home                               39                 6\n                     Regular exercise\nDormitory                          28\nOn-Campus Apartment                42\nOff-campus Apartment               15\nAt Home                             5\nround(test3$expected,2)                     No regular exercise Sporadic exercise\nDormitory                          48.83             23.94\nOn-Campus Apartment                97.66             47.87\nOff-campus Apartment               81.38             39.89\nAt Home                            27.13             13.30\n                     Regular exercise\nDormitory                       17.23\nOn-Campus Apartment             34.47\nOff-campus Apartment            28.72\nAt Home                          9.57"},{"path":"practice-problems-23.html","id":"step-3","chapter":"33 Practice Problems 23","heading":"33.2.3 Step 3:","text":"test statistics calculated :\\[\\begin{align*}\n\\chi^2 & = \\sum \\frac{(O- E)^2}{E}\\\\\n&= \\frac{(32 - 48.83)^2}{48.83} +  \\frac{(30 - 23.94)^2}{23.94} +  \\frac{(28 - 17.23)^2}{17.23} +\\\\\n& \\qquad \\frac{(74 - 97.66)^2}{97.66} + \\frac{(64 - 47.87)^2}{47.87} + \\frac{(42 - 34.47)^2}{34.47} + \\\\\n& \\qquad \\frac{(110 - 81.38)^2}{81.38} + \\frac{(25 - 39.89)^2}{39.89} + \\frac{(15 - 28.72)^2}{28.72} + \\\\\n& \\qquad \\frac{(39 - 27.13)^2}{27.13} + \\frac{(6 - 13.30)^2}{13.30} + \\frac{(5 - 9.57)^2}{9.57} \\\\\n&= 5.80 + 1.53 + 6.73 + 5.73 + 5.44 + 1.64 + 10.06 + 5.56 + 6.55 + 5.19 + 4.01 + 2.18\\\\\n&= 60.42\n\\end{align*}\\]degree freedom \\(\\chi^2\\) \\(df = (4-1)*(3-1) = 6\\).","code":"\n(32 - 48.83)^2/48.83 + (30 - 23.94)^2/23.94 + (28 - 17.23)^2/17.23 + (74 - 97.66)^2/97.66 + (64 - 47.87)^2/47.87 + (42 - 34.47)^2/34.47 + (110 - 81.38)^2/81.38 + (25 - 39.89)^2/39.89 + (15 - 28.72)^2/28.72 + (39 - 27.13)^2/27.13+(6 - 13.30)^2/13.30+(5 - 9.57)^2/9.57[1] 60.43885\n5.80 + 1.53 + 6.73 + 5.73 + 5.44 + 1.64 + 10.06 + 5.56 + 6.55 + 5.19 + 4.01 + 2.18[1] 60.42\ntest3\n    Pearson's Chi-squared test\n\ndata:  counts3\nX-squared = 60.439, df = 6, p-value = 3.664e-11"},{"path":"practice-problems-23.html","id":"step-4","chapter":"33 Practice Problems 23","heading":"33.2.4 Step 4:","text":"p-value can also calculated ","code":"\n1 - pchisq(60.43, df = 6)[1] 3.680733e-11"},{"path":"practice-problems-23.html","id":"step-5","chapter":"33 Practice Problems 23","heading":"33.2.5 Step 5:","text":"significant evidence association exercise living arrangements (\\(\\chi^2 = 60.43\\), df=6, p-value \\(\\approx\\) 0).","code":""},{"path":"practice-problems-23.html","id":"problem-3-does-political-comfort-level-depend-on-religion","chapter":"33 Practice Problems 23","heading":"33.3 Problem 3 : Does political comfort level depend on religion?","text":"Consider survey questions political comfort level religion. want know response comfort level question associated religious practice. test question two categorical variables one variable containing least 3 levels, must conduct chi-square test association.","code":""},{"path":"practice-problems-23.html","id":"a-hypotheses","chapter":"33 Practice Problems 23","heading":"33.3.0.1 (a) Hypotheses","text":"State hypotheses test.Answer: null can stated couple equivalent ways: association religion comfort level; variables comfort level religion independent one another; distribution comfort level three religion types.alternatives just “null” statements: association religion comfort level; variables comfort level religion dependent; distribution comfort level different least one religion type.","code":""},{"path":"practice-problems-23.html","id":"b-data","chapter":"33 Practice Problems 23","heading":"33.3.0.2 (b) Data","text":"data suggest association comfort level religion?","code":"\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# read the data \nsurvey <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/Survey.csv\") \n\n# and drop the rows containing missing values using the tidyr package\nsurvey <- survey %>% tidyr::drop_na()\n\n# rename comfort level using fct_recode() from the forcats package\nsurvey <- survey %>% mutate(comfortness = forcats::fct_recode(Question.9, \n                          `rarely` = \"rarely, if ever, comfortable\",\n                          `sometimes` = \"sometimes comfortable\",\n                          `almost always` = \"almost always comfortable\"),\n                          comfortness = forcats::fct_relevel(comfortness, \n                                                             \"almost always\",\n                                                             \"sometimes\", \n                                                             \"rarely\"))\n\n# rename comfort level using fct_recode() from the forcats package\nsurvey <- survey %>%mutate(religiousness = forcats::fct_recode(Question.8, \n                          `not religious` = \"not religious\",\n                          `religious not active` = \"religious but not actively practicing\",\n                          `religious active` = \"religious and actively practicing my religion\"),\n                          religiousness = forcats::fct_relevel(religiousness,\n                                                               \"not religious\",\n                                                               \"religious not active\",\n                                                               \"religious active\"))\n# Make a two way table\nlibrary(kableExtra)\ncounts <- table(survey$religiousness, survey$comfortness)\nprop.table(counts,1)  # dist of comfort level given religious level                      \n                       almost always  sometimes     rarely\n  not religious           0.53092784 0.39175258 0.07731959\n  religious not active    0.39393939 0.41414141 0.19191919\n  religious active        0.31578947 0.42105263 0.26315789"},{"path":"practice-problems-23.html","id":"formatted-tables-in-r","chapter":"33 Practice Problems 23","heading":"33.3.0.3 Formatted tables in R","text":"\nTable 33.1: two way table religious preference political comfortness\n","code":"\nkableExtra::kable(table(survey$religiousness, survey$comfortness), \n                  caption = \"A two way table of religious preference and political comfortness\") %>%\n  kable_styling(position = \"center\")\nggplot(survey, aes(x=religiousness, fill=comfortness)) +\n  geom_bar(position=\"fill\") +\n  labs(fill = \"Comfort level\", x = \"Religious level\", y = \"proportion\", \n       title=\"Comfort level by religious level\") +\n    scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 16))"},{"path":"practice-problems-23.html","id":"c-expected-counts","chapter":"33 Practice Problems 23","heading":"33.3.0.4 (c) Expected counts","text":"Compute expected number “religious” people “almost always comfortable”.Answer: 194 “religious” respondents overall rate (ignoring religion) “almost always” comfortable 45.7%. null true (religion doesn’t relate comfort level), expected number \\[194 \\times \\dfrac{160}{350} = 88.686\\]","code":"\ntable(survey$religiousness)\n       not religious religious not active \n                 194                   99 \n    religious active \n                  57 \ntable(survey$comfortness)\nalmost always     sometimes        rarely \n          160           141            49 "},{"path":"practice-problems-23.html","id":"d-chi-square-contribution","chapter":"33 Practice Problems 23","heading":"33.3.0.5 (d) Chi-square contribution","text":"contribution chi-square test statistic “religious”/“almost always comfortable” cell?Answer: contribution chi-square test stat category 2.31.","code":""},{"path":"practice-problems-23.html","id":"e-chi-square-test","chapter":"33 Practice Problems 23","heading":"33.3.0.6 (e) Chi-square test","text":"chisq.test(x,y) can used give chi-square test results. version, x y categorical variables data set.chi-square test stat value?degrees freedom 4 calculated?Interpret p-value test.","code":"\nComfortReligion <- chisq.test(survey$religiousness, survey$comfortness)\nComfortReligion\n    Pearson's Chi-squared test\n\ndata:  survey$religiousness and survey$comfortness\nX-squared = 19.33, df = 4, p-value = 0.0006768"},{"path":"practice-problems-23.html","id":"f-conclusion","chapter":"33 Practice Problems 23","heading":"33.3.0.7 (f) Conclusion","text":"conclusion test?","code":""},{"path":"practice-problems-23.html","id":"g-expected-counts","chapter":"33 Practice Problems 23","heading":"33.3.0.8 (g) Expected counts","text":"expected counts large enough use chi-square distribution compute p-value?","code":"\nComfortReligion$expected                      survey$comfortness\nsurvey$religiousness   almost always sometimes rarely\n  not religious             88.68571  78.15429  27.16\n  religious not active      45.25714  39.88286  13.86\n  religious active          26.05714  22.96286   7.98"},{"path":"practice-problems-23.html","id":"h-simulated-p-value","chapter":"33 Practice Problems 23","heading":"33.3.0.9 (h) Simulated p-value","text":"concerned expected counts weren’t large enough trust using chi-square distribution compute p-value, can add simulate.p.value = TRUE argument use randomization distribution compute p-value:p-value slightly different, conclusion .","code":"\nchisq.test(survey$religiousness, survey$comfortness, simulate.p.value = TRUE)\n    Pearson's Chi-squared test with simulated p-value\n    (based on 2000 replicates)\n\ndata:  survey$religiousness and survey$comfortness\nX-squared = 19.33, df = NA, p-value = 0.0009995"},{"path":"practice-problems-23.html","id":"i-where-is-the-difference","chapter":"33 Practice Problems 23","heading":"33.3.0.10 (i) Where is the difference?","text":"Use grouped bar graph conditional percents part (b) describe association () found part (f). help quantify differences, compute 95% confidence interval difference true proportions “rarely comfortable” people religious actively religious groups.Answer: largest test stat contributions comes religious/rarely comfortable group active religious/rarely comfortable group. can see religious respondents low “rarely” comfortable level compared religious groups (7.7% vs. 26.3% active 19.2% active) high almost always comfortable level compared religious groups (53.1% vs. 31.6% active 39.4% active).\\(p_{.rel}\\) \\(p_{active.rel}\\) denote true proportions “rarely comfortable” religious active religious groups. want 95% CI \\(p_{.rel} - p_{active}\\). sample proportions computed counts table (prop.table output). 194 “religious” respondents, 15 rarely comfortable \n\\[\\hat{p}_{.rel} = \\frac{15}{194} = 0.077\\]\n\\[\\hat{p}_{active.rel} = \\frac{15}{57} = 0.263\\]95% CI difference true rates rarely comfortable \n\\[\\begin{align*}\nCI &= (0.077 - 0.263) \\pm 1.96\\cdot\\sqrt{\\frac{0.077(1-0.077)}{194} + \\frac{0.263(1-0.263)}{57}}\\\\\n&= (-0.306, -0.066)\n\\end{align*}\\]95% confident percentage non-religious students rarely comfortable 7 31 percentage points lower actively religious students.","code":"\nround((0.077 - 0.263) + c(-1,1)* 1.96* sqrt(0.077*(1-0.077)/194  + 0.263*(1-0.263)/57),3)[1] -0.306 -0.066"},{"path":"practice-problems-24.html","id":"practice-problems-24","chapter":"34 Practice Problems 24","heading":"34 Practice Problems 24","text":"","code":""},{"path":"practice-problems-24.html","id":"problem-1-comparing-religious-guess-by-religion","chapter":"34 Practice Problems 24","heading":"34.1 Problem 1: Comparing % religious guess by religion","text":"One class survey questions asked respondents give best guess percentage students Carleton practice religion. can compare responses question religiousness respondent:","code":"\nlibrary(dplyr)\n# read the data \nsurvey <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/Survey.csv\") \n\n# and drop the rows containing missing values using the tidyr package\nsurvey <- survey %>% tidyr::drop_na()\n\n# make a new variable called `practice_religion_percentage` (more informative variable name)\nsurvey <- survey %>%  mutate(practice_religion = Question.7)\n\n# rename comfort level using fct_recode() from the forcats package\nsurvey <- survey %>%mutate(religiousness = forcats::fct_recode(Question.8, \n                          `not religious` = \"not religious\",\n                          `religious not active` = \"religious but not actively practicing\",\n                          `religious active` = \"religious and actively practicing my religion\"),\n                          religiousness = forcats::fct_relevel(religiousness,\n                                                               \"not religious\",\n                                                               \"religious not active\",\n                                                               \"religious active\"))\nggplot(data = survey, aes(x = religiousness, y = practice_religion)) +\n    geom_boxplot()\nlibrary(dplyr)\nlibrary(ggplot2)\nsurvey %>%\n  group_by(religiousness) %>%\n  summarize(\n    count = n(),\n    mean_practice = mean(practice_religion, na.rm = TRUE),\n    sd_practice = sd(practice_religion, na.rm = TRUE),\n  ) %>% knitr::kable()"},{"path":"practice-problems-24.html","id":"a-one-way-anova-hypotheses","chapter":"34 Practice Problems 24","heading":"34.1.0.1 (a) One-way ANOVA hypotheses","text":"want determine differences observed mean guesses statistically significant. State hypotheses test.Answer: Let \\(\\mu\\) true mean religous % guess given religiousness group. \\(H_0: \\mu_{notRelig} = \\mu_{Relig,Act} = \\mu_{Relig,NotAct}\\) vs. \\(H_A:\\) least one mean different.","code":""},{"path":"practice-problems-24.html","id":"b-check-assumptions","chapter":"34 Practice Problems 24","heading":"34.1.0.2 (b) Check assumptions","text":"Can use trust results one-way ANOVA test?Answer: Yes, assumptions met. distributions within group slightly skewed roughly symmetric, sample sizes within group least 30. addition, SD group close (18% 19.2%).","code":"\nggplot(survey, aes(sample = practice_religion)) + geom_qq() + geom_qq_line() + facet_wrap(~religiousness)"},{"path":"practice-problems-24.html","id":"c-one-way-anova-test","chapter":"34 Practice Problems 24","heading":"34.1.0.3 (c) One-way ANOVA test","text":"Assuming part (b) checks , run one-way ANOVA test compare means:F test stat value?Answer: \\(F = 0.898\\)Interpret p-value.Answer: difference true mean guess three groups, see F test stat least 0.898 40.8% time.conclusion?Answer: differences mean guesses ’ve observed sample statistically significant. don’t evidence true mean guesses three religiousness groups different.","code":"\nguess.aov <- aov(practice_religion ~ religiousness, data = survey)\nsummary(guess.aov)               Df Sum Sq Mean Sq F value Pr(>F)\nreligiousness   2    607   303.6   0.898  0.408\nResiduals     347 117321   338.1               "},{"path":"practice-problems-24.html","id":"d-describe-the-association","chapter":"34 Practice Problems 24","heading":"34.1.0.4 (d) Describe the association?","text":"found statistically significant difference means part (c), describe groups differ. find statistically significant difference part (c), estimate average guess students (hypothetical) population 215 students.Answer: didn’t find statistically significant difference part (c). best estimate average guess students, since responses don’t seem differ religiousness?95% confident mean guess percentage religious students Carleton 37.3% 41.1% math 215 students.difference?!Use EDA describe sample means differ. look like three means different, one mean look different rest? sample mean responses two religious groups look similar (active: 41.3%; active: 40.2%) mean response religious group lower (38.1%).conditions using theoretical ANOVA met example. However, use randomization approach using R, use permTestAnova() function CarletonStats package R follows:","code":"\nt.test(survey$practice_religion)\n    One Sample t-test\n\ndata:  survey$practice_religion\nt = 39.882, df = 349, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 37.25428 41.11927\nsample estimates:\nmean of x \n 39.18677        not religious religious not active \n            38.05155             40.18556 \n    religious active \n            41.31579 \nsurvey$religion <- ifelse(survey$religiousness == \"not religious\", \"not religious\", \"religious\")\nresult <-t.test(practice_religion ~ religion, data=survey)\nset.seed(7)\nlibrary(CarletonStats)\npermTestAnova(practice_religion ~ religiousness, data=survey)\n    ** Permutation test **\n\n Permutation test with alternative: greater \n Observed F statistic: 0.89787 \n Mean of permutation distribution: 1.0044 \n Standard error of permutation distribution: 1.01157 \n P-value:  0.4127 \n\n    *-------------*"},{"path":"practice-problems-24.html","id":"problem-2-frisbee-grip","chapter":"34 Practice Problems 24","heading":"34.2 Problem 2: Frisbee grip","text":"data set Frisbee.csv contains data Distance thrown (paces) three different frisbee Grip types. 24 difference cases (throws) can compare responses question religiousness respondent:question want answer whether differences observed mean distance thrown statistically significant. test question comparing means quantitative response broken least 2 groups, can conduct one-way ANOVA test.","code":"\nfrisbee <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/Frisbee.csv\")\nggplot(frisbee, aes(x = Grip, y = Distance)) + geom_boxplot()\ntapply(frisbee$Distance, frisbee$Grip, summary)$`Finger Out`\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.00   26.75   29.50   29.50   32.25   36.00 \n\n$Inverted\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   32.00   32.38   34.50   37.00 \n\n$Normal\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  28.00   30.00   32.50   33.12   36.25   39.00 "},{"path":"practice-problems-24.html","id":"a-one-way-anova-hypotheses-1","chapter":"34 Practice Problems 24","heading":"34.2.0.1 (a) One-way ANOVA hypotheses","text":"State hypotheses test.","code":""},{"path":"practice-problems-24.html","id":"b-one-way-anova-test","chapter":"34 Practice Problems 24","heading":"34.2.0.2 (b) One-way ANOVA test","text":"can obtain one-way ANOVA table test results aov(y ~ x, data=) command. Running summary function anova result gives ANOVA table:F test stat value?Interpret p-value.conclusion?","code":"\nfrisbee.anova <- aov(Distance ~ Grip, data = frisbee)\nsummary(frisbee.anova)            Df Sum Sq Mean Sq F value Pr(>F)\nGrip         2  58.58   29.29   2.045  0.154\nResiduals   21 300.75   14.32               "},{"path":"practice-problems-24.html","id":"c-checking-assumptions","chapter":"34 Practice Problems 24","heading":"34.2.0.3 (c) Checking assumptions","text":"Can trust p-value obtained using F distribution?","code":"\ntable(frisbee$Grip)  # check n's\nFinger Out   Inverted     Normal \n         8          8          8 \ntapply(frisbee$Distance, frisbee$Grip, sd)  # similar SD's?Finger Out   Inverted     Normal \n  4.174754   3.159453   3.943802 \nlibrary(ggplot2)  # shape?\nggplot(frisbee, aes(x = Grip, y = Distance)) + geom_boxplot()\nggplot(frisbee, aes(sample = Distance)) + geom_qq() + geom_qq_line() + facet_wrap(~Grip)"}]
