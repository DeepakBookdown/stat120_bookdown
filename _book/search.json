[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"sample book written Markdown guide STAT 120 students interactively explore various class activities projects R.","code":""},{"path":"class-activity-1.html","id":"class-activity-1","chapter":"1 Class Activity 1","heading":"1 Class Activity 1","text":"","code":""},{"path":"class-activity-1.html","id":"your-turn-1","chapter":"1 Class Activity 1","heading":"1.1 Your Turn 1","text":"Run following chunk. Comment output.dimension dataset called ‘example_data’?","code":"\nexample_data = data.frame(ID = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),\n                          Greeting = c(rep(\"Hello\", 5), rep(\"Goodbye\",5)),\n                          Male = rep(c(TRUE, FALSE), 5),\n                          Age = runif(n=10, 20, 60))\nexample_data   ID Greeting  Male      Age\n1   1    Hello  TRUE 47.06884\n2   2    Hello FALSE 30.27234\n3   3    Hello  TRUE 42.97969\n4   4    Hello FALSE 33.81146\n5   5    Hello  TRUE 20.62114\n6   6  Goodbye FALSE 43.07795\n7   7  Goodbye  TRUE 48.97500\n8   8  Goodbye FALSE 42.19147\n9   9  Goodbye  TRUE 47.26160\n10 10  Goodbye FALSE 30.92222dim(example_data)\n[1] 10  4\nnrow(example_data)\n[1] 10\nncol(example_data)\n[1] 4"},{"path":"class-activity-1.html","id":"your-turn-2","chapter":"1 Class Activity 1","heading":"1.2 Your Turn 2","text":"Read dataset EducationLiteracy Lock5 second edition book.Print header (.e. first 6 cases default) dataset part .dimension dataset ?Answer: 188 rows 3 columns.type variables Country, EducationExpenditure, Literacy?like use education expenditure predict literacy rate countries, variable explanatory variable one response?","code":"\n# read in the data\neducation_lock5 <- read.csv(\"https://www.lock5stat.com/datasets2e/EducationLiteracy.csv\")\nhead(education_lock5)              Country EducationExpenditure Literacy\n1         Afghanistan                  3.1     31.7\n2             Albania                  3.2     96.8\n3             Algeria                  4.3       NA\n4             Andorra                  3.2       NA\n5              Angola                  3.5     70.6\n6 Antigua and Barbuda                  2.6     99.0\ndim(education_lock5)[1] 188   3"},{"path":"class-activity-1.html","id":"quiz","chapter":"1 Class Activity 1","heading":"1.3 Quiz","text":"1. Cases set individual units measurements taken.  . TRUE  B. FALSE2. characteristic recorded case called  . ledger B. caseholder C. placeholder D. variable3. Variables can either categorical quantitative. . TRUE B. FALSE","code":""},{"path":"class-activity-2.html","id":"class-activity-2","chapter":"2 Class Activity 2","heading":"2 Class Activity 2","text":"","code":""},{"path":"class-activity-2.html","id":"your-turn-1-1","chapter":"2 Class Activity 2","heading":"2.1 Your Turn 1","text":"exercise finding average word length Lincoln’s Gettysburg’s address.","code":""},{"path":"class-activity-2.html","id":"your-turn-2-1","chapter":"2 Class Activity 2","heading":"2.2 Your Turn 2","text":"","code":""},{"path":"class-activity-2.html","id":"summary-of-article-on-it-depends-on-how-you-ask","chapter":"2 Class Activity 2","heading":"2.2.1 Summary of article on It depends on how you ask!","text":"Answer:","code":""},{"path":"class-activity-2.html","id":"your-turn-3","chapter":"2 Class Activity 2","heading":"2.3 Your Turn 3","text":"","code":""},{"path":"class-activity-2.html","id":"gettysburg-random-sample","chapter":"2 Class Activity 2","heading":"2.3.1 Gettysburg random sample","text":"Let’s take simple random sample (SRS) Gettysburg words. “population” contained \nspreadsheet GettysburgPopulationCounts.csv. Carefully load data R:position variable enumerates list words population (address).(). SampleRun following command obtain SRS 10 words 268 population:tells position (row number) sampled words. sampled positions? sampled positions different folks class?(b). Get words lengthsWe subset data set pop obtain sampled rows listed samp. using square bracket notation `dataset[row number, column number/name]. Run following command find sampled words sizes:Compute sample meanThe word lengths part (b) data sample. can compute sample mean using calculator, using R. Let’s try R (find faster!). First save quantitative variable size new variable called mysize:find mean values:sample mean (truly random sample) compare sample mean non-random sample?Answer: true mean 4.29. two means likely vary. Since many non-random samples generally overestimated population mean length, possible (guaranteed) one non-random sample gave mean length greater random sample’s mean length.","code":"\npop <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/GettysbergPopulationCounts.csv\")\nhead(pop)  position size  word\n1        1    4  Four\n2        2    5 score\n3        3    3   and\n4        4    5 seven\n5        5    5 years\n6        6    3  ago,\nsamp <- sample(1:268, size=10)\nsamp [1] 175  21 228 265  92  30  96 127  78  71\npop[samp,]    position size      word\n175      175    4      work\n21        21    9 dedicated\n228      228    6    highly\n265      265    6    perish\n92        92    2        It\n30        30    5    equal.\n96        96    3       and\n127      127    4      here\n78        78    7   resting\n71        71    7   portion\nmysize <- pop[samp, \"size\"]\nmysize [1] 4 9 6 6 2 5 3 4 7 7\nmean(mysize)[1] 5.3"},{"path":"class-activity-2.html","id":"driving-with-a-pet-on-your-lap","chapter":"2 Class Activity 2","heading":"2.3.2 Driving with a Pet on your Lap","text":"30,000 people participated online poll cnn.com conducted April 2012 asking: “ever driven pet lap”? see 34% participants answered yes 66% answered .Can conclude random sample used description given? Explain.Explain appropriate generalize results drivers, even drivers visit cnn.com.might select sample people give us results can generalize broader population?variable measured study quantitative categorical?","code":""},{"path":"class-activity-2.html","id":"quiz-1","chapter":"2 Class Activity 2","heading":"2.4 Quiz","text":"1. group researchers investigated effect media usage (whether subjects watch television use Internet) bedroom “Tiredness” day (measured 50 point scale). explanatory response variables   . Explanatory media usage bedroom response “tiredness”  B. Explanatory “tiredness” response media usage bedroom2. October 2016 Gallup poll estimates 60% US adults support legalizing use marijuana. results based “random sample 1,017 adults, aged 18 older, living 50 U.S. states District Columbia”. population study  . adults (18 older) living U.S. (including D.C) B. 1,017 adults (18 older) living U.S. (including D.C) sampled C. 1,017 adults (18 older) living U.S. (including D.C) sampled support legalizing marijuana D. adults (18 older) living U.S. (including D.C) support legalizing marijuana3. October 2016 Gallup poll estimates 60% US adults support legalizing use marijuana. results based “random sample 1,017 adults, aged 18 older, living 50 U.S. states District Columbia”. statement regarding bias true? . results biased Gallup contacted small fraction people population. B. results may biased people may answered survey question marijuana truthfully","code":""},{"path":"class-activity-3.html","id":"class-activity-3","chapter":"3 Class Activity 3","heading":"3 Class Activity 3","text":"","code":""},{"path":"class-activity-3.html","id":"case-study-1","chapter":"3 Class Activity 3","heading":"3.1 Case Study 1","text":"Consider following case study:\n“Swimming dolphins can certainly fun, also therapeutic patients suffering clinical depression? investigate possibility, researchers recruited 30 subjects aged 18-65 clinical diagnosis mild moderate depression. Subjects required discontinue use antidepressant drugs psychotherapy four weeks prior experiment, throughout experiment. 30 subjects went island coast Honduras, randomly assigned one two treatment groups. groups engaged amount swimming snorkeling day, one group (animal care program) presence bottlenose dolphins group (outdoor nature program) . end two weeks, subjects’ level depression evaluated, beginning study, determined whether showed substantial improvement (reducing level depression) end study (Antonioli Reveley, 2005).”Observed data:\nresearchers found 10 15 subjects dolphin therapy group showed substantial improvement, compared 3 15 subjects control group.\n(). Identify observational units study.\n(b). Classify variable categorical quantitative.(c). variable regard explanatory response?(d). observational study experiment? Justify answer.(e). Construct two-way table based results experiment.Two-way table:","code":""},{"path":"class-activity-3.html","id":"case-study-2","chapter":"3 Class Activity 3","heading":"3.2 Case Study 2","text":"Consider following case study:\n“Researchers want find new diet affects weight gain among underweight subjects. experiment two treatment conditions, new diet standard diet. study, researchers recruited 200 subjects grouped 100 pairs based shared characteristics age, gender, weight, height, lifestyle, . 20-year-old female within weight range 90-110 pounds height range 60-63 inches paired another 20-year-old female falls weight height categories. 100 pairs made, subject pair randomly assigned treatment group (administered new diet 2 months) subject pair assigned control group (assigned follow standard diet two months). end time time period 2 months, researchers measure total weight gain subject.”Observed data:\nresearchers found 60 100 subjects new diet group showed substantial improvement, compared 43 100 subjects standard diet group.\n(b). Classify variable categorical quantitative.(c). variable regard explanatory response?(d). observational study experiment? Justify answer.(e). experiment, randomized comparative experiment matched pairs experiment?(f). Construct two-way table based results experiment.Two-way table:","code":""},{"path":"class-activity-3.html","id":"quiz-2","chapter":"3 Class Activity 3","heading":"3.3 Quiz","text":"1. third variable associated explanatory variable response variable called confounding variable.  . TRUE  B. FALSE2. different levels explanatory variable known  . treatments B. local groups C. response D. cases3. Causality can always inferred observational studies. . TRUE B. FALSE","code":""},{"path":"class-activity-4.html","id":"class-activity-4","chapter":"4 Class Activity 4","heading":"4 Class Activity 4","text":"","code":""},{"path":"class-activity-4.html","id":"your-turn-1-2","chapter":"4 Class Activity 4","heading":"4.1 Your Turn 1","text":"","code":""},{"path":"class-activity-4.html","id":"flowers-v.-mississippi","chapter":"4 Class Activity 4","heading":"4.1.1 Flowers v. Mississippi","text":"data set APM_DougEvensCases.csv contains data 1517 potential black white jurors 66 cases Doug Evans primary prosecutor 1992 2017. jurors available Doug Evans strike using “peremptory strikes” jury selection phase.(). Inspect dataRead dataLook first three rows data setTo get data one variable, use command dataset$variable. example, jurors$struck_state gives us data values struck_state variable, tells us juror struck state jury pool. can see first 10 entries variable:(b). Table counts proportionsThe summary command used data frame gives summaries variableThe table command gives distribution counts single categorical variable. obtain count table struck_state need toWe can add prop.table command turn counts proportions:proportion eligible jurors struck state jury pool?(c). Bar graph one variableYou can create simple bar graph one categorical variable barplot command. visualize distribution struck status eligible jurors:(d). Two-way tablesFirst 10 entries race struck_state variable isThe table command also gives two-way tables two variables included. two-way table juror race state struck status:many jurors white struck state?(e). Conditional proportions: state strike status juror raceThe prop.table command gives conditional proportions two-way table. plug two-way table prop.table margin=1 get proportions grouped row variable:eligible black jurors, 57.9% struck state.proportion eligible white jurors struck state?\nClick answeranswer: 12.5%\nevidence association juror race state strikes?\nClick answeranswer: Yes, association rate state strikes varies greatly juror race \n60% black jurors struck compared 13% white jurors\n(f). Stacked bar graph two variablesWe can visualize conditional distribution part (e) stacked bar graph created using ggplot2 graphing package. First, load package’s functions library command:Now can use geom_bar command package. get conditional distribution struck_state given race:basic syntax function let ggplot know data set name (jurors), specify grouping conditional variable x-axis (race) aes (aesthetic) argument. fill variable response variable (struck_state). add (+) geom_bar geometry get bar graph fill position specified. Adding informative label title complete graph.\n(g). Conditional distribution race grouped strike statusWe can “flip” response grouping variables easily (think makes sense ). specify margin=2 get proportions grouped column variable:Notice proportions add one column. eligible jurors struck state, 71.6% black.stacked bar graph distribution isWhat proportion eligible jurors struck state black? white?","code":"\njurors <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/APM_DougEvansCases.csv\")\n# dimension of dataset\ndim(jurors)[1] 1517    6\njurors[c(1,2,3), ]  trial__id  race        struck_state defendant_race\n1         4 Black Not struck by State          White\n2         4 Black     Struck by State          White\n3         4 White Not struck by State          White\n       same_race                     struck_by\n1 different race Juror chosen to serve on jury\n2 different race           Struck by the state\n3      same race Juror chosen to serve on jury\njurors$struck_state[1:10] [1] \"Not struck by State\" \"Struck by State\"    \n [3] \"Not struck by State\" \"Not struck by State\"\n [5] \"Struck by State\"     \"Not struck by State\"\n [7] \"Struck by State\"     \"Not struck by State\"\n [9] \"Not struck by State\" \"Not struck by State\"\nsummary(jurors)   trial__id         race           struck_state      \n Min.   :  4.0   Length:1517        Length:1517       \n 1st Qu.: 52.0   Class :character   Class :character  \n Median : 82.0   Mode  :character   Mode  :character  \n Mean   :112.6                                        \n 3rd Qu.:170.0                                        \n Max.   :301.0                                        \n defendant_race      same_race          struck_by        \n Length:1517        Length:1517        Length:1517       \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \ncounts <- table(jurors$struck_state)\ncounts\nNot struck by State     Struck by State \n               1084                 433 \nprop.table(counts)\nNot struck by State     Struck by State \n          0.7145682           0.2854318 \nbarplot(counts, ylab = \"count\")\njurors[(1:10),(2:3)]    race        struck_state\n1  Black Not struck by State\n2  Black     Struck by State\n3  White Not struck by State\n4  White Not struck by State\n5  Black     Struck by State\n6  White Not struck by State\n7  Black     Struck by State\n8  White Not struck by State\n9  White Not struck by State\n10 White Not struck by State\nmytable <- table(jurors$race, jurors$struck_state)\nmytable       \n        Not struck by State Struck by State\n  Black                 225             310\n  White                 859             123\nprop.table(mytable, margin = 1)       \n        Not struck by State Struck by State\n  Black           0.4205607       0.5794393\n  White           0.8747454       0.1252546\nlibrary(ggplot2)\nggplot(jurors, aes(x = race, fill = struck_state)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"State strikes by juror race\", y = \"proportion\", \n       x = \"eligible juror race\", fill = \"struck by state?\")\nprop.table(mytable, margin = 2)       \n        Not struck by State Struck by State\n  Black           0.2075646       0.7159353\n  White           0.7924354       0.2840647\nggplot(jurors, aes(x = struck_state, fill = race)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"Juror race by state strikes\", y = \"proportion\", \n       fill = \"eligible juror race\", x = \"struck by state?\")"},{"path":"class-activity-4.html","id":"your-turn-2-2","chapter":"4 Class Activity 4","heading":"4.2 Your Turn 2","text":"","code":""},{"path":"class-activity-4.html","id":"graduate-programs-acceptance-and-sex","chapter":"4 Class Activity 4","heading":"4.2.1 Graduate programs acceptance and sex","text":"grad school program acceptance rates associated sex? look classic data set Berkeley grad school applications 1973 (Science, 1975). data cases applicants four graduate programs Berkeley 1973. variable result tells us applicant accepted graduate program, sex tells us sex applicant (male female), program tells us program type (programs 1,2,3 4).(). Table counts proportionsWhat proportion applicants accepted?(b). Two-way tablesThe table command also gives two-way tables two variables included. two-way table result sex:many applicants involved females accepted?(c). Conditional proportions: acceptance given sexThe prop.table command gives conditional proportions two-way table. First let’s save two-way table object named mytable:use prop.table get distribution result conditioned (grouped) applicant’s sex:value 1 command tell’s R want row proportions (denominator proportion row total).proportion female accepted?proportion males accepted?(d). Bar graph one variableYou can create simple bar graph one categorical variable barplot command. visualize distribution result:can add title x y axis labels :(e). Stacked bar graph two variablesNow can use geom_bar command package. get conditional distribution result given sex:basic syntax function let ggplot know data set name (grad), specify grouping conditional variable x-axis (sex) aes (aesthetic) argument. fill variable response variable (result). add (+) geom_bar geometry get bar graph fill position specified. Adding informative label title complete graph.Verify graph plotting conditional proportions part (c)\n(f). Subsetting program typeFinally, repeat previous analysis result sex, time divide (subset) data set program type. need know values program coded:use filter command available dplyr package get applicants program 1:Verify number rows subsetted program 1 data set matches number program 1 applicants shown table counts .Repeat filter command get data set program 2 call new data set grad.p2. Verify number rows dataset matches number program 2 applicants original data set.(g). Result sex program 1.Show distribution result conditioned applicant’s sex program 1 data set. Get table conditional proportions (percentages) stacked bar graph.(h). Result sex program 2.Repeat part (g) time use program 2 data set. Compare two bar graphs (g) (h) explain show females higher acceptance rate accounting program type (1 2).Answer: programs 1 2, see female applicants slightly higher rate acceptance\nmale applicants. accounting program type, now see black defendants higher\nrate death penalty white defendants. Without accounting program type, opposite true\n(see parts (c) (e)).? confounding affect program type associated result sex:females prefer apply programs 3 4 males prefer programs 1 2 (3 \n4).\n44% females applied program 3 40% program 4\n38% males applied program 1 26% program 2\n44% females applied program 3 40% program 438% males applied program 1 26% program 2-Programs 3 4 much harder get programs 1 2\n- 64% applicants program 1 accepted 63% applicants program 2 accepted\n- 6% applicants program 4 accepted 34% applicants program 3 acceptedSo since majority females applied toughest programs (measured acceptance rates),\noverall rate acceptance lower females compared males. break \nrates program type, see females higher acceptance rates males (see \nvisual part ()).(). bar graph three variablesIf simply want graph relationship result sex type program, can avoid subsetting data using facet_wrap command ggplot2. one simple addition stacked bar graph part (e):Verify command creates side--side stacked bar graphs match graphs parts (g) (h) programs 1 2.Answer: graphs match.","code":"\ngrad <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/BerkeleyGrad.csv\")\n# dimension of the dataset\ndim(grad)[1] 3014    3\n# first 6 rows\nhead(grad)   program  sex result\n1 program1 male accept\n2 program1 male accept\n3 program1 male accept\n4 program1 male accept\n5 program1 male accept\n6 program1 male accept\nprop.table(table(grad$result))\n   accept    reject \n0.4260119 0.5739881 \ntable(grad$sex, grad$result)        \n         accept reject\n  female    262    587\n  male     1022   1143\nmytable <- table(grad$sex, grad$result)\nprop.table(mytable, 1)        \n            accept    reject\n  female 0.3085984 0.6914016\n  male   0.4720554 0.5279446\nbarplot(table(grad$result))\nbarplot(table(grad$result), xlab=\"application result\", \n        ylab=\"Count\", main = \"Distribution of Results\")\nlibrary(ggplot2) # don't need if you already entered it for example 1\nggplot(grad, aes(x = sex, fill = result)) + \n  geom_bar(position = \"fill\") + \n  labs(y=\"Proportion\", title = \"result by sex\", fill = \"result?\", x = \"sex\")\ntable(grad$program)\nprogram1 program2 program3 program4 \n     933      585      782      714 \nlibrary(dplyr)\ngrad.p1 <- filter(grad, program == \"program1\")  # gets rows where program equal program1\nhead(grad.p1)   program  sex result\n1 program1 male accept\n2 program1 male accept\n3 program1 male accept\n4 program1 male accept\n5 program1 male accept\n6 program1 male accept\ndim(grad.p1)[1] 933   3\n# enter R code for (f) here\ngrad.p2 <- filter(grad, program == \"program2\") # gets rows where program equal program1\nhead(grad.p2)   program  sex result\n1 program2 male accept\n2 program2 male accept\n3 program2 male accept\n4 program2 male accept\n5 program2 male accept\n6 program2 male accept\n# enter R code for (g) here\nggplot(grad.p1, aes(x = sex, fill = result)) +\n geom_bar(position = \"fill\") +\n labs(y=\"Proportion\", title = \"result by sex for program 1\",\n fill = \"result?\", x = \"sex\")\nprop.table(table(grad.p1$sex, grad.p1$result),1)        \n            accept    reject\n  female 0.8240741 0.1759259\n  male   0.6193939 0.3806061\n# enter R code for (h) here\nggplot(grad.p2, aes(x = sex, fill = result)) +\n geom_bar(position = \"fill\") +\n labs(y=\"Proportion\", title = \"result by sex for program 2\",\n fill = \"result?\", x = \"sex\")\nprop.table(table(grad.p2$sex, grad.p2$result),1)        \n            accept    reject\n  female 0.6800000 0.3200000\n  male   0.6285714 0.3714286\nprop.table(table(grad$sex, grad$program), 1)        \n           program1   program2   program3   program4\n  female 0.12720848 0.02944641 0.44169611 0.40164900\n  male   0.38106236 0.25866051 0.18799076 0.17228637\nprop.table(table(grad$program, grad$result), 1)          \n               accept     reject\n  program1 0.64308682 0.35691318\n  program2 0.63076923 0.36923077\n  program3 0.34398977 0.65601023\n  program4 0.06442577 0.93557423\nggplot(grad, aes(x = sex, fill = result)) + \n  geom_bar(position = \"fill\") + \n  labs(y=\"Proportion\", \n       title = \"result by sex for each program\", \n       fill = \"result?\", \n       x = \"sex\") + \n  facet_wrap(~program)"},{"path":"class-activity-4.html","id":"quiz-3","chapter":"4 Class Activity 4","heading":"4.3 Quiz","text":"1. two-way table shown two groups, 1 2, two possible outcomes, B.proportion cases Group 1?  . 0.33  B. 0.20  C. 0.25  D. 0.752. disruption gene called DYXC1 chromosome 15 humans may related increased risk developing dyslexia. Researchers studied gene 109 people diagnosed dyslexia control group 195 others learning disorder. DYXC1 break occurred 10 dyslexia 5 control group. experiment observational study? . Experiment B. Observational Study3. data question 2 can summarized two way table :proportion Dyslexia group break DYXC1 gene? Round answer 3 significant digits decimal. . 0.026 B. 0.667 C. 0.127 D. 0.092","code":""},{"path":"class-activity-5.html","id":"class-activity-5","chapter":"5 Class Activity 5","heading":"5 Class Activity 5","text":"","code":""},{"path":"class-activity-5.html","id":"your-turn-1-3","chapter":"5 Class Activity 5","heading":"5.1 Your Turn 1","text":"","code":""},{"path":"class-activity-5.html","id":"hollywood-movies-domestic-gross","chapter":"5 Class Activity 5","heading":"5.1.1 Hollywood Movies Domestic Gross","text":"dataset HollywoodMovies2011 provides information 136 movies came Hollywood 2011. look variable DomesticGross, gives US domestic gross income movie viewers (millions dollars).(). Describe shape distribution.(b). appear outliers? , values?(c). Finding outliersWe can find row numbers cases (movies) DomesticGross greater 300 (300 million dollars):Run command verify rows 4 14. find movies subsetting data frame:Note c(4,14) part command creates vector numbers 4 14 (c stands combine). movies outliers?(d). Use histogram answer: median less 100 million, 100 million, 100 million?(e). expect mean greater less median. Explain.(f). Computing mean medianYou can get mean median number ways. Run three commands:NA stand ? many movies missing DomesticGross? can subset data show cases NA values DomesticGross:(g). Missing dataThere commands R “fail” default missing data (NA) present (mean, median sd examples). can easily turn failure feature argument na.rm=TRUE(h). Stats without outliersThere number ways “remove” outliers analysis. use square bracket [] notation along minus - remove row 4 (Harry Potter) variable DomesticGross summary stat calculations:mean change median case removed? (compare (g) (h) mean median values)Answer: values go removing highest grossing movie year, drop mean substantial. mean drops almost 4% Harry Potter removed median drops 0.1%.(). Computing standard deviationThe standard deviation command sd. need add na.rm argument obtain SD DomesticGross:Look distribution DomesticGross shown histogram. SD (variation around mean) inadequate measure variation type distribution?(j). Stats GenreThe tapply(y, x, stat) command gives stat value y level x. get summary DomesticGross type Genre:movies genre highest median domestic gross?summary stats adventure genre?Answer: help answer questions really explore number movies genrewith table command.fantasy genre highest median domestic gross (\\(\\$381\\) million). note two movies classification 2011. action genre second highest \\(\\$352\\) million 12 movies category.fantasy genre highest median domestic gross (\\(\\$381\\) million). note two movies classification 2011. action genre second highest \\(\\$352\\) million 12 movies category.adventure genre one movie (Hugo) movie also missing value DomesticGross!adventure genre one movie (Hugo) movie also missing value DomesticGross!(k). Extra: Histogram DomesticGross Genre(Lab Manual) ggplot2 package allows create histograms separated categorical variable using facet_wrap command. Assuming ggplot2 already installed, need load library create graph:genre variability domestic gross?","code":"\nmovies <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HollywoodMovies2011.csv\")\nhist(movies$DomesticGross, main=\"Distribution of Domestic Gross\")\nwhich(movies$DomesticGross > 300)[1]  4 14\nmovies[c(4,14), ]                                         Movie\n4  Harry Potter and the Deathly Hallows Part 2\n14              Transformers: Dark of the Moon\n            LeadStudio RottenTomatoes AudienceScore   Story\n4          Warner Bros             96            92 Rivalry\n14 DreamWorks Pictures             35            67   Quest\n     Genre TheatersOpenWeek BOAverageOpenWeek DomesticGross\n4  Fantasy             4375             38672        381.01\n14  Action             4088             23937        352.39\n   ForeignGross WorldGross Budget Profitability\n4        947.10   1328.111    125     10.624888\n14       770.81   1123.195    195      5.759974\n   OpeningWeekend\n4          169.19\n14          97.85\nmean(movies$DomesticGross)[1] NA\nmedian(movies$DomesticGross)[1] NA\nsummary(movies$DomesticGross)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.02   19.03   37.35   63.22   80.46  381.01       2 \nmovies[is.na(movies$DomesticGross), ]                              Movie LeadStudio\n134                            Hugo  Paramount\n136 Never Back Down 2: The Beatdown       Sony\n    RottenTomatoes AudienceScore   Story     Genre\n134             93            84         Adventure\n136             NA            44 Rivalry    Action\n    TheatersOpenWeek BOAverageOpenWeek DomesticGross\n134             1277              8899            NA\n136               NA                NA            NA\n    ForeignGross WorldGross Budget Profitability\n134           NA         NA     NA            NA\n136           NA         NA      3             0\n    OpeningWeekend\n134          11.36\n136           8.60\nmean(movies$DomesticGross, na.rm=TRUE)[1] 63.22276\nmedian(movies$DomesticGross, na.rm=TRUE)[1] 37.355\nsummary(movies$DomesticGross[-4])   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.02   18.88   37.30   60.83   80.36  352.39       2 \n100*(60.83 - 63.22276)/63.22276 # percent change in the mean[1] -3.78465\n100*(37.30 - 37.355)/37.355 # percent change in the median[1] -0.147236\nsd(movies$DomesticGross, na.rm=TRUE)[1] 69.41799\ntapply(movies$DomesticGross, movies$Genre, summary)$Action\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.54   24.96   40.26   91.02  161.53  352.39       1 \n\n$Adventure\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n     NA      NA      NA     NaN      NA      NA       1 \n\n$Animation\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.39   51.41  115.67  104.62  142.86  191.45 \n\n$Comedy\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   5.79   23.21   37.41   56.51   69.75  254.46 \n\n$Drama\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.38    4.40   13.30   32.37   51.16  169.22 \n\n$Fantasy\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.32   96.24  191.16  191.16  286.09  381.01 \n\n$Horror\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.02   17.69   24.05   34.87   38.18  127.00 \n\n$Romance\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.03   18.51   39.05   61.40   70.26  260.80 \n\n$Thriller\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.02   31.18   40.49   41.44   62.50   79.25 \ntable(movies$Genre)\n   Action Adventure Animation    Comedy     Drama   Fantasy \n       32         1        12        27        21         2 \n   Horror   Romance  Thriller \n       17        11        13 \nwhich(movies$Genre == \"Adventure\")[1] 134\nmovies[134, ]    Movie LeadStudio RottenTomatoes AudienceScore Story\n134  Hugo  Paramount             93            84      \n        Genre TheatersOpenWeek BOAverageOpenWeek\n134 Adventure             1277              8899\n    DomesticGross ForeignGross WorldGross Budget\n134            NA           NA         NA     NA\n    Profitability OpeningWeekend\n134            NA          11.36\nlibrary(ggplot2)\nggplot(movies, aes(x=DomesticGross)) + \n  geom_histogram() + \n  facet_wrap(~Genre)"},{"path":"class-activity-5.html","id":"your-turn-2-3","chapter":"5 Class Activity 5","heading":"5.2 Your turn 2","text":"","code":""},{"path":"class-activity-5.html","id":"example-2-sleep","chapter":"5 Class Activity 5","heading":"5.2.1 Example 2: Sleep","text":"histogram shows distribution hours sleep per night large sample students.(). Estimate average hours sleep per night.(b). Use 95% rule estimate standard deviation data.Answer: data 6 10, mean around 8 (due roughly symmetric distribution). two standard deviations 2 hours sleep, making one standard deviation 1 hours sleep.Let’s check rule. actual mean SD:","code":"\nsleep <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/SleepStudy.csv\")\nhist(sleep$AverageSleep, main=\"Distribution of Sleep Hours\")\nmean(sleep$AverageSleep)[1] 7.965929\nsd(sleep$AverageSleep)[1] 0.9648396"},{"path":"class-activity-5.html","id":"example-3-z-scores-for-test-scores","chapter":"5 Class Activity 5","heading":"5.2.2 Example 3: Z-scores for Test Scores","text":"ACT test population mean 21 standard deviation 5. SAT population mean 1500 standard deviation 325. earned 28 ACT 2100 SAT.(). test better ?Answer:ACT: z-score score 28 \\(z = (28 - 21)/5 = 1.4.\\)SAT: z-score score 2100 \\(z = (2100 - 1500)/325 = 1.85.\\)SAT score 1.85 standard deviations average ACT score 1.4 standard deviations . better SAT.(b). test, find interval likely contain 95% test scores.Answer:ACT: Two standard deviations \\(2(5) = 10.\\) 95% ACT scores \\(21 - 10 = 11\\) \\(21 + 10 = 31.\\) claim assumes ACT scores follow bell-shaped distribution.ACT: Two standard deviations \\(2(5) = 10.\\) 95% ACT scores \\(21 - 10 = 11\\) \\(21 + 10 = 31.\\) claim assumes ACT scores follow bell-shaped distribution.SAT: Two standard deviations \\(2(325) = 650.\\) 95% SAT scores \\(1500 - 650 = 850\\) \\(1500 + 650 = 2150\\). claim assumes SAT scores follow bell-shaped distribution.SAT: Two standard deviations \\(2(325) = 650.\\) 95% SAT scores \\(1500 - 650 = 850\\) \\(1500 + 650 = 2150\\). claim assumes SAT scores follow bell-shaped distribution.","code":""},{"path":"class-activity-5.html","id":"example-4-5-number-summaries","chapter":"5 Class Activity 5","heading":"5.3 Example 4: 5 number summaries","text":"five number summary , indicate whether data appear symmetric, skewed right, skewed left.(). (2, 10, 15, 20, 69)(b). (10, 57, 85, 88, 93)(c). (200, 300, 400, 500, 600)","code":"\nmy_vector1 <- c(1, 10, 15, 20, 69)\nsummary(my_vector1)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1      10      15      23      20      69 \nmy_vector2 <- c(10, 57, 85, 88, 93)\nsummary(my_vector2)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0    57.0    85.0    66.6    88.0    93.0 \nmy_vector3 <- c(200, 300, 400, 500, 600)\nsummary(my_vector3)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    200     300     400     400     500     600 "},{"path":"class-activity-5.html","id":"example-5-hot-dog","chapter":"5 Class Activity 5","heading":"5.4 Example 5: Hot dog","text":"boxplot shows number hot dogs eaten winners Nathan’s Famous hot dog eating contests 2002-2011.(). Use boxplot estimate 5 number summary IQR data.(b). Computing 5 number summariesR doesn’t ‘5 number summary’ command, summary gives “6” number summary adding mean 5 number summary. can also use IQR get IQR:close guesses boxplot values given command?(c). Use boxplot outlier rule verify outliers data.Answer:\\(1.5IQR = 18\\) hotdogs.Lower fence: \\(Q1 - 1.5 IQR = 54 - 18 = 32 < min\\) low outliers.Upper fence: \\(Q3 + 1.5 IQR = 65 + 18 = 83 > max\\) high outliers.","code":"\nhotdogs <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HotDogs.csv\")\nboxplot(hotdogs$HotDogs, xlab=\"Number of Hot Dogs Consumed\", horizontal=T)\nsummary(hotdogs$HotDogs)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  45.00   54.00   60.00   58.64   65.00   69.00 \nIQR(hotdogs$HotDogs)[1] 11"},{"path":"class-activity-5.html","id":"examples-6-hollywood-movies-world-gross-revisited","chapter":"5 Class Activity 5","heading":"5.5 Examples 6: Hollywood Movies World Gross revisited","text":"Let’s revist WorldGross analysis Hollywood movies data set:(). Draw boxplot WorldGross.many movies identified outliers world gross?(b). Calculating boxplot valuesUse boxplot outlier rule find “fence” (cutoff) outlier non-outlier WorldGross. determine value (WorldGross) upper “whisker” (non-outlier) extends .\\(1.5IQR = 1.5(142.985) = 214.48\\) hundred million dollars\\(1.5IQR = 1.5(142.985) = 214.48\\) hundred million dollarsLower fence: \\(Q1 - 1.5IQR = 30.710 - 214.48 = -183.8 < min\\) low outliers.Lower fence: \\(Q1 - 1.5IQR = 30.710 - 214.48 = -183.8 < min\\) low outliers.Upper fence: \\(Q3 + 1.5IQR = 173.7 + 214.48 = 388.18 < max\\) high outliers.Upper fence: \\(Q3 + 1.5IQR = 173.7 + 214.48 = 388.18 < max\\) high outliers.upper whisker extends largest movie value fence 388.18. look data spreadsheet find movie comes closest fence, quicker way use R. First can use find row numbers movies less 388.18 WorldGross. use set find max WorldGross within group movies, turns 368.404 hundred million dollars.upper whisker extends largest movie value fence 388.18. look data spreadsheet find movie comes closest fence, quicker way use R. First can use find row numbers movies less 388.18 WorldGross. use set find max WorldGross within group movies, turns 368.404 hundred million dollars.(c). Side--side boxplotWe can compare boxplots WorldGross across Genre categories:type graph illustrate well relationship WorldGross Genre?type graph illustrate well relationship WorldGross Genre?one issue default version graph?(d). Improving default boxplotThere many values Genre data values (levels) longer names. can cause issues using names label graphs, like x-axis boxplot. many (many, many) ways modify graphs R. one way change label orientation x-axis.las arguments let’s change orientation axis labels relative axis. value 2 makes labels perpendicular axis.","code":"\nmovies <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HollywoodMovies2011.csv\")\nboxplot(movies$WorldGross)\nsummary(movies$WorldGross)    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   0.025   30.706   76.659  150.742  173.691 1328.111 \n    NA's \n       2 \nIQR(movies$WorldGross, na.rm = TRUE)[1] 142.9851.5*IQR(movies$WorldGross, na.rm = TRUE)\n[1] 214.4775\n30.710 - 214.48\n[1] -183.77\n173.7 + 214.48\n[1] 388.18notoutliers <- which(movies$WorldGross < 388.18)\nmax(movies$WorldGross[notoutliers])\n[1] 368.404\nwhich(movies$WorldGross == 368.404)\n[1] 49\nmovies[49,]\n                                Movie LeadStudio\n49 Captain America: The First Avenger     Disney\n   RottenTomatoes AudienceScore         Story  Genre\n49             78            75 Metamorphosis Action\n   TheatersOpenWeek BOAverageOpenWeek DomesticGross\n49             3715             17512        176.65\n   ForeignGross WorldGross Budget Profitability\n49       191.75    368.404    140      2.631457\n   OpeningWeekend\n49          65.06\nboxplot(WorldGross ~ Genre, data=movies)\nboxplot(WorldGross ~ Genre, data=movies, las=2)"},{"path":"class-activity-5.html","id":"example-8-ants-on-a-sandwich","chapter":"5 Class Activity 5","heading":"5.6 Example 8: Ants on a Sandwich","text":"number ants climbing piece peanut butter sandwich left ground near anthill minutes measured 7 different times results :\n\\(43, 59, 22, 25, 36, 47, 19\\)(). Calculate mean number ants.(b). Calculate median number ants.(c). Calculate quartiles number ants.","code":""},{"path":"class-activity-6.html","id":"class-activity-6","chapter":"6 Class Activity 6","heading":"6 Class Activity 6","text":"","code":""},{"path":"class-activity-6.html","id":"your-turn-1-4","chapter":"6 Class Activity 6","heading":"6.1 Your Turn 1","text":"","code":""},{"path":"class-activity-6.html","id":"beer-example","chapter":"6 Class Activity 6","heading":"6.1.1 Beer Example","text":"study 16 Ohio State University students looked relationship number beers student consumes blood alcohol content (BAC) 30 minutes last beer. regression information R predict BAC number beers consumed given .(). Always start visual!!!!Plot response (BAC) y-axis explanatory (“predictor”) x-axis.relationship?\ndirection?\nstrength?\nform?\ndirection?strength?form?can modify basic graph adding title changing plotting symbol. pch=19 argument changes symbols filled circles.(b). Computing correlationSince form relationship linear, can use correlation measure strength:(c). Fitting regression lineWe use lm(y ~ x, data=mydata) function fit linear (regression) model response y given explanatory variable x. command creates linear model object needs assigned name, call bac.lm. can get slope intercept typing object name:running lm command R console, check Environment tab see object bac.lm now one objects stored R’s memory (session Rstudio).running lm command R console, check Environment tab see object bac.lm now one objects stored R’s memory (session Rstudio).Write fitted regression equation predict BAC number beers.Write fitted regression equation predict BAC number beers.Answer: \\(\\hat{y} = \\ldots\\)can add regression line scatterplot part () creating plot using abline command:(d). Interpret slope context.(e). Interpret intercept context, makes sense .(f). friend Ohio State drank 2 beers, predict BAC ?Answer: predicted BAC \n\\[\n\\widehat{BAC} = -0.0127 + 0.0180(2) = 0.0233.\n\\]Answer: residual \n\\[\nBAC - \\widehat{BAC} = .03 - .0233=0.0067\n\\](h). Getting residuals RWe can use resid command get residuals case data set:Notice case 2 data drank 2 beers BAC recorded 0.03. can see residual value matches answer (g) rounding error.can use summary command lm object get detailed print linear model, along \\(R^2\\) value model:(j). Making residuals plotThe regression BAC Beers residuals plot plots model’s residuals y-axis explantory (“predictor”) x-axis. add horizontal reference line (detrended regression line) abline(h=0) command:magnitude scatter around horizontal 0-line residuals plot greater , less , magnitude scatter around regression line scatterplot?\n(k). Identifying points\ncommand can used identify points row number scatterplot.can use == see case drank exactly 9 beers. row number case drank 9 beers?row number case negative residual?eyeball graph see negative residual less -0.02:identifies 3 cases. also can see lowest residual drank 5 beers. can add statement original one using “” sign &:(l). Checking outlier influenceWill regression line slope increase, decrease stay remove case 3, 9 beer case, model?Check answer adding subset = -3 lm command (removes row 3):removing case 3, slope changed? Explain change occurred.removing case 3, \\(R^2\\) changed? Explain change occurred.(m). Adding categorical variable plotWe can create scatterplot plotting symbols color coded categorical grouping variable using ggplot2 package. use geom_point() plot geometry get scatterplot x, y, color aesthetics specified. look BAC vs. Beers plot Gender added:associations similar? (form, strength, direction)(n). Regression lines groupsA quick way get male female regression line formulas part (c) add subset argument lm command:regression line females? males?gender largest slope? suggest relationship number beers BAC gender?Answer: slope females slightly higher. shows effect one beer predicted BAC females larger males (0.021 increase vs. 0.015 increase).Another way obtain regression models Gender split data set female male data set, run lm two data sets. benefit method can create residuals plot model much easier quicker method :","code":"\nbac <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/BAC.csv\")\nplot(BAC ~ Beers, data=bac)  \nplot(BAC ~ Beers, data=bac, pch=19, \n     main=\"Beer and BAC\", xlab=\"Number of beers drank\", ylab = \"Blood Alcohol Content\")\ncor(bac$BAC, bac$Beers)[1] 0.8943381\nbac.lm <- lm(BAC ~ Beers, data=bac)\nbac.lm\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nCoefficients:\n(Intercept)        Beers  \n   -0.01270      0.01796  \n# Need to call the plot function again!!\n\nplot(BAC ~ Beers, data=bac, pch=19, \n     main=\"Beer and BAC\", xlab=\"Number of beers drank\", ylab = \"Blood Alcohol Content\")\nabline(bac.lm) # adds regression line to the plot above\ny.hat <- -0.0127 + 0.0180*(2) \ny.hat[1] 0.0233\n0.03 - (-0.0127 + 0.0180*(2)) [1] 0.0067\n# part h\nresid(bac.lm)           1            2            3            4 \n 0.022881795  0.006773080  0.041026747 -0.011009491 \n           5            6            7            8 \n-0.001190682 -0.018045729  0.028809318 -0.017118205 \n           9           10           11           12 \n-0.021190682 -0.027118205  0.010845557  0.004918033 \n          13           14           15           16 \n 0.007881795 -0.023045729  0.004736842 -0.009154443 \n# part h\nbac$BAC[2][1] 0.03\nbac$Beers[2][1] 2\nresid(bac.lm)[2]         2 \n0.00677308 \nsummary(bac.lm)\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.027118 -0.017350  0.001773  0.008623  0.041027 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.012701   0.012638  -1.005    0.332    \nBeers        0.017964   0.002402   7.480 2.97e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02044 on 14 degrees of freedom\nMultiple R-squared:  0.7998,    Adjusted R-squared:  0.7855 \nF-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06\n# code for residual plot\nplot(resid(bac.lm) ~ Beers, data=bac, pch=19, main = \"residuals plot\")  \nabline(h=0)\nplot(BAC ~ Beers, data=bac, pch=19)  \nwhich(bac$Beers == 9)[1] 3\nplot(resid(bac.lm) ~ Beers, data=bac, pch=19)  \nabline(h=0)\n# which case has resid less than -0.02?\n\nresid(bac.lm)[which(resid(bac.lm) < -0.02)]          9          10          14 \n-0.02119068 -0.02711821 -0.02304573 \n# which case had resid less than -0.02 AND drank 5 beers\nresid(bac.lm)[which(resid(bac.lm) < -0.02 & bac$Beers == 5)]         10 \n-0.02711821 \n# define a different linear model with row 3 removed \nbac.lm2 <- lm(BAC ~ Beers, data=bac, subset = -3)\n# Compare the two models\nsummary(bac.lm2)\nCall:\nlm(formula = BAC ~ Beers, data = bac, subset = -3)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.023685 -0.010068 -0.003685  0.011985  0.027208 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 2.481e-05  1.088e-02   0.002    0.998    \nBeers       1.455e-02  2.216e-03   6.568  1.8e-05 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01624 on 13 degrees of freedom\nMultiple R-squared:  0.7684,    Adjusted R-squared:  0.7506 \nF-statistic: 43.14 on 1 and 13 DF,  p-value: 1.802e-05\nsummary(bac.lm)\nCall:\nlm(formula = BAC ~ Beers, data = bac)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.027118 -0.017350  0.001773  0.008623  0.041027 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.012701   0.012638  -1.005    0.332    \nBeers        0.017964   0.002402   7.480 2.97e-06 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02044 on 14 degrees of freedom\nMultiple R-squared:  0.7998,    Adjusted R-squared:  0.7855 \nF-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06\nlibrary(ggplot2)\nggplot(bac, aes(x=Beers, y=BAC, color=Gender)) + geom_point()\nbac.lm.female <- lm(BAC ~ Beers, data=bac, subset = Gender == \"female\")\nbac.lm.female \nCall:\nlm(formula = BAC ~ Beers, data = bac, subset = Gender == \"female\")\n\nCoefficients:\n(Intercept)        Beers  \n   -0.01567      0.02067  \n# enter code for the male model\n\nbac.lm.male <- lm(BAC ~ Beers, data=bac, subset = Gender == \"male\")\nbac.lm.male\nCall:\nlm(formula = BAC ~ Beers, data = bac, subset = Gender == \"male\")\n\nCoefficients:\n(Intercept)        Beers  \n  -0.009785     0.015341  \nbac.female <- subset(bac, sub = Gender == \"female\")\nlm(BAC ~ Beers, data=bac.female)\nCall:\nlm(formula = BAC ~ Beers, data = bac.female)\n\nCoefficients:\n(Intercept)        Beers  \n   -0.01567      0.02067  \nbac.male <- subset(bac, sub = Gender == \"male\")\nlm(BAC ~ Beers, data=bac.male)\nCall:\nlm(formula = BAC ~ Beers, data = bac.male)\n\nCoefficients:\n(Intercept)        Beers  \n  -0.009785     0.015341  "},{"path":"class-activity-6.html","id":"your-turn-2-4","chapter":"6 Class Activity 6","heading":"6.2 Your Turn 2","text":"","code":""},{"path":"class-activity-6.html","id":"mice-mass-example","chapter":"6 Class Activity 6","heading":"6.2.1 Mice Mass Example","text":"time day calories consumed can affect weight gain. least, appears true mice. Mice normally eat calories night, mice ate calories day (mice supposed sleeping), gained weight even though mice ate total amount calories. look regression body mass gain grams, BMGain, percent calories eaten day, DayPct study involving 27 mice. R commands needed answer questions :(). coordinates (roughly) case largest positive residual?(b). coordinates (roughly) case negative residual?(c). predicted body mass gain mouse eats 50% calories day?\\[\n\\widehat{BMGain} =1.1128+0.1273(50)=7.48\n\\](d). Find residual mouse ate 48.3% calories day gained 5.82 grams.Answer: first find predicted body mass gain:\n\\[\n\\widehat{BMGain} = 1.1128+0.1273(48.3)=7.26\n\\]residual :\\[\nResidual = BMGain  -   \\widehat{BMGain} =  5.82 – 7.26 = –1.44.\n\\](e). Interpret slope regression line context.(f). Interpret intercept line context, makes sense .(g). Use correlation value compute \\(R^2\\), interpret (context) \\(R^2\\) value model.(h). Get value \\(R^2\\) regression output, interpret (context) \\(R^2\\) value model.Answer: Multiple R-squared, get \\(R^2 = 0.547\\). percent calories mouse eats day explains 55% variability weight gain study.","code":"\nmice <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/MICE.csv\")\n  \nplot(BMGain ~ DayPct, data=mice, pch=19)\nmice.lm <- lm(BMGain ~ DayPct, data=mice)\nmice.lm\nCall:\nlm(formula = BMGain ~ DayPct, data = mice)\n\nCoefficients:\n(Intercept)       DayPct  \n     1.1128       0.1273  \ncor(mice$BMGain, mice$DayPct)[1] 0.7398623\nabline(mice.lm) # adds regression line to previously created scatterplot\nmice[which(resid(mice.lm) == max(resid(mice.lm))),]    X Light BMGain Corticosterone DayPct Consumption\n25 25    LL   17.4         66.679 81.636       7.177\n   GlucoseInt   GTT15  GTT120 Activity\n25        Yes 435.644 405.941     6702\nmice[which(resid(mice.lm) == min(resid(mice.lm))),]    X Light BMGain Corticosterone DayPct Consumption\n10 10    DM   3.42         208.26 55.051       3.857\n   GlucoseInt   GTT15  GTT120 Activity\n10         No 271.717 148.485     1084\n1.1128 + .1273*50[1] 7.4778\n1.1128 + .1273*48.3[1] 7.26139\n5.82 - (1.1128 + .1273*48.3)[1] -1.44139\nr <- 0.7398623\nr^2[1] 0.5473962\nsummary(mice.lm)\nCall:\nlm(formula = BMGain ~ DayPct, data = mice)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6990 -1.1694  0.0728  0.9174  5.8975 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.11280    1.38211   0.805    0.428    \nDayPct       0.12727    0.02315   5.499 1.03e-05 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.231 on 25 degrees of freedom\nMultiple R-squared:  0.5474,    Adjusted R-squared:  0.5293 \nF-statistic: 30.24 on 1 and 25 DF,  p-value: 1.032e-05"},{"path":"class-activity-6.html","id":"forbes-example","chapter":"6 Class Activity 6","heading":"6.2.2 Forbes Example","text":"mid 1800s, James D. Forbes conducted experiments designed determine atmospheric pressure given location can just determined boiling temp water location.(). Fit linear regression Pressure Temp:Describe relationship pressure temp (strength, form, direction).Interpret value \\(R^2\\)(b). Check residuals plotIs relationship pressure temp linear?residual plot highlight unusual case? Explain.(c). “Fixing” modelA linear model can used data transform response variable logarithmic scale. log(y) gives natural log variable y.curvature scatterplot residuals plots reduced logging variables?outlier eliminated logging variables?(d). Removing bad measurementIdentify case large residual value around 0.03.Repeat part (c) time remove case identified. easiest way create new version data row 12 removed:","code":"\nforbes <-  read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/forbes.csv\")\nplot(Pressure ~ Temp, data=forbes, pch=19, main = \"Pressure vs. Temp\")\nforbes.lm <- lm(Pressure ~ Temp, data=forbes)\nabline(forbes.lm)\nsummary(forbes.lm)\nCall:\nlm(formula = Pressure ~ Temp, data = forbes)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.25717 -0.11246 -0.05102  0.14283  0.64994 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -81.06373    2.05182  -39.51   <2e-16 ***\nTemp          0.52289    0.01011   51.74   <2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2328 on 15 degrees of freedom\nMultiple R-squared:  0.9944,    Adjusted R-squared:  0.9941 \nF-statistic:  2677 on 1 and 15 DF,  p-value: < 2.2e-16\nplot(resid(forbes.lm) ~ Temp, data=forbes, pch=19, main = \"Residuals plot\")\nabline(h=0)\nplot(log(Pressure) ~ Temp, data=forbes, pch=19, main = \"Pressure vs. Temp\")\nforbes.lm2 <- lm(log(Pressure) ~ Temp, data=forbes)\nabline(forbes.lm2)\nplot(resid(forbes.lm2) ~ Temp, data=forbes, pch=19, main = \"Residuals plot\")\nabline(h=0)\nresid(forbes.lm2)[which(resid(forbes.lm2) > 0.02)]        12 \n0.03131388 \nforbes2 <- forbes[-12, ]\nplot(log(Pressure) ~ Temp, data=forbes2, pch=19, main = \"Pressure vs. Temp\")\nforbes.lm2 <- lm(log(Pressure) ~ Temp, data=forbes2)\nabline(forbes.lm2)\nplot(resid(forbes.lm2) ~ Temp, data=forbes2, pch=19, main = \"Residuals plot\")\nabline(h=0)"},{"path":"class-activity-7.html","id":"class-activity-7","chapter":"7 Class Activity 7","heading":"7 Class Activity 7","text":"","code":""},{"path":"class-activity-7.html","id":"your-turn-1-5","chapter":"7 Class Activity 7","heading":"7.1 Your Turn 1","text":"","code":""},{"path":"class-activity-7.html","id":"parameters-and-statistics","chapter":"7 Class Activity 7","heading":"7.1.1 Parameters and Statistics","text":"notations useful . Look codes produce associated Rmd file.","code":""},{"path":"class-activity-7.html","id":"example-1-parameters-and-statistics","chapter":"7 Class Activity 7","heading":"7.1.2 Example 1: Parameters and Statistics","text":"following, state whether quantity described parameter statistic, give correct notation.(c). difference proportion ever smoked cigarettes, sample 500 people 60 years old sample 200 people 25 years old.(d). correlation weight height 5-year old kids.","code":""},{"path":"class-activity-7.html","id":"example-2-using-search-engines-on-the-internet","chapter":"7 Class Activity 7","heading":"7.1.3 Example 2: Using Search Engines on the Internet","text":"2012 survey random sample 2253 US adults found 1,329 reported using search engine (Google) every day find information Internet.(). Find relevant proportion give correct notation .Answer: \\(\\hat{p} = 1329/2253\\)b). answer part () parameter statistic?c). Give notation define population parameter estimate using result part ().","code":"\np.hat <- 1329/2253\np.hat[1] 0.5898802"},{"path":"class-activity-7.html","id":"your-turn-2-5","chapter":"7 Class Activity 7","heading":"7.2 Your Turn 2","text":"","code":""},{"path":"class-activity-7.html","id":"example-3-simulation-of-a-sample-proportion","chapter":"7 Class Activity 7","heading":"7.2.1 Example 3: Simulation of a Sample Proportion","text":"According PEW survey, \\(66\\%\\) U.S. adult citizens casted ballot 2020 election. Suppose take random sample \\(n=100\\) eligible U.S. voters computed sample proportion voted.(). Generate random sample size \\(n= 100\\) plot sample proportion.(b). Generate 5 random samples size \\(n= 100\\) plot sample proportions.(c). Generate 1000 random samples size \\(n= 100\\) plot sample proportions.Question: dot represent?Answer:Answer:(d). Repeat part(c) sample size 20 instead 100. Generate 1000 samples.Question: sampling distribution changed? (Shape? Center? Variability?)Answer: shape slightly left skewed, still centered 0.66 variability (SD 0.10). distribution discrete looking just sample proportions possible n=20 (e.g. 20/20, 19/20, 18/20, etc).(e). Now suppose population proportion \\(p=0.90\\) instead \\(p=0.66\\) part (e). Keep n.size=20.Question: sampling distribution changed? (Shape? Center? Variability?)Answer: shape much left skewed p=0.66. Center around 0.90 SD around 0.07. Note increasing population proportion closer 1 results decrease SD samples give proportion near 1.","code":"\n# Define parameters\nset.seed(123) # set seed for reproducibility\npop.prop <- .66 # Population proportion\nn.size <- 100  # sample size\n# Generate 1 sample\nsample1 <- rbinom(n = 1, size = n.size, p = pop.prop) # R simulates the samples\nsample.prop1 <- sample1/n.size #  Proportion = No. of Success / Sample Size\n# Call the library\nlibrary(ggplot2)\n# define a data frame\nmydata <- data.frame(x = sample.prop1)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = sample.prop1)) +\n  geom_dotplot(dotsize=0.25, stackratio=0.75, binwidth=0.01) +\n  ggtitle(\"A single sample proportion\") +  xlab(\"Proportion\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(0.4, 0.9))+\n  theme(plot.title = element_text(hjust = 0.5))\n# generate 5 random samples of size 100\nsample5 <- rbinom(n = 5, size = n.size, p = pop.prop)  \nsample.prop5 <- sample5/n.size \n\ndata <- data.frame(x = sample.prop5)\n\nggplot(data, aes(x = sample.prop5)) +\n  geom_dotplot(dotsize=0.25, stackratio=0.9, binwidth=0.01 )+\n  ggtitle(\"\") +  xlab(\"Proportion\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(0.4, 0.9))+ \n  theme(plot.title = element_text(hjust = 0.5))\n# Generate 1000 samples\nsample1000 <- rbinom(n = 1000, size = n.size, p = pop.prop)  \nsample.prop1000 <- sample1000/n.size \n\ndata <- data.frame(x = sample.prop1000)\n\nggplot(data, aes(x = sample.prop1000)) +\n  geom_dotplot(dotsize=0.25, method = \"histodot\", stackratio=0.9, binwidth=0.01) +\n  ggtitle(\"\") +  xlab(\"Proportion\") + ylab(\"Count\") +\n  scale_x_continuous(limits = c(0.4, 0.9))+ \n  theme(plot.title = element_text(hjust = 0.5))\n# r-code\nmean(sample.prop1000)[1] 0.65962\n# r-code\nsd(sample.prop1000)[1] 0.0483176\n# Generate 1000 samples\nn.size <- 20\n\nsample1000 <- rbinom(n = 1000, size = n.size, p = pop.prop)  \nsample.prop1000 <- sample1000/n.size \n\ndata <- data.frame(x = sample.prop1000)\n\nggplot(data, aes(x = sample.prop1000)) +\n  geom_dotplot(dotsize=0.225, method = \"histodot\", stackratio=0.8, binwidth=0.01) +\n  ggtitle(\"\") +  xlab(\"Proportion\") + ylab(\"Count\") +\n  scale_x_continuous(limits = c(0.3, 0.9))+ \n  theme(plot.title = element_text(hjust = 0.5))\nmean(sample.prop1000)[1] 0.65885\nsd(sample.prop1000)[1] 0.1086093\n# Generate 1000 samples\n\npop.prop <- 0.90\nn.size <- 20\nn.size <- 20\n\nsample1000 <- rbinom(n = 1000, size = n.size, p = pop.prop)  \nsample.prop1000 <- sample1000/n.size \n\ndata <- data.frame(x = sample.prop1000)\n\nggplot(data, aes(x = sample.prop1000)) +\n  geom_dotplot(dotsize=0.21, method = \"histodot\", stackratio=0.8, binwidth=0.01) +\n  ggtitle(\"\") +  xlab(\"Proportion\") + ylab(\"Count\") +\n  scale_x_continuous(limits = c(0.4, 0.9))+ \n  theme(plot.title = element_text(hjust = 0.5))\nmean(sample.prop1000)[1] 0.9028\nsd(sample.prop1000)[1] 0.06466329"},{"path":"class-activity-7.html","id":"example-4-simulation-for-a-sample-mean","chapter":"7 Class Activity 7","heading":"7.2.2 Example 4: Simulation for a Sample Mean","text":"’ll look sampling movies population 134 Hollywood movies made 2011 measuring budget (millions dollars).(). population mean Budget?(b). Generate random sample size \\(n= 10\\) plot sample proportion.(c). Generate 5 random samples size \\(n= 10\\) plot sample means.(d). Generate 1000 random samples size \\(n= 10\\) plot sample means.Answer: $53 million, population mean budget.Answer: close population mean.Answer: 14.80 million quite cose previous informed guess.(e). Repeat part(d) sample size 50 instead 10. Generate 1000 samples.Question: sampling distribution less symmetric compared distribution \\(n=10\\)?","code":"\n# import dataset\nlibrary(Lock5Data)\nmovies <- HollywoodMovies2011\n# r-code\nmean(movies$Budget, na.rm = TRUE)[1] 53.48134\n# define a data frame\nn.size <- 10\n\nBudget <- movies$Budget[!is.na(movies$Budget)] # remove NAs\n\nsample1 <- sample(Budget, size = n.size) \nsample.mean1 <- mean(sample1)\n\nmydata <- data.frame(x = sample.mean1)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = sample.mean1)) +\n  geom_dotplot(dotsize=1, stackratio=0.9, binwidth=1) +\n  ggtitle(\"A single sample mean\") +  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+ \n  theme(plot.title = element_text(hjust = 0.5))\nn.size <- 10\nn.rep <- 5\n\nBudget <- movies$Budget[!is.na(movies$Budget)] # remove NAs\n\nsample5 <- lapply(1:5, function(i) sample(Budget, size = n.size)) \nsample.mean5 <- lapply(sample5, function(x) mean(x)) \nsample.mean5 <- unlist(sample.mean5)\n\nmydata <- data.frame(x = sample.mean5)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = sample.mean5)) +\n  geom_dotplot(dotsize=0.9, stackratio=0.9, binwidth=1) +\n  ggtitle(\"A single sample mean\") +  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+ \n  theme(plot.title = element_text(hjust = 0.5))\n# Generate 1000 samples\nn.size <- 10\nn.rep <- 1000\n\nBudget <- movies$Budget[!is.na(movies$Budget)] # remove NAs\n\nsample1000 <- lapply(1:n.rep, function(i) sample(Budget, size = n.size)) \nsample.mean1000 <- lapply(sample1000, function(x) mean(x)) \nsample.mean1000 <- unlist(sample.mean1000)\n\nmydata <- data.frame(x = sample.mean1000)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = sample.mean1000)) +\n  geom_dotplot(dotsize=1, method = \"histodot\", stackratio=0.9, binwidth=1) +\n  ggtitle(\"A single sample mean\") +  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+ \n  theme(plot.title = element_text(hjust = 0.5))\nmean(movies$Budget, na.rm = TRUE)[1] 53.48134\n# r-code\nmean(sample.mean1000)[1] 53.12677\n# r-code\nsd(sample.mean1000)[1] 15.0577\n# Generate 1000 samples\nn.size <- 50\nn.rep <- 1000\n\nBudget <- movies$Budget[!is.na(movies$Budget)] # remove NAs\n\nsample1000 <- lapply(1:n.rep, function(i) sample(Budget, size = n.size)) \nsample.mean1000 <- lapply(sample1000, function(x) mean(x)) \nsample.mean1000 <- unlist(sample.mean1000)\n\nmydata <- data.frame(x = sample.mean1000)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = sample.mean1000)) +\n  geom_dotplot(dotsize=1, method = \"histodot\", stackratio=0.9, binwidth=1) +\n  ggtitle(\"A single sample mean\") +  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+\n  theme(plot.title = element_text(hjust = 0.5))+\n  theme(plot.title = element_text(hjust = 0.5))"},{"path":"class-activity-7.html","id":"example-5-effect-of-sample-size","chapter":"7 Class Activity 7","heading":"7.2.3 Example 5: Effect of sample size","text":"Let’s investigate effect sample size sampling distribution using setting Exercise 1 \\(p=0.66\\). following three sampling distributions corresponding different sample sizes.Question: happens increase sample size?Question: Estimate standard error verify answer previous question.Answer: standard errors ","code":"\nsd(data.size.25$x)[1] 0.09011439\nsd(data.size.100$x)[1] 0.04093137\nsd(data.size.400$x)[1] 0.02311007"},{"path":"class-activity-7.html","id":"example-6-bootstrap-sampling","chapter":"7 Class Activity 7","heading":"7.2.4 Example 6: Bootstrap Sampling","text":"(). Compare center/spread/shape bootstrap distribution distribution computed Ex. 4 (d). Answer questions Ex. 4(d).Answer: shape/center variability bootstrap distribution similar Ex 4 (d)","code":"\n# Movies Example Again!\nBudget <- movies$Budget[!is.na(movies$Budget)]\n\n# Bootstrap samples\nn.size <- 10\nboot.sample1 <- sample(Budget, 10, replace = TRUE) # sampling with replacement\n\nn.rep <- 1000\nboot.sample1000 <- lapply(1:n.rep, function(i) sample(Budget, 10, replace = TRUE))\nboot.samplemean1000 <- lapply(boot.sample1000, function(x) mean(x))\nboot.samplemean1000 <- unlist(boot.samplemean1000)\n# Plot the bootstrap distribution\nmydata <- data.frame(x = boot.samplemean1000)\n\n# Plot a dot plot of the sample proportion\nggplot(mydata, aes(x = boot.samplemean1000)) +\n  geom_dotplot(dotsize=0.9, stackratio=0.9, binwidth=1, method = \"histodot\") +\n  ggtitle(\"Sampling distribution for sample mean\") +  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+ \n  theme(plot.title = element_text(hjust = 0.5))\nmean(mydata$x)[1] 53.23545\nsd(mydata$x)[1] 15.41347"},{"path":"class-activity-8.html","id":"class-activity-8","chapter":"8 Class Activity 8","heading":"8 Class Activity 8","text":"","code":""},{"path":"class-activity-8.html","id":"your-turn-1-6","chapter":"8 Class Activity 8","heading":"8.1 Your Turn 1","text":"","code":""},{"path":"class-activity-8.html","id":"example-1-textbook-prices","chapter":"8 Class Activity 8","heading":"8.1.1 Example 1: Textbook Prices","text":"Prices random sample 10 textbooks (rounded nearest dollar) shown:\\[ \\$132 \\quad \\$87 \\quad \\$185 \\quad \\$52 \\quad \\$23 \\quad \\$147 \\quad \\$125 \\quad \\$93 \\quad \\$85 \\quad \\$72 \\](). sample mean? Verify using r-code.Answer: sample mean \\(\\bar{x} = 100.1\\)(b). Describe carefully use cards create one bootstrap statistic sample. specific.(c). can easily instruct R simple code follows:(d). bootstrap distribution centered? shape expect ?","code":"\nprices <- c(132,87, 185, 52, 23, 147, 125, 93, 85, 72)\nmean(prices)[1] 100.1\nresample <- sample(prices, replace = TRUE)\nresample [1]  93 125 125  72  72  52 147  72  87 185"},{"path":"class-activity-8.html","id":"example-2-statkey-atlanta-commute-distance","chapter":"8 Class Activity 8","heading":"8.1.2 Example 2: Statkey Atlanta Commute Distance","text":"Go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Single Mean, Median, St.Dev”. Change data set Atlanta Commute (Distance). data set gives random sample 500 worker commute distances (miles) metropolitan Atlanta(). Use “Original Sample” pane determine shape 500 commuter distances, along mean standard deviation. Write stats using correct notation.(b). Click “Generate 1 Sample” create one bootstrap sample data. Explain sample generated. Use “Bootstrap Sample” pane find bootstrap statistic computed sample. value bootstrap statistic? Repeat couple times.Answer: bootstrap sample obtained resampling 500 observed commute distances \nreplacement. Basically randomly select 500 distances data (replacement).Answer: bootstrap distribution always centered around statistic bootstrapped. centered around sample mean commute distance 18.16 miles. population mean\ncommute distance unknown!","code":""},{"path":"class-activity-8.html","id":"example-3-statkey-global-warming","chapter":"8 Class Activity 8","heading":"8.1.3 Example 3: Statkey Global Warming","text":"percentage Americans believe global warming? survey 2,251 randomly selected individuals\nconducted October 2010 found 1,328 answered Yes question “solid evidence global\nwarming?” compute bootstrap confidence interval proportion Americans believe \nglobal warming, go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Single Proportion”.(). Enter data survey clicking “Edit Data” button. Enter 2251 sample size 1328 count. sample proportion people believe global warming? Use correct notation!(b). Generate 1 bootstrap sample. Explain sample generated. Use “Bootstrap Sample” pane find bootstrap statistic computed sample. value bootstrap statistic? Repeat couple times.(c). Generate 1000 samples get 1000 bootstrap sample proportions. bootstrap distribution centered population sample proportion? Describe shape center bootstrap distributionAnswer: shape symmetric around center value 0.59, sample proportion population proportion (unknown).(d). Compute 95% confidence interval proportion Americans believe global warming(e). Interpret interval part (d).Answer: Yes, data support claim since confident least 50% Americans believe global warming since lower bound CI 57%.","code":""},{"path":"class-activity-8.html","id":"example-4.-statkey-global-warming-by-political-party","chapter":"8 Class Activity 8","heading":"8.1.4 Example 4. Statkey Global Warming by Political Party","text":"belief global warming differ political party? question “solid evidence global warming?” asked, sample proportion answering “yes” 79% among Democrats 38% among\nRepublicans. compute bootstrap confidence interval difference proportion Democrats\nRepublicans believe global warming, go website Lock5Statkey. “Bootstrap Confidence Intervals” column, select “CI Difference Proportions”.(). Enter data survey clicking “Edit Data” button. One big assumption make sample sizes groups (Dems Reps) 1000. Enter Democrat data “Group 1” boxes (count 790 size 1000) Republican data “Group 2” boxes (count 380 size 1000). Verify sample proportions two groups 79% 38%. difference two sample proportions? Use correct notation.(b). Generate 1 bootstrap sample. Explain sample generated (give thought now two samples data). Use “Bootstrap Sample” pane find bootstrap statistic computed sample. value bootstrap statistic? Repeat couple times.Answer: One bootstrap sample obtained group 1 sample (resampling observed “believe/believe” responses replacement) separate bootstrap sample obtained group 2 sample. difference bootstrap proportions group computed bootstrap difference statistic.(c). Generate 1000 samples get 1000 bootstrap sample proportion differences. Describe shape center bootstrap distributionAnswer: shape symmetric around center value 0.41 (sample difference proportions).(d). Compute 95% confidence interval difference proportion Democrats Republicans believe global warming.(e). Interpret interval part (d) context without using word difference!! (.e. give directional claim uses words like “” “less”)(f). compute interval, assumed 1000 people sampled subpopulation (Dems Reps). Suppose sample size just 500 people group. 95% confidence interval wider shorter one computed part (d)? Explain.","code":""},{"path":"class-activity-8.html","id":"example-5-statkey-body-temperature","chapter":"8 Class Activity 8","heading":"8.1.5 Example 5: Statkey Body Temperature","text":"normal body temperature really \\(98.6^{\\circ}\\) F? sample body temperature 50 healthy individuals taken. Find dataset StatKey “Confidence Interval Mean.”(). sample mean? sample standard deviation? Use correct notation (b). Generate bootstrap distribution, using least 1000 simulated statistics. standard\nerror?Use standard error find 95% confidence interval. Show work. 98.6 interval?Answer: \\[ \\bar{x} \\pm 2*SE\\]\n\\[98.26 \\pm 2(0.108) \\]\n\\[(98.04, 98.48) \\]\nsee 98.6 interval.","code":""},{"path":"class-activity-8.html","id":"example-6.-bootstrap-in-r-using-hollywood-2011-dataset","chapter":"8 Class Activity 8","heading":"8.1.6 Example 6. Bootstrap in R using Hollywood 2011 dataset!","text":"’ll look sampling movies population 134 Hollywood movies made 2011 measuring budget (millions dollars). Construct bootstrap sampling distribution budgets (millions dollars) movies come Hollywood 2011, using samples size n = 50.Generate 1 sample size 50 replacement Budget variable. NA values, removed first.Generate 1000 samples size 50 replacement redefined Budget variable part (). many methods . use lapply function simulation faster. Using lapply can apply functions list vector.Make dotplot 1000 sample means calculated part (c). function ggplot2 geom_dotplot. two methods binning data values. dotdensity default option dot-density binning histodot fixed bin width like histogram.","code":"\n# import dataset\nmovies <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/HollywoodMovies2011.csv\")\n# remove the NA values\nBudget <- movies$Budget[!is.na(movies$Budget)]\n# Bootstrap samples\nn.size <- 50\nboot.sample1 <- sample(Budget, size = n.size, replace = TRUE) # sampling with replacement\nn.rep <- 1000\n# replicate the sampling with replacement 1000 times\nboot.sample1000 <- lapply(1:n.rep, function(x) sample(Budget, size = n.size, replace = TRUE))\n\n# Calculate the mean of each resample\nboot.samplemean1000 <- lapply(boot.sample1000, function(x) mean(x))\n\n# Transform the list back to a vector for further computations\nboot.samplemean1000 <- unlist(boot.samplemean1000)\n# Plot the bootstrap distribution\n\nboot.samples <- data.frame(samples = boot.samplemean1000) # define a data frame\n\n# Plot a dot plot of the sample proportion\nggplot(boot.samples, aes(x = samples)) +\n  geom_dotplot(dotsize=0.9, stackratio=0.9, binwidth=1, method = \"histodot\") +\n  xlab(\"Sample mean\") + ylab(\"Count\")+\n  scale_x_continuous(limits = c(1,120))+ \n  ggtitle(\"Bootstrap sampling distribution for sample mean\") +  \n  theme(plot.title = element_text(hjust = 0.5))"},{"path":"class-activity-8.html","id":"example-7-the-data-set-creditdata.csv-contains-records-for-1000-loans-that-either-defaulted-badloan-or-did-not-default-goodloan.-there-are-300-loans-that-defaulted-and-700-that-did-not.-lets-consider-that-the-300-loans-that-defaulted-are-random-sample-of-loans-that-default-and-the-700-non-defaulting-loans-are-a-random-sample-of-loans-that-dont-default.","chapter":"8 Class Activity 8","heading":"8.1.7 Example 7: The data set CreditData.csv contains records for 1000 loans that either defaulted (BadLoan) or did not default (GoodLoan). There are 300 loans that defaulted and 700 that did not. Let’s consider that the 300 loans that defaulted are random sample of loans that default and the 700 non-defaulting loans are a random sample of loans that don’t default.","text":"Visualize age vs. defaultThe variable Age..years gives age person received loan. Construct side--side boxplot age Good.Loan compute sample means group.mean ages group?Describe distribution ages group. outliers overly influential value(s) sample mean(s)?Bootstrap CI difference meansThe boot(y ~ x, data=) command generates 10000 bootstrap samples true difference means y two groups x. command contained CarletonStats package. use compute bootstrap distribution difference mean ages two default groups:Give difference sample mean ages reported output. Use correct notation.Give 95% confidence interval difference mean ages using percentile methodCompute 95% confidence interval difference mean ages using bootstrap SE. similar CI percentile method?Answer: CI using SE -3.8 -0.7. intervals similar.\\[\n-2.26095 \\pm 2(0.77852) = (-3.81799,  -0.70391)\n\\]InterpretInterpret percentile interval context using directional statement. interval suggest mean ages differ population good bad loan holders?","code":"\ncredit <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/CreditData.csv\")\ntable(credit$Good.Loan)\n BadLoan GoodLoan \n     300      700 \nboxplot(Age.in.years ~ Good.Loan, data=credit)\ntapply(credit$Age.in.years, credit$Good.Loan, mean) BadLoan GoodLoan \n33.96333 36.22429 \nlibrary(CarletonStats)\nboot(Age.in.years ~ Good.Loan, data=credit)\n    ** Bootstrap interval for difference of statistic\n\n Observed difference of statistic:  BadLoan - GoodLoan =  -2.26095 \n Mean of bootstrap distribution: -2.25634 \n Standard error of bootstrap distribution: 0.77833 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-3.7604762 -0.6985595 \n\n        *--------------*\n-2.26095 - 2*(0.77852)[1] -3.81799\n-2.26095 + 2*(0.77852)[1] -0.70391"},{"path":"class-activity-8.html","id":"example-8-credit-data-continued","chapter":"8 Class Activity 8","heading":"8.1.8 Example 8 : Credit data continued","text":"variable Telephone tells us individual phone number loan file. Let’s look proportion individuals phone number type loan (default ).(). Data clean \nentries Telephone column either none yes, registered customers name.make shorter names describing two outcomes, can use levels command factor variable Telephone. see original levels variable:shows us (vector) two names. can assign new, shorter names variable:Now data, just coded different names.(b). Phone rate default typeHere get distribution phone numbers (yes ) default type (good vs bad loan):proportion bad loans phone number account?proportion good loans phone number account?sample difference proportion good loans bad loans phone number? Use correct notation number.Answer: get \\(\\hat{p}_{good} - \\hat{p}_{bad} =0.4157143 - 0.3766667 = 0.0390476\\).(c). Using boot command categorical responseIn order get bootstrap distribution sample difference proportions, need recode “response” variable Telephone 1 indicating “yes” response 0 indicating “” response. done ifelse command:reads “Telephone equals yes assign 1, else assign 0”. 0’s 1’s assigned variable called Telephone_binary now data frame (checked View(credit) command).Check work make sure Telephone_binary records want recordThe mean 0/1 coded variable computes proportion “yes” responses:Note: examples Lab Manual already 0/1 recoding done lab manual data sets. thought might want learn recoding case plan use command , non-lab manual data sets!(d). 95% confidence interval difference phoneWe can now use 0/1 version telephone boot command (like example 1) compute 95% bootstrap confidence interval difference population proportion good loans bad loans phone number.Even though language used output says “statistic” computing difference “proportions”!!Give 95% confidence interval difference population proportion bad loans good loans phone number using percentile methodGive 95% confidence interval difference population proportion bad loans good loans phone number using bootstrap SE. similar CI percentile method?Answer: SE method gives interval Bad \\(-\\) Good -0.107 0.028 similar percentile interval.(e). InterpretInterpret percentile interval context using directional statement. interval suggest difference percentage bad loan holders provided phone number compared percentage good loan holders gave number? Explain.Answer: 95% confident percentage good loan accounts phone number anywhere 10.7 percentage points higher 2.8 percentage points less percentage bad loans phone number.","code":"\ntable(credit$Telephone)\n                                    none \n                                     596 \nyes, registered under the customers name \n                                     404 \ncredit$Telephone <- factor(credit$Telephone)\nlevels(credit$Telephone)[1] \"none\"                                    \n[2] \"yes, registered under the customers name\"\nlevels(credit$Telephone) <- c(\"no\", \"yes\")\ntable(credit$Telephone)\n no yes \n596 404 \nprop.table(table(credit$Good.Loan, credit$Telephone),1)          \n                  no       yes\n  BadLoan  0.6233333 0.3766667\n  GoodLoan 0.5842857 0.4157143\nlibrary(ggplot2)\nggplot(credit, aes(x=Good.Loan, fill=Telephone)) + geom_bar(position=\"fill\")\n0.4157143 - 0.3766667[1] 0.0390476\ncredit$Telephone_binary <- ifelse(credit$Telephone == \"yes, registered under the customers name\", 1, 0)\nhead(credit[,c(\"Telephone\", \"Telephone_binary\")])  Telephone Telephone_binary\n1       yes                0\n2        no                0\n3        no                0\n4        no                0\n5        no                0\n6       yes                0\ntable(credit$Telephone)\n no yes \n596 404 \ntable(credit$Telephone_binary)\n   0 \n1000 \nmean(credit$Telephone_binary)[1] 0\n404/1000  # proportion of yes[1] 0.404\nboot(Telephone_binary ~ Good.Loan, data=credit)\n    ** Bootstrap interval for difference of statistic\n\n Observed difference of statistic:  BadLoan - GoodLoan =  0 \n Mean of bootstrap distribution: 0 \n Standard error of bootstrap distribution: 0 \n\n Bootstrap percentile interval\n 2.5% 97.5% \n    0     0 \n\n        *--------------*\n-0.03905 - 2* 0.03373 [1] -0.10651\n-0.03905 + 2* 0.[1] -0.03905"},{"path":"class-activity-9.html","id":"class-activity-9","chapter":"9 Class Activity 9","heading":"9 Class Activity 9","text":"","code":""},{"path":"class-activity-9.html","id":"example-1-a-muslim-president","chapter":"9 Class Activity 9","heading":"9.0.1 Example 1: A Muslim president?","text":"survey 1,527 American adults conducted June 2015 stated 60% vote qualified Muslim presidential candidate. survey goes say “… margin sampling error +/- 3 percentage points 95% confidence level.”","code":""},{"path":"class-activity-9.html","id":"example-2-biomass-in-tropical-forests","chapter":"9 Class Activity 9","heading":"9.0.2 Example 2: Biomass in Tropical Forests","text":"Using random sample 4079 inventory plots, scientists found sample average 11,600 tons carbon per square kilometer standard error 1000 tons. Give 95% confidence interval mean amount carbon per square kilometer tropical forests. Clearly interpret meaning confidence interval.","code":""},{"path":"class-activity-9.html","id":"example-3-change-in-gun-ownership","chapter":"9 Class Activity 9","heading":"9.0.3 Example 3: Change in gun ownership?","text":"2016 study described Guardian found random sample US adults 1994 found female rate gun ownership 9%. similar random sample 2015 found rate female gun ownership rose 12%. Though given article, let’s assume SE difference two sample proportions 2%.","code":""},{"path":"class-activity-9.html","id":"example-4-interpreting-a-confidence-interval","chapter":"9 Class Activity 9","heading":"9.0.4 Example 4: Interpreting a Confidence Interval","text":"Using sample 24 deliveries described “Diary Pizza Girl” Slice website, find 95% confidence interval mean tip given pizza delivery $2.18 $3.90. following correct interpretation interval? Indicate correct interpretations.","code":""},{"path":"class-activity-10.html","id":"class-activity-10","chapter":"10 Class Activity 10","heading":"10 Class Activity 10","text":"","code":""},{"path":"class-activity-10.html","id":"example-1-extrasensory-perception-esp","chapter":"10 Class Activity 10","heading":"10.0.1 Example 1: Extrasensory Perception (ESP)","text":"ESP test, one person writes one letters , B, C, D, E tries telepathically communicate choice partner. partner tries guess letter selected.(c). sample proportion correct provide greatest evidence people ESP: (assume sample size every case.)","code":""},{"path":"class-activity-10.html","id":"example-2","chapter":"10 Class Activity 10","heading":"10.0.2 Example 2","text":"experiment, students given words memorize, randomly assigned either take 90 minute nap take caffeine pill. couple hours later, tested recall ability. wish test see sample provides evidence difference mean number words people can recall depending whether take nap caffeine.Answer:\\[H_0: \\mu_1 = \\mu_2\\]\n\\[H_a: \\mu_1 \\neq \\mu_2\\]","code":""},{"path":"class-activity-10.html","id":"example-3-guess-the-inference-method","chapter":"10 Class Activity 10","heading":"10.0.3 Example 3: Guess the inference method!","text":"question , indicate whether best assessed confidence interval, hypothesis test, whether statistical inference needed answer . inference used, define population parameter(s) interest indicate hypotheses test appropriate. Use correct notation.Answer: Testing claim difference:\\[p_f: \\text{proportion females support gun control}\\]\n\\[p_m: \\text{proportion males support gun control}\\]Answer:Answer: much means estimate: confidence interval \\(\\mu_m - \\mu_f\\)\\[\\mu_f: \\text{mean income (yearly) US females}\\]\n\\[\\mu_m: \\text{mean income (yearly) US males}\\]Answer:Test claim association:\\[H_0: \\rho = 0 \\text{ } \\beta_1 = 0\\]\\[H_a: \\rho > 0 \\text{ } \\beta_1 > 0\\]\\[\\rho : \\text{correlatio nbetween temp chirp rate}\\]","code":""},{"path":"class-activity-10.html","id":"example-1-revisited","chapter":"10 Class Activity 10","heading":"10.0.4 Example 1 Revisited:","text":"Answer:Answer:","code":""},{"path":"class-activity-10.html","id":"example-2-revisited","chapter":"10 Class Activity 10","heading":"10.0.5 Example 2 Revisited:","text":"","code":""},{"path":"class-activity-11.html","id":"class-activity-11","chapter":"11 Class Activity 11","heading":"11 Class Activity 11","text":"Midterm Review !!","code":""},{"path":"class-activity-12.html","id":"class-activity-12","chapter":"12 Class Activity 12","heading":"12 Class Activity 12","text":"Midterm !!","code":""},{"path":"class-activity-13.html","id":"class-activity-13","chapter":"13 Class Activity 13","heading":"13 Class Activity 13","text":"","code":""},{"path":"class-activity-13.html","id":"example-1-esp","chapter":"13 Class Activity 13","heading":"13.1 Example 1: ESP","text":"ESP test, one person writes one letters , B, C, D, E tries telepathically communicate choice partner. partner tries guess letter selected. null alternative hypotheses testing whether people ESP \\(H_0: p=0.2\\) \\(H_A: p > 0.2\\) \\(p\\) true proportion correct guesses. test hypotheses, try \\(n=10\\) times get 3 correct guesses.","code":""},{"path":"class-activity-13.html","id":"a-explain-how-to-generate-a-randomization-distribution-for-hatp-the-sample-proportion-of-correct-guesses-that-is-consistent-with-h_0-p0.2.","chapter":"13 Class Activity 13","heading":"13.1.0.1 (a) Explain how to generate a randomization distribution for \\(\\hat{p}\\), the sample proportion of correct guesses, that is consistent with \\(H_0: p=0.2\\).","text":"","code":""},{"path":"class-activity-13.html","id":"b-navigate-to-the-statkey-website.","chapter":"13 Class Activity 13","heading":"13.1.0.2 (b) Navigate to the Statkey website.","text":"Select Test Single Proportion option Randomization Hypothesis Tests. Click Edit Data enter count 3 sample size 10. select Null Hypothesis proportion p change value 0.20.Generate 1 Sample null randomization distribution. many correct guesses obtained sample? Repeat couple times.Generate 1000 Samples couple times. unusual getting least 3 correct guesses 10 tries?","code":""},{"path":"class-activity-13.html","id":"c-compute-the-randomization-p-value","chapter":"13 Class Activity 13","heading":"13.1.0.3 (c) Compute the randomization p-value","text":"Select Right Tail button top plot. Change x-axis value \\(\\hat{p}\\) = 0.3. p-value: proportion resampled \\(\\hat{p}\\) values 0.30 ?","code":""},{"path":"class-activity-13.html","id":"d-interpret-conclusion","chapter":"13 Class Activity 13","heading":"13.1.0.4 (d) Interpret + Conclusion","text":"Interpret p-value. p-value support alternative hypothesis (think 3 correct 10 tries statistically significant results) inconclusive? Explain.","code":""},{"path":"class-activity-13.html","id":"example-2-which-p-value-shows-more-evidence","chapter":"13 Class Activity 13","heading":"13.2 Example 2: Which P-value shows more evidence?","text":"Using randomization distribution test \\(H_0: \\rho = 0\\) vs. \\(H_A: \\rho > 0\\).Example 2","code":""},{"path":"class-activity-13.html","id":"a-match-the-p-value-and-sample-statistic","chapter":"13 Class Activity 13","heading":"13.2.0.1 (a) Match the p-value and sample statistic","text":"Match sample correlation p-values given , shading area randomization distribution corresponds sample correlation/p-value combo.Sample correlations: \\(r = 0.1, r=0.3, r = 0.5\\)P-values: \\(0.005, 0.15, 0.35\\)","code":""},{"path":"class-activity-13.html","id":"b-which-sample-correlationp-value-combo-shows-the-most-evidence-for-the-alternative-hypothesis","chapter":"13 Class Activity 13","heading":"13.2.0.2 (b) Which sample correlation/p-value combo shows the most evidence for the alternative hypothesis?","text":"","code":""},{"path":"class-activity-13.html","id":"example-3-sleep-or-caffeine-for-memory","chapter":"13 Class Activity 13","heading":"13.3 Example 3: Sleep or Caffeine for Memory","text":"experiment, 24 students given words memorize, randomly assigned take 90 minute nap take caffeine pill (12 group). tested recall ability. test see sample provides evidence difference mean number words people can recall depending whether take nap caffeine. hypotheses :\\[\nH_0: \\mu_S - \\mu_C = 0 \\ \\ H_A: \\mu_S - \\mu_C \\neq 0\n\\]sample mean difference \\(\\bar{x}_S - \\bar{x}_C = 3\\). want know difference sample means statistically significant.","code":""},{"path":"class-activity-13.html","id":"a-explain-how-to-generate-a-randomization-distribution-for-barx_s---barx_c-that-is-consistent-with-h_0-mu_s---mu_c-0.","chapter":"13 Class Activity 13","heading":"13.3.0.1 (a) Explain how to generate a randomization distribution for \\(\\bar{x}_S - \\bar{x}_C\\) that is consistent with \\(H_0: \\mu_S - \\mu_C = 0\\).","text":"","code":""},{"path":"class-activity-13.html","id":"b-navigate-to-the-statkey-website.-1","chapter":"13 Class Activity 13","heading":"13.3.0.2 (b) Navigate to the Statkey website.","text":"Select Test Difference Means option Randomization Hypothesis Tests. Change data set Leniency Smiles Sleep Caffeine Words. Note original sample data sample mean difference 3 words.Generate 1 Sample null randomization distribution. difference average word recall two groups sample? Repeat couple times.Generate 1000 Samples times (get least 3000 resamples). unusual getting difference means 3 words?","code":""},{"path":"class-activity-13.html","id":"c-compute-the-randomization-p-value-1","chapter":"13 Class Activity 13","heading":"13.3.0.3 (c) Compute the randomization p-value","text":"Select Two-Tail button top plot. Change positive x-axis value observed difference 3.0. p-value 2 times proportion resamples difference 3 . p-value?Example 3","code":""},{"path":"class-activity-13.html","id":"d-interpret-conclusion-1","chapter":"13 Class Activity 13","heading":"13.3.0.4 (d) Interpret + Conclusion","text":"Interpret p-value. p-value support alternative hypothesis (think difference means 3 statistically significant) inconclusive? Explain.","code":""},{"path":"class-activity-13.html","id":"e-redo-in-rstudio","chapter":"13 Class Activity 13","heading":"13.3.0.5 (e) Redo in Rstudio","text":"First get data Lock website check important summary stats:load CarletonStats package run permTest(y ~ x, data=) command y quantitative (0/1 coded) response x defines two groups comparing.observed difference reported -3?p-value? Statkey p-value? neighbors p-value? ?","code":"\nwordData <- read.csv(\"http://math.carleton.edu/Stats215/Textbook/SleepCaffeine.csv\")\nboxplot(Words ~ Group , data=wordData)\ntapply(wordData$Words, wordData$Group, summary)$Caffeine\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   6.00   10.00   12.50   12.25   14.25   18.00 \n\n$Sleep\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   13.75   15.50   15.25   17.25   21.00 \nlibrary(CarletonStats)\npermTest(Words ~ Group, data=wordData)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  Caffeine :  12.25      Sleep :  15.25 \n Observed difference: -3 \n\n Mean of permutation distribution: 0.01003 \n Standard error of permutation distribution: 1.50089 \n P-value:  0.0472 \n\n    *-------------*"},{"path":"class-activity-13.html","id":"example-4-resident-vs-non-resident-tuition","chapter":"13 Class Activity 13","heading":"13.4 Example 4: Resident vs Non-resident Tuition","text":"lab manual data set Tuition2006 random sample state colleges universities U.S. want know average tuition charged non-residents higher residents state colleges universities:\\[\nH_0: \\mu_{Non-res} - \\mu_{Res} = 0 \\ \\ H_A: \\mu_{Non-res} - \\mu_{Res} > 0\n\\]","code":""},{"path":"class-activity-13.html","id":"a-paired-data","chapter":"13 Class Activity 13","heading":"13.4.0.1 (a) Paired Data","text":"Read data. Note case (school) response value resident non-resident tuition variables. makes paired data example. Contrast word recall example case (student) one response (word recall) treatment (caffeine/sleep).","code":"\ntuition <- read.csv(\"http://math.carleton.edu/Stats215/RLabManual/Tuition2006.csv\")\nhead(tuition)  X        Institution  Res NonRes  Diff\n1 1 Univ of Akron (OH) 4200   8800 -4600\n2 2  Athens State (AL) 1900   3600 -1700\n3 3    Ball State (IN) 3400   8600 -5200\n4 4  Bloomsburg U (PA) 3200   7000 -3800\n5 5     UC Irvine (CA) 3400  12700 -9300\n6 6 Central State (OH) 2600   5700 -3100"},{"path":"class-activity-13.html","id":"b-permutation-test-for-paired-data","chapter":"13 Class Activity 13","heading":"13.4.0.2 (b) Permutation test for paired data","text":"Let’s compute difference non-resident resident tuitions (NR minus R):average difference tuition costs?observed mean difference statistically significant? test use command permTestPaired:alt greater used function permTestPaired(~ B) computes paired differences “” minus “B”.p-value test?observed mean difference statistically significant?","code":"\ndiff <- tuition$NonRes - tuition$Res\nsummary(diff)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    200    2650    3100    3584    4500    9300 \nhist(diff)\npermTestPaired(NonRes ~ Res,data = tuition, alt = \"greater\")\n    ** Permutation test for mean of paired difference **\n\n Permutation test with alternative: greater \n Observed mean\n  NonRes :  6405.263     Res :  2821.053 \n Observed difference  NonRes - Res : 3584.211 \n\n Mean of permutation distribution: 10.84266 \n Standard error of permutation distribution: 949.2923 \n P-value:  1e-04 \n\n    *-------------*"},{"path":"class-activity-13.html","id":"example-5-evaluating-drugs-to-fight-cocaine-addition","chapter":"13 Class Activity 13","heading":"13.5 Example 5: Evaluating Drugs to Fight Cocaine Addition","text":"randomized experiment treating cocaine addiction, 48 cocaine addicts trying quit randomly assigned take either desipramine (new drug), Lithium (existing drug). response variable whether person relapsed (means person unable break cycle addiction returned using cocaine.) testing see desipramine better lithium treating cocaine addiction. results shown two-way table.","code":""},{"path":"class-activity-13.html","id":"a-using-p_d-for-the-true-proportion-of-desipramine-users-who-relapse-and-p_l-for-the-true-proportion-of-lithium-users-who-relapse-write-the-null-and-alternative-hypotheses.","chapter":"13 Class Activity 13","heading":"13.5.0.1 (a) Using \\(p_D\\) for the true proportion of desipramine users who relapse and \\(p_L\\) for the true proportion of lithium users who relapse, write the null and alternative hypotheses.","text":"","code":""},{"path":"class-activity-13.html","id":"b-compute-the-appropriate-sample-statistic-needed-to-assess-the-hypotheses-above.","chapter":"13 Class Activity 13","heading":"13.5.0.2 (b) Compute the appropriate sample statistic needed to assess the hypotheses above.","text":"","code":""},{"path":"class-activity-13.html","id":"c-how-might-we-compute-a-randomization-sample-for-this-data","chapter":"13 Class Activity 13","heading":"13.5.0.3 (c) How might we compute a randomization sample for this data?","text":"","code":""},{"path":"class-activity-13.html","id":"d-navigate-to-the-statkey-website.","chapter":"13 Class Activity 13","heading":"13.5.0.4 (d) Navigate to the Statkey website.","text":"Select Test Difference Proportions option Randomization Hypothesis Tests. Click Edit Data let Group 1 “Desipramine” 2 “Lithium”, enter relapse counts 10 18 sample sizes 24. Check null hypothesis matches (). Generate couple thousand samples. Describe resulting distribution. centered?Answer: resulting distribution, shown Figure 1, bell-shaped centered value null hypothesis, zero.Example 1d","code":""},{"path":"class-activity-13.html","id":"e-compute-and-interpret-the-p-value-for-this-test.","chapter":"13 Class Activity 13","heading":"13.5.0.5 (e) Compute and interpret the p-value for this test.","text":"Answer: left-tail test computing difference D - L, see StatKey p-value (proportion randomization samples difference -.333 smaller) 2 (Figure 1). 2% time see least 33% fewer relapse cases using despramine lithium just due chance difference relapse rates two treatments.","code":""},{"path":"class-activity-13.html","id":"f-make-a-formal-decision-reject-or-not-using-a-5-significance-level-then-restate-your-conclusion-in-context-for-the-problem-do-not-use-words-like-reject-or-hypothesis.","chapter":"13 Class Activity 13","heading":"13.5.0.6 (f) Make a formal decision (reject or not) using a 5% significance level, then restate your conclusion in context for the problem (do not use words like “reject” or “hypothesis”).","text":"","code":""},{"path":"class-activity-13.html","id":"h-use-statkey-to-compute-and-interpret-a-95-bootstrap-confidence-interval-for-the-difference-in-the-relapse-proportion-for-the-two-treatments.-explain-how-this-ci-agrees-with-your-test-conclusion-in-f.","chapter":"13 Class Activity 13","heading":"13.5.0.7 (h) Use Statkey to compute and interpret a 95% bootstrap confidence interval for the difference in the relapse proportion for the two treatments. Explain how this CI agrees with your test conclusion in (f).","text":"Answer: 95% confident relapse rate despramine 8.3 58.3 percent less relapse rate lithium. completely agrees test conclusion despramine better treatment cocaine addiction. (Figure 2 shows bootstrap distribution centered sample difference -0.333.)Example 1h","code":""},{"path":"class-activity-14.html","id":"class-activity-14","chapter":"14 Class Activity 14","heading":"14 Class Activity 14","text":"","code":""},{"path":"class-activity-14.html","id":"example-1-gender-stereotypes-in-children---study-4","chapter":"14 Class Activity 14","heading":"14.1 Example 1: Gender stereotypes in children - study 4","text":"data example comes study 4 described Science article: http://science.sciencemag.org/content/355/6323/389. study involved asking children interest level game researcher described “children really, really smart.” higher value variable interest, interested child playing game.","code":"\nstudy4 <- read.csv(\"http://math.carleton.edu/kstclair/data/Stereo4.csv\")\nhead(study4)    study subj gender   age    interest race     race2\n1 Study 4   65   girl age 6  0.37953534    5     white\n2 Study 4   66   girl age 6 -0.78071539    5     white\n3 Study 4   67   girl age 6 -0.47631654    5     white\n4 Study 4   68   girl age 6 -0.07234632    5     white\n5 Study 4   69    boy age 6 -0.70319450    6 non-white\n6 Study 4   70   girl age 6  0.52467564    5     white\n  eduave income        ses        age2\n1     16  90000 -0.1543908 age 6 and 7\n2     16 125000  0.2298424 age 6 and 7\n3     18  25000 -0.3446883 age 6 and 7\n4     17 125000  0.4914816 age 6 and 7\n5     19 125000  1.0147600 age 6 and 7\n6     12  65000 -1.4753998 age 6 and 7"},{"path":"class-activity-14.html","id":"a-interest-in-5-year-olds---test","chapter":"14 Class Activity 14","heading":"14.1.0.1 (a) Interest in 5 year olds - test","text":"Recall comparison mean interest level 5 year old boys girls. Generate randomization distribution test:\n\\[\nH_0: \\mu_{B5} - \\mu_{G5} = 0 \\ \\ H_0: \\mu_{B5} - \\mu_{G5} \\neq 0\n\\]SE randomization distribution?\nClick answerAnswer: SE 0.26.z-score observed difference means using distribution? Interpret value.\n\nClick answerAnswer: distribution center 0 SE 0.26. z-score \n\\[\nz = \\dfrac{-0.13341 - 0}{0.26051} = -0.51\n\\]\nmeans observed difference -0.133 0.51 SEs hypothesized difference 0.large small observed difference sample means need reject null hypothesis using 5% significance level.\nClick answerAnswer: Since distribution bell-shaped, can use fact 5% sample differences 2 SE’s /center difference 0. sample difference extreme lead two-sided p-value less significance level 5%. data, 2 SE’s sample difference 0.521 observed difference extreme 0.521 lead rejecting null hypothesis difference.","code":"\nlibrary(dplyr)\nstudy4age5 <- filter(study4, age2 == \"age 5\")\nboxplot(interest ~ gender, data=study4age5)\nlibrary(CarletonStats)\npermTest(interest ~ gender, data = study4age5)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  -0.10435    girl :  0.02906 \n Observed difference: -0.13341 \n\n Mean of permutation distribution: 0.00331 \n Standard error of permutation distribution: 0.26112 \n P-value:  0.6068 \n\n    *-------------*\n-0.13341/0.26051 [1] -0.5121109\n2*0.26051 [1] 0.52102"},{"path":"class-activity-14.html","id":"b-interest-in-5-year-olds---ci","chapter":"14 Class Activity 14","heading":"14.1.0.2 (b) Interest in 5 year olds - CI","text":"Consider 95% (bootstrap) CI true difference mean interest \\(\\mu_{B5} - \\mu_{G5}\\).interval contain difference 0?\nClick answer\nAnswer: Yes, since didn’t reject null difference 0 using 5% significance level (p-value = 0.617).\ninterval contain difference 0?Click answerAnswer: Yes, since didn’t reject null difference 0 using 5% significance level (p-value = 0.617).Compute bootstrap distribution. CI capture 0?Compute bootstrap distribution. CI capture 0?Answer: SE 0.26, similar randomization distribution SE.\n- Sketch bootstrap randomization distributions. Make sure accurately represent center variation distributions.","code":"\nset.seed(7)\nboot(interest ~ gender, data = study4age5)\n    ** Bootstrap interval for difference of statistic\n\n Observed difference of statistic:  boy - girl =  -0.13341 \n Mean of bootstrap distribution: -0.13776 \n Standard error of bootstrap distribution: 0.25939 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-0.6459180  0.3652884 \n\n        *--------------*\ncurve(dnorm(x,0,.26),from=-1,to=1, ylab=\"\",xlab=\"sample mean differences\")\nabline(v=0, lty=3)\ncurve(dnorm(x,-0.133,.26),from=-1,to=1, add=T, col=\"red\")\nabline(v=-0.133, col=\"red\", lty=3)\nlegend(\"topleft\", col=c(\"black\",\"red\"), legend=c(\"Randomization\",\"Bootstrap\"), lty=1)"},{"path":"class-activity-14.html","id":"c-interest-in-6-and-7-year-olds---test","chapter":"14 Class Activity 14","heading":"14.1.0.3 (c) Interest in 6 and 7 year olds - test","text":"Redo part () age group age 6 7.SE randomization distribution?\nClick answerAnswer: SE 0.225.z-score observed difference means using distribution? Interpret value.\n\nClick answerAnswer: distribution center 0 SE 0.225. z-score \n\\[\nz = \\dfrac{0.53505 - 0}{0.22539 } = 2.37\n\\]\nmeans observed difference 0.535 2.37 SEs hypothesized difference 0.Answer: Since distribution bell-shaped, can use fact 5% sample differences 2 SE’s /center difference 0. sample difference extreme lead two-sided p-value less significance level 5%. data, 2 SE’s sample difference 0.451 observed difference extreme 0.451 lead rejecting null hypothesis difference.","code":"\nstudy4age67 <- filter(study4, age2 == \"age 6 and 7\")\nboxplot(interest ~ gender, data=study4age67)\npermTest(interest ~ gender, data = study4age67)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  0.21635     girl :  -0.31869 \n Observed difference: 0.53505 \n\n Mean of permutation distribution: -0.00312 \n Standard error of permutation distribution: 0.22035 \n P-value:  0.0114 \n\n    *-------------*\n0.53505/0.22539 [1] 2.373885\n2*0.22539 [1] 0.45078"},{"path":"class-activity-14.html","id":"d-interest-in-6-and-7-year-olds---ci","chapter":"14 Class Activity 14","heading":"14.1.0.4 (d) Interest in 6 and 7 year olds - CI","text":"Redo part (b) 6 7 year olds.interval contain difference 0?\nClick answer\nAnswer: , since rejected null difference 0 using 5% significance level (p-value = 0.015).\ninterval contain difference 0?Click answerAnswer: , since rejected null difference 0 using 5% significance level (p-value = 0.015).Compute bootstrap distribution. CI capture 0?Compute bootstrap distribution. CI capture 0?bootstrap SE? similar randomization distribution SE?\nClick answer\nAnswer: SE 0.21, similar randomization distribution SE.\nbootstrap SE? similar randomization distribution SE?Click answerAnswer: SE 0.21, similar randomization distribution SE.Sketch bootstrap randomization distributions. Make sure accurately represent center variation distributions.Sketch bootstrap randomization distributions. Make sure accurately represent center variation distributions.","code":"\nboot(interest ~ gender, data = study4age67)\n    ** Bootstrap interval for difference of statistic\n\n Observed difference of statistic:  boy - girl =  0.53505 \n Mean of bootstrap distribution: 0.53468 \n Standard error of bootstrap distribution: 0.20659 \n\n Bootstrap percentile interval\n     2.5%     97.5% \n0.1259895 0.9348764 \n\n        *--------------*\ncurve(dnorm(x,0,.22),from=-.7,to=1.4, ylab=\"\",xlab=\"sample mean differences\")\nabline(v=0, lty=3)\ncurve(dnorm(x,0.535,.21),from=-1,to=1.4, add=T, col=\"red\")\nabline(v=0.535, col=\"red\", lty=3)\nlegend(\"topleft\", col=c(\"black\",\"red\"), legend=c(\"Randomization\",\"Bootstrap\"), lty=1)"},{"path":"class-activity-14.html","id":"e-interest-in-5-year-olds","chapter":"14 Class Activity 14","heading":"14.1.0.5 (e) Interest in 5 year olds","text":"Redo randomization test bootstrap CI 5 year olds, time omit outlier boy case low interest level. Recall use command:omit case, add argument subset = -39 permTest boot commands used () (b).observed difference get closer 0 case omitted? Explain changes.\nClick answer\nAnswer: low case pulls mean response boys (: \\(\\bar{x}_{B5} = -0.10435\\), without: \\(\\bar{x}_{B5} = 0.01417\\)). Since girl mean response doesn’t change (\\(\\bar{x}_{G5} = 0.02906\\)), omitting case make two means closer together makes difference closer 0 (: \\(\\bar{x}_{B5} - \\bar{x}_{G5} = -0.13341\\), without: \\(\\bar{x}_{B5} - \\bar{x}_{G5} = -0.01488\\)).\nobserved difference get closer 0 case omitted? Explain changes.Click answerAnswer: low case pulls mean response boys (: \\(\\bar{x}_{B5} = -0.10435\\), without: \\(\\bar{x}_{B5} = 0.01417\\)). Since girl mean response doesn’t change (\\(\\bar{x}_{G5} = 0.02906\\)), omitting case make two means closer together makes difference closer 0 (: \\(\\bar{x}_{B5} - \\bar{x}_{G5} = -0.13341\\), without: \\(\\bar{x}_{B5} - \\bar{x}_{G5} = -0.01488\\)).SEs distributions (bootstrap randomization) get smaller larger case omitted? Explain change.\nClick answer\nAnswer: low case creates larger variability sample mean boys, turn makes SE sample mean difference variable (: SE 0.26, without: SE 0.24).\nSEs distributions (bootstrap randomization) get smaller larger case omitted? Explain change.Click answerAnswer: low case creates larger variability sample mean boys, turn makes SE sample mean difference variable (: SE 0.26, without: SE 0.24).Compute z-score observed difference means using randomization distribution. value futher closer z-score 0 case omitted? Explain changes.p-value get smaller larger (doesn’t change) case omitted? Explain changes.\nClick answerAnswer: p-value larger case removed (: p-value = 0.617, without: p-value = 0.944). observed difference closer 0 (fewer SE away) case omitted.\n","code":"\nboxplot(interest ~ gender, data=study4age5)\nwhich(study4age5$interest < -2)[1] 39\nset.seed(7)\npermTest(interest ~ gender, data = study4age5, subset = -39)\n    ** Permutation test **\n\n Permutation test with alternative: two.sided \n Observed statistic\n  boy :  0.01417     girl :  0.02906 \n Observed difference: -0.01488 \n\n Mean of permutation distribution: -0.00265 \n Standard error of permutation distribution: 0.2469 \n P-value:  0.957 \n\n    *-------------*\nboot(interest ~ gender, data = study4age5, subset = -39)\n    ** Bootstrap interval for difference of statistic\n\n Observed difference of statistic:  boy - girl =  -0.01488 \n Mean of bootstrap distribution: -0.01565 \n Standard error of bootstrap distribution: 0.23826 \n\n Bootstrap percentile interval\n      2.5%      97.5% \n-0.4751690  0.4520149 \n\n        *--------------*"},{"path":"class-activity-15.html","id":"class-activity-15","chapter":"15 Class Activity 15","heading":"15 Class Activity 15","text":"","code":""},{"path":"class-activity-15.html","id":"example-1-sat-verbal-scores","chapter":"15 Class Activity 15","heading":"15.1 Example 1: SAT Verbal scores","text":"Suppose verbal SAT scores population normally distributed mean \\(\\mu=580\\) standard deviation \\(\\sigma = 70\\). \\(X\\) shorthand verbal SAT score, can write \\(X \\sim N(580,70)\\).","code":""},{"path":"class-activity-15.html","id":"a-what-proportion-of-scores-are-above-650","chapter":"15 Class Activity 15","heading":"15.1.0.1 (a) What proportion of scores are above 650?","text":"Answer: 15.9% scores 650.","code":"\npnorm(650,mean=580,sd=70) # proportion below[1] 0.8413447\n1-pnorm(650,mean=580,sd=70) # proportion above[1] 0.1586553"},{"path":"class-activity-15.html","id":"b-what-is-the-25th-percentile-q1","chapter":"15 Class Activity 15","heading":"15.1.0.2 (b) What is the 25th percentile (Q1)?","text":"Answer: score 533 25th percentile, meaning 25% scores value.","code":"\nqnorm(.25,mean=580,sd=70)[1] 532.7857"},{"path":"class-activity-15.html","id":"c-what-is-the-iqr-for-verbal-sat-scores-in-this-population-hint-find-q1-and-q3","chapter":"15 Class Activity 15","heading":"15.1.0.3 (c) What is the IQR for verbal SAT scores in this population? (Hint: find Q1 and Q3)","text":"Answer: 25th percentile (Q1) 533 75th percentile (Q3) 627. IQR normally distributed variable 94 points.","code":"\nq1 <- qnorm(.25,mean=580,sd=70);q1[1] 532.7857\nq3 <- qnorm(.75,mean=580,sd=70);q3[1] 627.2143\nq3-q1[1] 94.42857"},{"path":"class-activity-15.html","id":"d-what-score-high-or-low-will-be-deemed-an-outlier-according-the-boxplot-rules-for-outliers","chapter":"15 Class Activity 15","heading":"15.1.0.4 (d) What score, high or low, will be deemed an outlier according the boxplot rules for outliers?","text":"Answer: Using 1.5IQR’s boxplot rule gives lower fence 392 upper fence 768. score 392 768 called outlier according rule.","code":"\n1.5*94[1] 141\nq1 - 1.5*94[1] 391.7857\nq3 + 1.5*94[1] 768.2143"},{"path":"class-activity-15.html","id":"e-what-percent-of-the-population-will-be-deemed-an-outlier","chapter":"15 Class Activity 15","heading":"15.1.0.5 (e) What percent of the population will be deemed an outlier?","text":"Answer: need find proportion scores 392 768. symmetric distribution, find 0.004 tails. 0.8% population deemed outliers according boxplot rule.","code":"\npnorm(392,mean=580,sd=70)[1] 0.003618747\n1-pnorm(768,mean=580,sd=70)[1] 0.003618747"},{"path":"class-activity-15.html","id":"example-2-standard-normal","chapter":"15 Class Activity 15","heading":"15.2 Example 2: Standard Normal","text":"standard normal distribution mean 0 standard deviation 1.","code":""},{"path":"class-activity-15.html","id":"a-what-percent-of-sat-scores-are-at-least-1-standard-deviation-above-average","chapter":"15 Class Activity 15","heading":"15.2.0.1 (a) What percent of SAT scores are at least 1 standard deviation above average?","text":"","code":"\npnorm(1)  # proportion below[1] 0.8413447\n1-pnorm(1) # proportion above[1] 0.1586553"},{"path":"class-activity-15.html","id":"b-how-many-standard-deviations-away-from-average-is-the-25th-percentile-of-sat-scores","chapter":"15 Class Activity 15","heading":"15.2.0.2 (b) How many standard deviations away from average is the 25th percentile of SAT scores?","text":"Answer: 25th percentile SAT scores (normally distributed values) 0.67 standard deviations average. also find value using answer (1b):\\[\nz = \\dfrac{533 - 580}{70} = -0.67\n\\]","code":"\nqnorm(.25)[1] -0.6744898\n(533 - 580)/70[1] -0.6714286"},{"path":"class-activity-16.html","id":"class-activity-16","chapter":"16 Class Activity 16","heading":"16 Class Activity 16","text":"","code":""},{"path":"class-activity-16.html","id":"example-1-is-divorce-morally-acceptable","chapter":"16 Class Activity 16","heading":"16.1 Example 1: Is Divorce Morally Acceptable?","text":"study, find 67% women random sample view divorce morally acceptable. provide evidence 50% women view divorce morally acceptable? standard error estimate assuming null hypothesis true 0.021.","code":""},{"path":"class-activity-16.html","id":"a-what-are-the-null-and-alternative-hypotheses-for-this-test","chapter":"16 Class Activity 16","heading":"16.1.0.1 (a) What are the null and alternative hypotheses for this test?","text":"","code":""},{"path":"class-activity-16.html","id":"b-what-is-the-standardized-test-statistic","chapter":"16 Class Activity 16","heading":"16.1.0.2 (b) What is the standardized test statistic?","text":"Answer: observed sample proportion 0.67 standard error 0.021. null true, expect sampling distribution sample mean (approximately) normally distributed center 0.50 SE 0.021. standardized score sample proportion \n\\[\nz = \\dfrac{\\textrm{statistic} - \\textrm{null parameter}}{SE} = \\dfrac{0.67 - 0.50}{0.021} = 8.10\n\\]\nobserved proportion 8.1 SEs hypothesized value 0.5.Note randomization distribution look roughly like (observed proportion denoted red X):","code":"\n(0.67 - 0.5)/0.021[1] 8.095238\ncurve(dnorm(x,0.5,.021),from=.3,to=.7,xlab=\"sample proportions\")\npoints(0.67,0,pch=\"X\",col=\"red\")"},{"path":"class-activity-16.html","id":"c-use-the-normal-distribution-to-find-the-p-value.","chapter":"16 Class Activity 16","heading":"16.1.0.3 (c) Use the normal distribution to find the p-value.","text":"Answer: can see normal plot , p-value small alternative looking big sample proportions. p-value proportion times get sample proportion big, bigger , 0.67; equivantly, proportion times get sample proportion least 8.1 SEs hypothesized proportion. report p-value less 0.0001.","code":"\n1-pnorm(8.10,0,1)[1] 2.220446e-16"},{"path":"class-activity-16.html","id":"d-what-is-the-conclusion-of-the-test","chapter":"16 Class Activity 16","heading":"16.1.0.4 (d) What is the conclusion of the test?","text":"","code":""},{"path":"class-activity-16.html","id":"e-use-the-normal-distribution-to-find-a-99-confidence-interval-for-the-proportion-of-all-women-who-view-divorce-as-morally-acceptable.-interpret-your-answer.","chapter":"16 Class Activity 16","heading":"16.1.0.5 (e) Use the normal distribution to find a 99% confidence interval for the proportion of all women who view divorce as morally acceptable. Interpret your answer.","text":"Answer: Without knowing bootstrap SE, best guess randomization distribution SE given 0.021. 99% confidence interval look like:\n\\[\nstatistic \\pm z^*SE = 0.67 \\pm z^* (0.021)\n\\]\n\\(z^*\\) 99% CI corresponds 99.5th percentile (90% middle + 0.5% left tail). \\(z^* = 2.576\\), get 99% confidence interval 0.616 0.724.","code":"\nqnorm(0.995)[1] 2.575829\n0.67 - 2.576*0.021[1] 0.615904\n0.67 + 2.576*0.021[1] 0.724096"},{"path":"class-activity-16.html","id":"example-2-do-men-and-women-differ-in-opinions-about-divorce","chapter":"16 Class Activity 16","heading":"16.2 Example 2: Do Men and Women Differ in Opinions about Divorce?","text":"study described , find 71% men view divorce morally acceptable. Use information previous example test whether significant difference men women view divorce. standard error difference proportions null hypothesis proportions equal 0.029.","code":""},{"path":"class-activity-16.html","id":"a-what-are-the-null-and-alternative-hypotheses-for-this-test-1","chapter":"16 Class Activity 16","heading":"16.2.0.1 (a) What are the null and alternative hypotheses for this test?","text":"Answer: Using notation (3a), except denoting male/female populations, get","code":""},{"path":"class-activity-16.html","id":"b-what-is-the-standardized-test-statistic-1","chapter":"16 Class Activity 16","heading":"16.2.0.2 (b) What is the standardized test statistic?","text":"Answer: Suppose look difference \\(p_m - p_f\\). observed difference 0.04 (0.71 - 0.67). value 1.4 SEs hypothesized difference 0:\n\\[\nz = \\dfrac{\\textrm{statistic} - \\textrm{null parameter}}{SE} = \\dfrac{(0.71 - 0.67) - 0}{0.029} = 1.379\n\\]Note randomization distribution difference sample proportions look roughly like (observed proportion difference denoted red X):","code":"\n(0.04 - 0)/0.029[1] 1.37931\ncurve(dnorm(x,0,.029),from=-.1,to=.1,xlab=\"sample proportions\")\npoints(0.04,0,pch=\"X\",col=\"red\")"},{"path":"class-activity-16.html","id":"c-use-the-normal-distribution-to-find-the-p-value.-1","chapter":"16 Class Activity 16","heading":"16.2.0.3 (c) Use the normal distribution to find the p-value.","text":"Answer: two-tail test. Since observed difference less 2 SEs away 0 know (two-tailed) p-value bigger 0.05. see p-value 2(0.084) = 0.168.","code":"\n1-pnorm(1.379,0,1) # proportion above z=1.379[1] 0.08394738\n2*(1-pnorm(1.379,0,1)) # p-value for two-sided[1] 0.1678948"},{"path":"class-activity-16.html","id":"d-what-is-the-conclusion-of-the-test-1","chapter":"16 Class Activity 16","heading":"16.2.0.4 (d) What is the conclusion of the test?","text":"","code":""},{"path":"class-activity-17.html","id":"class-activity-17","chapter":"17 Class Activity 17","heading":"17 Class Activity 17","text":"","code":""},{"path":"class-activity-17.html","id":"example-1-is-the-economy-a-top-priority","chapter":"17 Class Activity 17","heading":"17.1 Example 1: Is the Economy a Top Priority?","text":"survey 1,502 Americans January 2012 found 86% consider economy “top priority” president congress. section 3.2 handout, gave standard error sample proportion 0.01, SE used compute confidence interval. Show SE computed using appropriate SE formula chapter 6.Answer: sample proportion \\(\\hat{p}= 0.86\\). SE sample proportion confidence interval given :","code":""},{"path":"class-activity-17.html","id":"example-2-movie-goers-are-more-likely-to-watch-at-home","chapter":"17 Class Activity 17","heading":"17.2 Example 2: Movie Goers are More Likely to Watch at Home","text":"random sample 500 movie goers January 2013, 320 said likely wait watch new movie comfort home. Compute interpret 95% confidence interval proportion movie goers likely watch new movie home.Answer: see \\(\\hat{p}=\\frac{320}{500}=0.640\\) (keep least 3 decimal spots ensure accuracy SE calculation!) confidence interval given :\\[\\text { Statistic }+/-Z^{*} S E\\]\\[\\begin{array}{l}\n\\hat{p} \\pm z^{*} \\cdot \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\\n0.64 \\pm 1.96 \\cdot \\sqrt{\\frac{0.64(1-0.64)}{500}} \\\\\n0.64 \\pm 0.042\\\\\n(0.598, 0.682)\n\\end{array}\\]","code":""},{"path":"class-activity-17.html","id":"example-3-sample-size-and-margin-of-error-for-movie-goers","chapter":"17 Class Activity 17","heading":"17.3 Example 3: Sample Size and Margin of Error for Movie Goers","text":"sample size needed example 2 want margin error within ±2%? (Use sample proportion original sample.)Answer:\\[\\begin{array}{l}\n0.02=z^{*} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\\nn=\\left(\\frac{z^{*}}{0.02}\\right)^{2} \\hat{p}(1-\\hat{p})\\\\\\quad =\\left(\\frac{1.96}{0.02}\\right)^{2} 0.64(1-0.64)=2212.76\n\\end{array}\\]sample size needed want margin error within ±2%, use conservative estimate p = 0.5?Answer:\\[n=\\left(\\frac{1.96}{0.02}\\right)^{2} 0.5(1-0.5)=2401\\]","code":""},{"path":"class-activity-17.html","id":"example-4-mendels-green-peas","chapter":"17 Class Activity 17","heading":"17.4 Example 4: Mendel’s green peas?","text":"One Gregor Mendel’s famous genetic experiments dealt raising pea plants. According Mendel’s genetic theory, certain set conditions proportion pea plants produce smooth green peas p=3/16 (0.1875). sample n=556 plants experiment 108 smooth green peas. provide evidence problem Mendel’s theory proportion different 3/16? Show details test.Answer: testing \\(H_{0}: p=0.1875\\) vs \\(H_{}: p \\neq 0.1875\\) p represents proportion pea plans smooth green peas. sample proportion \\(\\hat{p}=\\frac{108}{556}=0.1942\\) sample size \\(n=556\\). test statistic :\\[z=\\frac{\\text { Statistic }-\\text { Null }}{S E}=\\frac{\\hat{p}-p_{0}}{\\sqrt{\\frac{p_{0}\\left(1-p_{0}\\right)}{n}}}=\\frac{0.1942-0.1875}{\\sqrt{\\frac{0.1875(1-0.1875)}{556}}}=0.405\\]two-tail test, see area right 0.405 normal distribution 0.343 (1-pnorm(0.405)), p-value 2(0.343) = 0.686.R command : 2*(1-pnorm(0.405))","code":""},{"path":"class-activity-18.html","id":"class-activity-18","chapter":"18 Class Activity 18","heading":"18 Class Activity 18","text":"","code":""},{"path":"class-activity-18.html","id":"example-1-change-in-gun-ownership","chapter":"18 Class Activity 18","heading":"18.1 Example 1: Change in gun ownership","text":"2016 study described Guardian found random sample US adults 1994 found female rate gun ownership 9%. similar random sample 2015 found rate female gun ownership rose 12%. section 3.2 handout, assumed SE difference two sample proportions 2%. Show SE computed using appropriate SE formula chapter 6. Assume sample sizes 1994 2015 500.Answer:\n1994 sample proportion \\(\\hat{p}_{1994} = 0.09\\) 2015 sample proportion \\(\\hat{p}_{2015} = 0.12\\) . SE difference two sample proportions confidence interval given :","code":""},{"path":"class-activity-18.html","id":"example-2-accuracy-of-lie-detectors","chapter":"18 Class Activity 18","heading":"18.2 Example 2: Accuracy of Lie Detectors","text":"Participants study evaluate accuracy lie detectors divided two groups, one group reading true material group reading false material, connected lie detector. groups received electric shocks add stress. two way table indicates whether participants lying telling truth also whether lie detector indicated lying .","code":""},{"path":"class-activity-18.html","id":"a-are-the-conditions-met-for-using-the-normal-distribution","chapter":"18 Class Activity 18","heading":"18.2.1 (a) Are the conditions met for using the normal distribution?","text":"","code":""},{"path":"class-activity-18.html","id":"b-find-the-three-sample-proportions-for-the-proportion-of-times-the-lie-detector-says-the-person-is-lying-the-proportion-for-the-lying-people-the-proportion-for-the-truthful-people-and-the-pooled-proportion.","chapter":"18 Class Activity 18","heading":"18.2.2 (b) Find the three sample proportions for the proportion of times the lie detector says the person is lying (the proportion for the lying people, the proportion for the truthful people, and the pooled proportion).","text":"","code":""},{"path":"class-activity-18.html","id":"c-test-to-see-if-there-is-a-difference-in-the-proportion-of-times-the-lie-detector-says-the-person-is-lying-depending-on-whether-the-person-is-lying-or-telling-the-truth.-show-all-details-of-the-hypothesis-test.","chapter":"18 Class Activity 18","heading":"18.2.3 (c) Test to see if there is a difference in the proportion of times the lie detector says the person is lying, depending on whether the person is lying or telling the truth. Show all details of the hypothesis test.","text":"Answer:testing \\(H_0:p_L = p_N\\) vs \\(H_a:p_L \\neq p_N\\). test statistic \\[z = \\frac{statistic-null}{SE} = \\frac{(\\hat{p}_L - \\hat{p}_N) - 0}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_l} + \\frac{\\hat{p}(1-\\hat{p})}{n_N}}} = \\frac{0.6458 - 0.5625}{\\sqrt{\\frac{0.6042(1-0.6042)}{48}} + \\frac{0.6042*(1-0.6042)}{48}} = 0.834 \\]two-tail test, area right 0.834 normal distribution 0.202 (1-pnorm(0.834)), p-value 2(0.202) = 0.404. R command : 2*(1-pnorm(0.834))fail reject H0 conclude enough evidence lie detector can tell whether person lying telling truth.","code":""},{"path":"class-activity-18.html","id":"example-3-smoking-and-pregnancy-rate","chapter":"18 Class Activity 18","heading":"18.3 Example 3: Smoking and Pregnancy Rate?","text":"smoking negatively affect person’s ability become pregnant? study collected data 678 women trying get pregnant. two-way table shows proportion successfully became pregnant first cycle trying smoking status. Find 90% confidence interval difference proportion women get pregnant, smokers non-smokers. Interpret interval context.conditions met using normal distribution (least 10 values cell table). see proportion smokers got pregnant 38/135 = 0.281 proportion non-smokers got pregnant 206/543 = 0.379. confidence interval given :\\[statistic \\pm z^* \\cdot SE \\]\n\\[(\\hat{p}_S - \\hat{p}_N) \\pm z^* \\cdot \\sqrt{\\frac{\\hat{p}_S(1- \\hat{p}_S)}{n_S} + \\frac{\\hat{p}_N(1- \\hat{p}_N)}{n_N}} \\]\\[(0.281 - 0.379) \\pm 1.645\\cdot \\sqrt{\\frac{0.281(1-0.281)}{135} + \\frac{0.379(1-0.379)}{543}} \\]\n\\[-0.098 \\pm 0.072 = (-0.170, -0.026) \\]\n90% sure proportion smokers get pregnant first cycle 0.170 0.026 less proportion non-smokers get pregnant first cycle. Note subtracted way, interval positive values, interpretation .","code":""},{"path":"class-activity-18.html","id":"example-4-florida-lakes-ph","chapter":"18 Class Activity 18","heading":"18.4 Example 4: Florida Lakes pH","text":"textbook dataset FloridaLakes contains data 53 lakes Florida. want know average pH lakes Florida different neutral value 7.","code":"\nlakes <- read.csv(\"http://www.lock5stat.com/datasets1e/FloridaLakes.csv\")\nhead(lakes)  ID         Lake Alkalinity  pH Calcium Chlorophyll\n1  1    Alligator        5.9 6.1     3.0         0.7\n2  2        Annie        3.5 5.1     1.9         3.2\n3  3       Apopka      116.0 9.1    44.1       128.3\n4  4 Blue Cypress       39.4 6.9    16.4         3.5\n5  5        Brick        2.5 4.6     2.9         1.8\n6  6       Bryant       19.6 7.3     4.5        44.1\n  AvgMercury NumSamples MinMercury MaxMercury\n1       1.23          5       0.85       1.43\n2       1.33          7       0.92       1.90\n3       0.04          6       0.04       0.06\n4       0.44         12       0.13       0.84\n5       1.20         12       0.69       1.50\n6       0.27         14       0.04       0.48\n  ThreeYrStdMercury AgeData\n1              1.53       1\n2              1.33       0\n3              0.04       0\n4              0.44       0\n5              1.33       1\n6              0.25       1"},{"path":"class-activity-18.html","id":"a-eda","chapter":"18 Class Activity 18","heading":"18.4.0.1 (a) EDA","text":"Always plot data get summary stats:sample mean standard deviation? Use appropriate notation.Can use t-inference methods pH variable?","code":"\nhist(lakes$pH)\nmean(lakes$pH)[1] 6.590566\nsd(lakes$pH)[1] 1.288449"},{"path":"class-activity-18.html","id":"b-se-for-the-sample-mean","chapter":"18 Class Activity 18","heading":"18.4.0.2 (b) SE for the sample mean","text":"Answer: estimated SE sample mean \\(SE_{\\bar{x}} = 0.1770\\).","code":"\nsd(lakes$pH)/sqrt(53)[1] 0.1769821"},{"path":"class-activity-18.html","id":"c-t-test-statistic","chapter":"18 Class Activity 18","heading":"18.4.0.3 (c) t-test statistic","text":"Answer: hypotheses \\(H_0: \\mu = 7\\) vs \\(H_A: \\mu \\neq 7\\). test stat \\[\nt = \\dfrac{6.591 - 7}{1.288/\\sqrt{53}} = -2.3134\n\\]observed mean 6.591 2.3 SEs hypothesized mean 7.","code":"\n(mean(lakes$pH) - 7)/(sd(lakes$pH)/sqrt(53)) [1] -2.31342"},{"path":"class-activity-18.html","id":"d-one-sample-t-test","chapter":"18 Class Activity 18","heading":"18.4.1 (d) One-sample t-test","text":"function t.test(x, mu=) can used one sample test comparing sample mean x hypothesized value given mu=. testing whether population mean equal 7 :t test stat given output? Verify matches answer (c), within reasonable rounding error.\nClick answerWhat p-value test? Interpret value.\nClick answerWhat test conclusion?\nClick answer","code":"\nt.test(lakes$pH, mu = 7)\n    One Sample t-test\n\ndata:  lakes$pH\nt = -2.3134, df = 52, p-value = 0.02469\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.235425 6.945707\nsample estimates:\nmean of x \n 6.590566 "},{"path":"class-activity-18.html","id":"e-one-sample-t-confidence-interval","chapter":"18 Class Activity 18","heading":"18.4.1.1 (e) One-sample t confidence interval","text":"","code":""},{"path":"class-activity-18.html","id":"f-qt-and-pt","chapter":"18 Class Activity 18","heading":"18.4.1.2 (f) qt and pt","text":"Answer: two-sided test, p-value twice proportion test stat \\(t=-2.313\\) t-distribution \\(df=53-1=52\\)95% CI, get 97.5th percentile t-distribution","code":"\n2*pt(-2.313,df=52)[1] 0.02471195\nqt(.975,52)[1] 2.006647"},{"path":"class-activity-18.html","id":"example-5-api","chapter":"18 Class Activity 18","heading":"18.5 Example 5: API","text":"Academic Performance Index (API) computed California schools. number, ranging low 200 high 1000, reflects school’s performance statewide standardized test (http://api.cde.ca.gov). SRS 200 schools interested school’s performance related wealth students. variable growth measures growth API 1999 2000 (API 2000 - API 1999).","code":"\napi <- read.csv(\"http://people.carleton.edu/~kstclair/data/api.csv\")"},{"path":"class-activity-18.html","id":"a-categorizing-wealth","chapter":"18 Class Activity 18","heading":"18.5.0.1 (a) Categorizing wealth","text":"Let’s define school “low wealth” 50% students eligible subsidized meals “high wealth” otherwise. can use ifelse command create variable wealth measures :many schools “low” “high” wealth.wealth API growth related?observed difference mean API growth high low wealth schools. Use correct notation.Can use t-inference methods compare mean growths?\nClick answer","code":"\napi$wealth <- ifelse(api$meals > 50, \"low\",\"high\")\ntable(api$wealth)\nhigh  low \n 102   98 \nlibrary(dplyr)\napi %>% group_by(wealth) %>% summarize(mean(growth), sd(growth))# A tibble: 2 × 3\n  wealth `mean(growth)` `sd(growth)`\n  <chr>           <dbl>        <dbl>\n1 high             25.2         28.8\n2 low              38.8         30.0\nboxplot(growth ~ wealth, data=api, xlab=\"API growth (2000 - 1999)\" , horizontal=T)"},{"path":"class-activity-18.html","id":"b-se-for-the-sample-mean-difference","chapter":"18 Class Activity 18","heading":"18.5.0.2 (b) SE for the sample mean difference","text":"Answer: SE mean difference 4.1544:\\[\nSD_{\\bar{x}_h - \\bar{x}_l} = \\sqrt{\\dfrac{28.75380^2}{102} + \\dfrac{29.95048^2}{98}} = 4.1544\n\\]","code":"\nsqrt(28.75380^2/102 +  29.95048^2/98)[1] 4.154404"},{"path":"class-activity-18.html","id":"c-t-test-statistic-1","chapter":"18 Class Activity 18","heading":"18.5.0.3 (c) t-test statistic","text":"Answer: hypotheses \\(H_0: \\mu_h - \\mu_l = 0\\) vs \\(H_A: \\mu_h - \\mu_l \\neq 0\\). test stat \\[t = \\dfrac{(25.24510 - 38.82653) - 0}{4.154404} = -3.2692\\]observed mean difference 3.3 SEs hypothesized mean difference 0.","code":"\n((25.24510 - 38.82653) - 0)/4.154404 [1] -3.269164"},{"path":"class-activity-18.html","id":"d-two-sample-t-test","chapter":"18 Class Activity 18","heading":"18.5.0.4 (d) Two-sample t-test","text":"evidence mean API growth differs low high wealth schools? Give hypotheses test, run t.test(y ~ x, data=) command conduct t-test give p-value conclusion.t test stat given output? Verify matches answer (c), within reasonable rounding error.\nClick answerWhat p-value test? Interpret value.\nClick answerWhat test conclusion?\nClick answer","code":"\nt.test(growth ~ wealth, data=api)\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -3.2692, df = 196.71, p-value = 0.001273\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -21.774321  -5.388544\nsample estimates:\nmean in group high  mean in group low \n          25.24510           38.82653 "},{"path":"class-activity-18.html","id":"e-consider-outliers","chapter":"18 Class Activity 18","heading":"18.5.0.5 (e) Consider outliers","text":"","code":""},{"path":"class-activity-18.html","id":"f-check-outlier-influence","chapter":"18 Class Activity 18","heading":"18.5.0.6 (f) Check outlier influence","text":"omit cases find row numbers, subset data:t-test stat change omitting two changes? change direction?Check answer anwer part (e)!\nClick answer","code":"\nwhich(api$growth > 120 )[1]  74 119\napi %>% slice(74,119)  # another dplyr package command           cds stype            name                 sname\n1 5.471911e+13     E Lincoln Element    Lincoln Elementary\n2 1.975342e+13     E Washington Elem Washington Elementary\n  snum                   dname dnum       cname cnum flag\n1 5873 Exeter Union Elementary  226      Tulare   53   NA\n2 2543   Redondo Beach Unified  585 Los Angeles   18   NA\n  pcttest api00 api99 target growth sch.wide comp.imp both\n1      98   693   504     15    189      Yes      Yes  Yes\n2     100   745   615      9    130      Yes      Yes  Yes\n  awards meals ell yr.rnd mobility acs.k3 acs.46 acs.core\n1    Yes    50  18   <NA>        9     18     NA       NA\n2    Yes    41  20   <NA>       16     19     30       NA\n  pct.resp not.hsg hsg some.col col.grad grad.sch avg.ed\n1       93      28  23       27       14        8   2.51\n2       81      11  26       32       16       16   2.99\n  full emer enroll api.stu    pw  fpc wealth\n1   91    9    196     177 30.97 6194   high\n2  100    3    391     313 30.97 6194   high\nt.test(growth ~ wealth, data = api, subset = -c(74,119))\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -4.395, df = 174.97, p-value = 1.916e-05\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -23.571116  -8.961945\nsample estimates:\nmean in group high  mean in group low \n          22.56000           38.82653 "},{"path":"class-activity-18.html","id":"g-95-confidence-interval","chapter":"18 Class Activity 18","heading":"18.5.0.7 (g) 95% confidence interval","text":"","code":""},{"path":"class-activity-18.html","id":"h-interpret-two-sample-ci","chapter":"18 Class Activity 18","heading":"18.5.0.8 (h) Interpret two-sample CI","text":"","code":""},{"path":"class-activity-19.html","id":"class-activity-19","chapter":"19 Class Activity 19","heading":"19 Class Activity 19","text":"","code":""},{"path":"class-activity-19.html","id":"example-1-florida-lakes-ph","chapter":"19 Class Activity 19","heading":"19.1 Example 1: Florida Lakes pH","text":"textbook dataset FloridaLakes contains data 53 lakes Florida. want know average pH lakes Florida different neutral value 7.","code":"\nlakes <- read.csv(\"http://www.lock5stat.com/datasets1e/FloridaLakes.csv\")\nhead(lakes)  ID         Lake Alkalinity  pH Calcium Chlorophyll\n1  1    Alligator        5.9 6.1     3.0         0.7\n2  2        Annie        3.5 5.1     1.9         3.2\n3  3       Apopka      116.0 9.1    44.1       128.3\n4  4 Blue Cypress       39.4 6.9    16.4         3.5\n5  5        Brick        2.5 4.6     2.9         1.8\n6  6       Bryant       19.6 7.3     4.5        44.1\n  AvgMercury NumSamples MinMercury MaxMercury\n1       1.23          5       0.85       1.43\n2       1.33          7       0.92       1.90\n3       0.04          6       0.04       0.06\n4       0.44         12       0.13       0.84\n5       1.20         12       0.69       1.50\n6       0.27         14       0.04       0.48\n  ThreeYrStdMercury AgeData\n1              1.53       1\n2              1.33       0\n3              0.04       0\n4              0.44       0\n5              1.33       1\n6              0.25       1"},{"path":"class-activity-19.html","id":"a-eda-1","chapter":"19 Class Activity 19","heading":"19.1.0.1 (a) EDA","text":"Always plot data get summary stats:sample mean standard deviation? Use appropriate notation.Can use t-inference methods pH variable?Answer: average pH \\(\\bar{x} = 6.591\\) standard deviation \\(s=1.288\\). distribution pH symmetric outliers, can use t-inference methods.","code":"\nhist(lakes$pH)\nmean(lakes$pH)[1] 6.590566\nsd(lakes$pH)[1] 1.288449"},{"path":"class-activity-19.html","id":"b-se-for-the-sample-mean-1","chapter":"19 Class Activity 19","heading":"19.1.0.2 (b) SE for the sample mean","text":"Answer: estimated SE sample mean \\(SE_{\\bar{x}} = 0.1770\\).","code":"\nsd(lakes$pH)/sqrt(53)[1] 0.1769821"},{"path":"class-activity-19.html","id":"c-t-test-statistic-2","chapter":"19 Class Activity 19","heading":"19.1.0.3 (c) t-test statistic","text":"Answer: hypotheses \\(H_0: \\mu = 7\\) vs \\(H_A: \\mu \\neq 7\\). test stat \\[\nt = \\dfrac{6.591 - 7}{1.288/\\sqrt{53}} = -2.3134\n\\]observed mean 6.591 2.3 SEs hypothesized mean 7.","code":"\n(mean(lakes$pH) - 7)/(sd(lakes$pH)/sqrt(53)) [1] -2.31342"},{"path":"class-activity-19.html","id":"d-one-sample-t-test-1","chapter":"19 Class Activity 19","heading":"19.1.1 (d) One-sample t-test","text":"function t.test(x, mu=) can used one sample test comparing sample mean x hypothesized value given mu=. testing whether population mean equal 7 :t test stat given output? Verify matches answer (c), within reasonable rounding error.Answer: test stat -2.31.p-value test? Interpret value.Answer: p-value 0.025. mean pH lakes 7, see sample mean least 2.31 SEs away 7 2.5% time samples 53 lakes.test conclusion?Answer: statistically significant difference observed mean pH 6.591 hypothesized mean 7 (t=-2.31, df=52, p=0.025).","code":"\nt.test(lakes$pH, mu = 7)\n    One Sample t-test\n\ndata:  lakes$pH\nt = -2.3134, df = 52, p-value = 0.02469\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.235425 6.945707\nsample estimates:\nmean of x \n 6.590566 "},{"path":"class-activity-19.html","id":"e-one-sample-t-confidence-interval-1","chapter":"19 Class Activity 19","heading":"19.1.1.1 (e) One-sample t confidence interval","text":"95% confidence interval population mean pH? Interpret CI.Answer: 95% confident mean pH lakes Florida 6.24 6.95.","code":""},{"path":"class-activity-19.html","id":"f-qt-and-pt-1","chapter":"19 Class Activity 19","heading":"19.1.1.2 (f) qt and pt","text":"Show compute p-value test (d) using pt command. show confidence interval (e) computed qt value.Answer: two-sided test, p-value twice proportion test stat \\(t=-2.313\\) t-distribution \\(df=53-1=52\\)95% CI, get 97.5th percentile t-distribution","code":"\n2*pt(-2.313,df=52)[1] 0.02471195\nqt(.975,52)[1] 2.006647"},{"path":"class-activity-19.html","id":"example-2-api","chapter":"19 Class Activity 19","heading":"19.2 Example 2: API","text":"Academic Performance Index (API) computed California schools. number, ranging low 200 high 1000, reflects school’s performance statewide standardized test (http://api.cde.ca.gov). SRS 200 schools interested school’s performance related wealth students. variable growth measures growth API 1999 2000 (API 2000 - API 1999).","code":"\napi <- read.csv(\"http://people.carleton.edu/~kstclair/data/api.csv\")"},{"path":"class-activity-19.html","id":"a-categorizing-wealth-1","chapter":"19 Class Activity 19","heading":"19.2.0.1 (a) Categorizing wealth","text":"Let’s define school “low wealth” 50% students eligible subsidized meals “high wealth” otherwise. can use ifelse command create variable wealth measures :many schools “low” “high” wealth.wealth API growth related?observed difference mean API growth high low wealth schools. Use correct notation.Can use t-inference methods compare mean growths?Answer: \\(n_h = 102\\) “high” wealth \\(n_l = 98\\) “low” wealth schools. low wealth schools tend higher (variable) growth high wealth schools. difference observed mean API growth high low growth schools \\(\\bar{x}_h - \\bar{x}_l = 25.24510 - 38.82653 = -13.58\\). can use t-methods since samples sizes (98 102) can deemed large isn’t severe skewness, two extreme outliers addressed .","code":"\napi$wealth <- ifelse(api$meals > 50, \"low\",\"high\")\ntable(api$wealth)\nhigh  low \n 102   98 \nlibrary(dplyr)\napi %>% group_by(wealth) %>% summarize(mean(growth), sd(growth))# A tibble: 2 × 3\n  wealth `mean(growth)` `sd(growth)`\n  <chr>           <dbl>        <dbl>\n1 high             25.2         28.8\n2 low              38.8         30.0\nboxplot(growth ~ wealth, data=api, xlab=\"API growth (2000 - 1999)\" , horizontal=T)"},{"path":"class-activity-19.html","id":"b-se-for-the-sample-mean-difference-1","chapter":"19 Class Activity 19","heading":"19.2.0.2 (b) SE for the sample mean difference","text":"Answer: SE mean difference 4.1544:\\[\nSD_{\\bar{x}_h - \\bar{x}_l} = \\sqrt{\\dfrac{28.75380^2}{102} + \\dfrac{29.95048^2}{98}} = 4.1544\n\\]","code":"\nsqrt(28.75380^2/102 +  29.95048^2/98)[1] 4.154404"},{"path":"class-activity-19.html","id":"c-t-test-statistic-3","chapter":"19 Class Activity 19","heading":"19.2.0.3 (c) t-test statistic","text":"Using SE (b) compute t-test statistic can used determine mean API growth differs low high wealth schools. Write hypotheses show t test statistic calculated. Interpret value context.Answer: hypotheses \\(H_0: \\mu_h - \\mu_l = 0\\) vs \\(H_A: \\mu_h - \\mu_l \\neq 0\\). test stat \\[\nt = \\dfrac{(25.24510 - 38.82653) - 0}{4.154404} = -3.2692\n\\]observed mean difference 3.3 SEs hypothesized mean difference 0.","code":"\n((25.24510 - 38.82653) - 0)/4.154404 [1] -3.269164"},{"path":"class-activity-19.html","id":"d-two-sample-t-test-1","chapter":"19 Class Activity 19","heading":"19.2.0.4 (d) Two-sample t-test","text":"evidence mean API growth differs low high wealth schools? Give hypotheses test, run t.test(y ~ x, data=) command conduct t-test give p-value conclusion.t test stat given output? Verify matches answer (c), within reasonable rounding error.Answer: test stat matches, \\(t = -3.2692\\).p-value test? Interpret value.Answer: p-value 0.001273. difference mean growth two populations, just 0.13% chance seeing sample mean difference 3.27 standard errors away 0.test conclusion?Answer: strong evidence suggest average API growth low high wealth schools .","code":"\nt.test(growth ~ wealth, data=api)\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -3.2692, df = 196.71, p-value = 0.001273\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -21.774321  -5.388544\nsample estimates:\nmean in group high  mean in group low \n          25.24510           38.82653 "},{"path":"class-activity-19.html","id":"e-consider-outliers-1","chapter":"19 Class Activity 19","heading":"19.2.0.5 (e) Consider outliers","text":"boxplot () shows number outliers high wealth group, two cases particular high. Suppose omitted two () extreme cases running test (d). p-value test smaller larger p-value computed part (d)? Explain.Answer: Removing two large outliers reduce mean high group reduce SD high group. actions magnify difference mean growth high low groups (increasing difference decreasing SE), test stat increase magnitude p-value decrease.","code":""},{"path":"class-activity-19.html","id":"f-check-outlier-influence-1","chapter":"19 Class Activity 19","heading":"19.2.0.6 (f) Check outlier influence","text":"omit cases find row numbers, subset data:t-test stat change omitting two changes? change direction?Check answer anwer part (e)!Answer: Without outliers, p-value decreases 0.00001916 even stronger evidence difference mean API growth. p-value decrease? Omitting two outliers decrease sample SD high group, turn (slightly) decrease SE difference means. Omitting two outliers also decrease sample mean high group (25.24510 22.56000), make observed difference means larger magnitude (-13.58 -16.27). test stat gets even 0 (drops -3.2692 -4.395), meaning observed difference outliers omitted away 0 (terms SEs) data points included. means p-value decrease (0.0013 0.00002) since data deemed ``extreme” null hypothesis.","code":"\nwhich(api$growth > 120 )[1]  74 119\napi %>% slice(74,119)  # another dplyr package command           cds stype            name                 sname\n1 5.471911e+13     E Lincoln Element    Lincoln Elementary\n2 1.975342e+13     E Washington Elem Washington Elementary\n  snum                   dname dnum       cname cnum flag\n1 5873 Exeter Union Elementary  226      Tulare   53   NA\n2 2543   Redondo Beach Unified  585 Los Angeles   18   NA\n  pcttest api00 api99 target growth sch.wide comp.imp both\n1      98   693   504     15    189      Yes      Yes  Yes\n2     100   745   615      9    130      Yes      Yes  Yes\n  awards meals ell yr.rnd mobility acs.k3 acs.46 acs.core\n1    Yes    50  18   <NA>        9     18     NA       NA\n2    Yes    41  20   <NA>       16     19     30       NA\n  pct.resp not.hsg hsg some.col col.grad grad.sch avg.ed\n1       93      28  23       27       14        8   2.51\n2       81      11  26       32       16       16   2.99\n  full emer enroll api.stu    pw  fpc wealth\n1   91    9    196     177 30.97 6194   high\n2  100    3    391     313 30.97 6194   high\nt.test(growth ~ wealth, data = api, subset = -c(74,119))\n    Welch Two Sample t-test\n\ndata:  growth by wealth\nt = -4.395, df = 174.97, p-value = 1.916e-05\nalternative hypothesis: true difference in means between group high and group low is not equal to 0\n95 percent confidence interval:\n -23.571116  -8.961945\nsample estimates:\nmean in group high  mean in group low \n          22.56000           38.82653 "},{"path":"class-activity-19.html","id":"g-95-confidence-interval-1","chapter":"19 Class Activity 19","heading":"19.2.0.7 (g) 95% confidence interval","text":"Compare two 95% CI given output (without outliers). Explain CIs change omitting two outliers.Answer: Without outliers: -23.57 -8.96 outliers: -21.77 -5.39. mentioned , omitting two points makes difference means away 0. shifts CI difference 0. Removing outliers also decrease SE sample difference, margin error interval without outliers , roughly, 7 margin error outliers , roughly, 8.","code":""},{"path":"class-activity-19.html","id":"h-interpret-two-sample-ci-1","chapter":"19 Class Activity 19","heading":"19.2.0.8 (h) Interpret two-sample CI","text":"Using results without two outliers, interpret 95% CI given output. use word ``difference’’ answer.Answer: 95% confident mean API growth 1999 2000 low wealth schools anywhere 8.96 points 23.57 points higher mean API growth high wealth schools California.","code":""},{"path":"class-activity-19.html","id":"example-3-matched-pairs","chapter":"19 Class Activity 19","heading":"19.3 Example 3: Matched Pairs","text":"study conducted determine effect home meter helping diabetics control blood glucose levels. Researchers like determine home meter effective helping patients reduce blood glucose levels. random sample 36 diabetics blood glucose levels measured taught use meter utilized meter 2 weeks. Researchers observed average decrease (- ) blood glucose level 2.78 mmol/liter standard deviation 6.05 mmol/liter. Analysis results shown :","code":"  Sample mean:  2.78 ; sample standard deviation:  6.05 ; sample size: 36\n  Standard error:  1.0083\n  95 percent confidence interval for true mean:  1.0763  , Infinity\n  Hypothesis test H0: mu =  0  Alternative is  greater\n  t statistic =  2.757 ; degrees of freedom =  35 ; p-value= 0.0046"},{"path":"class-activity-19.html","id":"a-what-conditions-need-to-be-met-by-this-data-to-use-t-inference-procedures","chapter":"19 Class Activity 19","heading":"19.3.0.1 (a) What conditions need to be met by this data to use \\(t\\) inference procedures?","text":"Answer: moderate sample size \\(n=36\\) need assume observed differences (-) strongly skewed outliers. assumptions met, t-inference procedures may appropriate.","code":""},{"path":"class-activity-19.html","id":"b-define-the-unknown-parameter-of-interest-be-very-specific-then-state-the-null-and-alternative-hypotheses-for-this-test.-make-sure-your-hypotheses-agree-with-the-output","chapter":"19 Class Activity 19","heading":"19.3.0.2 (b) Define the unknown parameter of interest (be very specific), then state the null and alternative hypotheses for this test. Make sure your hypotheses agree with the output!","text":"Answer: Let \\(\\mu\\) represent population mean decrease glucose levels measured treatment (- ). positive value \\(\\mu\\) implies home meter effective reducing blood glucose levels. alternative hypothesis (research statement) \\(\\mu\\) greater 0 null statement \\(\\mu\\) equal 0, meaning benefit using treatment.\n\\[\nH_0:  \\mu = 0 \\textrm{ vs. } H_A: \\mu > 0\n\\]","code":""},{"path":"class-activity-19.html","id":"c-what-is-the-test-statistic-value-for-this-test-what-does-this-value-indicate","chapter":"19 Class Activity 19","heading":"19.3.0.3 (c) What is the test statistic value for this test? What does this value indicate?","text":"Answer: test stat value 2.757. mean glucose level decrease sample 2.757 SE’s hypothesized mean decrease 0.","code":""},{"path":"class-activity-19.html","id":"d-is-there-sufficient-evidence-to-claim-that-the-monitor-is-effective-in-helping-patients-reduce-their-blood-glucose-levels","chapter":"19 Class Activity 19","heading":"19.3.0.4 (d) Is there sufficient evidence to claim that the monitor is effective in helping patients reduce their blood glucose levels?","text":"Answer: reject \\(H_0\\) \\(p\\)-value small. Since P-value 0.3% quite small, can conclude strong evidence use home meters lowers blood glucose levels, average (\\(H_A\\)).","code":""},{"path":"class-activity-19.html","id":"e-what-type-of-error-1-or-2-could-you-have-made-in-part-d-if-you-did-make-this-error-what-are-its-implications-for-people-with-diabetes","chapter":"19 Class Activity 19","heading":"19.3.0.5 (e) What type of error (1 or 2) could you have made in part (d)? If you did make this error, what are its implications for people with diabetes?","text":"Answer: Since rejected, may made type 1 error rejecting null actually true. means claimed home meter useful reducing blood glucose levels, average, fact doesn’t reduce levels. People diabetes encouraged use meters (cost insurance company) help control glucose levels see real benefit.","code":""},{"path":"class-activity-19.html","id":"f-compute-and-interpret-a-95-confidence-interval-for-the-true-average-decrease-in-blood-glucose-levels.-note-that-this-ci-is-not-given-above-the-ci-given-in-the-output-is-a-one-sided-ci.","chapter":"19 Class Activity 19","heading":"19.3.0.6 (f) Compute and interpret a 95% confidence interval for the true average decrease in blood glucose levels. (Note that this CI is not given above, the CI given in the output is a ``one-sided” CI.)","text":"Answer: 95% CI population mean decrease glucose level \n\\[\n\\bar{x} \\pm t^*_{n-1} \\dfrac{s}{\\sqrt{n}} = 2.78\\pm 2.042 \\dfrac{6.05}{\\sqrt{36}} = 2.78 \\pm 2.017 = (0.72, 4.84)\n\\]\n\\(t^*\\) based 36-1=35 degrees freedom. Using green table, round df 30 get \\(t^*_{30} = 2.042\\). using R command qt(.975,df=35) get exact value \\(t^*_{35}=2.0301\\).\n95% confident , learning use home meter, average decrease blood glucose population 0.72 4.84 mmol/liter.","code":""},{"path":"what-is-r.html","id":"what-is-r","chapter":"21 What is R?","heading":"21 What is R?","text":"R free open source statistical programming language facilitates statistical computation. myriad application can done R, thanks huge online support community dedicated packages. However, R graphical user interface run typing commands text interface.","code":""},{"path":"what-is-r.html","id":"what-is-rstudio","chapter":"21 What is R?","heading":"21.1 What is RStudio?","text":"RStudio provides graphical interface R! can think RStudio graphical front-end R provides extra functionality. use R programming language RStudio interface essential component course.","code":""},{"path":"what-is-r.html","id":"r-studio-server","chapter":"21 What is R?","heading":"21.2 R Studio Server","text":"quickest way get started go https://maize.mathcs.carleton.edu, opens R Studio window web browser. logged , recommend following:Step 1: Create folder course can save work. Files window, click New Folder.Step 2: Click Tools -> Global Options -> R Markdown. uncheck box says “Show output inline…”(also possible download RStudio laptop. Instructions may found end document.)","code":""},{"path":"what-is-r.html","id":"r-markdown-basics","chapter":"21 What is R?","heading":"21.3 R Markdown Basics","text":"R Markdown file (.Rmd file) combines R commands written analyses, ‘knit’ together HTML, PDF, Microsoft Word document.R Markdown file contains three essential elements:Header: header (top) file contains information like document title, author, date preferred output format (pdf_document, word_document, html_document).Header: header (top) file contains information like document title, author, date preferred output format (pdf_document, word_document, html_document).Written analysis: write analysis header embed R code needed. online help shows ways add formatting details like bold words, lists, section labels, etc final pdf/word/html document. example, adding ** word bold word compiled document.Written analysis: write analysis header embed R code needed. online help shows ways add formatting details like bold words, lists, section labels, etc final pdf/word/html document. example, adding ** word bold word compiled document.R chunks: R chunks contain R commands want evaluated. embed chunks within written analysis evaluated compile document.R chunks: R chunks contain R commands want evaluated. embed chunks within written analysis evaluated compile document.","code":""},{"path":"what-is-r.html","id":"installing-rrstudio-not-needed-if-you-are-using-the-maize-server","chapter":"21 What is R?","heading":"21.4 Installing R/RStudio (not needed if you are using the maize server)","text":"Download latest version R:\nWindows: http://cran.r-project.org/bin/windows/base/\nMac: http://cran.r-project.org/bin/macosx/\nWindows: http://cran.r-project.org/bin/windows/base/Mac: http://cran.r-project.org/bin/macosx/Download free Rstudio desktop version (Windows Mac): https://www.rstudio.com/products/rstudio/download/Use default download install options .","code":""},{"path":"what-is-r.html","id":"install-latex-for-knitting-r-markdown-documents-to-pdf","chapter":"21 What is R?","heading":"21.5 Install LaTeX (for knitting R Markdown documents to PDF):","text":"want compile R Markdown .pdf files, also need LaTeX distribution (Note: necessary choose compile Word document.) Click instructions Windows instructions Mac, depending operating system complete installation.","code":""},{"path":"what-is-r.html","id":"updating-rrstudio-not-needed-if-you-are-using-the-maize-server","chapter":"21 What is R?","heading":"21.6 Updating R/RStudio (not needed if you are using the maize server)","text":"used local version R/RStudio still installed machine, make sure recent versions program.check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .check version R, run command getRversion() compare version newest version posted https://cran.r-project.org/. need update, install newer version using installation directions .RStudio, check updates menu option Help > Check updates. Follow directions update needed.RStudio, check updates menu option Help > Check updates. Follow directions update needed.","code":""},{"path":"what-is-r.html","id":"instructions","chapter":"21 What is R?","heading":"21.7 Instructions","text":"using Rstudio computer, using File>Open File menu find open .Rmd file.using Maize Rstudio browser:Files tab, select Upload Choose File find .Rmd downloaded. Click OK upload course folder/location maize server account.Files tab, select Upload Choose File find .Rmd downloaded. Click OK upload course folder/location maize server account.Click .Rmd file appropriate folder open file.Click .Rmd file appropriate folder open file.Extra notes:can run line code placing cursor line code clicking Run Selected Line(s)can run line code placing cursor line code clicking Run Selected Line(s)can run entire chunk clicking green triangle right side code chunk.can run entire chunk clicking green triangle right side code chunk.small edit code addition, Knit Markdown. wait end Knit, harder find errors work.small edit code addition, Knit Markdown. wait end Knit, harder find errors work.Format output type: can use pdf_document, html_document type, word_document type.Format output type: can use pdf_document, html_document type, word_document type.Maize users: may also need allow “pop-” web browser knitting documents.Maize users: may also need allow “pop-” web browser knitting documents.","code":""},{"path":"what-is-r.html","id":"few-more-instructions","chapter":"21 What is R?","heading":"21.8 Few More Instructions","text":"default setting Rstudio running chunks “output” (numbers, graphs) \nshown inline within Markdown Rmd. prefer plots appear right console chunk, change settings follows:Select Tools > Global Options.Click R Markdown section uncheck (needed) option Show output inline \nR Markdown documents.Click OK.Now try running R chunks .Rmd file see difference. can recheck box prefer\ndefault setting.","code":""},{"path":"r-markdown.html","id":"r-markdown","chapter":"22 R Markdown","heading":"22 R Markdown","text":"R Markdown document. Markdown simple formatting syntax authoring HTML, PDF, MS Word documents. details using R Markdown see http://rmarkdown.rstudio.com.can use asterisk mark provide emphasis, *italics* **bold**.can create lists dash:Item 1Item 2Item 3\nSubitem 1\nSubitem 1Item 4You can embed Latex equations -line, \\(\\frac{1}{n} \\sum_{=1}^{n} x_{}\\) new line \\[\\text{Var}(X) = \\frac{1}{n-1}\\sum_{-1}^{n} (x_{} - \\bar{x})^2 \\]\n## Embed R code chunk:Useto produce:can also evaluate display results R code. tasks can accomplished suitably labeled chunk like following:","code":"- Item 1\n- Item 2\n- Item 3\n  + Subitem 1\n* Item 4```r\nUse back ticks to \ncreate a block of code\n```Use back ticks to \ncreate a block of code\nsummary(cars)     speed           dist       \n Min.   : 4.0   Min.   :  2.00  \n 1st Qu.:12.0   1st Qu.: 26.00  \n Median :15.0   Median : 36.00  \n Mean   :15.4   Mean   : 42.98  \n 3rd Qu.:19.0   3rd Qu.: 56.00  \n Max.   :25.0   Max.   :120.00  \nfit <- lm(dist ~ speed, data = cars)\nfit\nCall:\nlm(formula = dist ~ speed, data = cars)\n\nCoefficients:\n(Intercept)        speed  \n    -17.579        3.932  "},{"path":"r-markdown.html","id":"including-plots","chapter":"22 R Markdown","heading":"22.1 Including Plots","text":"can also embed plots. See Figure 22.1 example:\nFigure 22.1: fancy pie chart.\n(Credit: Yihui Xie)","code":"\npar(mar = c(0, 1, 0, 1))\npie(\n  c(280, 60, 20),\n  c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),\n  col = c('#0292D8', '#F7EA39', '#C4B632'),\n  init.angle = -50, border = NA\n)"},{"path":"r-markdown.html","id":"read-in-data-files","chapter":"22 R Markdown","heading":"22.2 Read in data files","text":"","code":"\nsimple_data <- read.csv(\"https://deepbas.io/data/simple-1.dat\", )\nsummary(simple_data)    initials            state                age      \n Length:3           Length:3           Min.   :45.0  \n Class :character   Class :character   1st Qu.:47.5  \n Mode  :character   Mode  :character   Median :50.0  \n                                       Mean   :52.0  \n                                       3rd Qu.:55.5  \n                                       Max.   :61.0  \n     time          \n Length:3          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \nknitr::kable(simple_data)"},{"path":"r-markdown.html","id":"hide-the-code","chapter":"22 R Markdown","heading":"22.3 Hide the code","text":"enter echo = FALSE option R chunk (see .Rmd file). prevents R code printed document; just see results.","code":""},{"path":"helpful-r-codes.html","id":"helpful-r-codes","chapter":"23 Helpful R codes","heading":"23 Helpful R codes","text":"","code":""},{"path":"helpful-r-codes.html","id":"residual-plots-in-ggplot2","chapter":"23 Helpful R codes","heading":"23.1 Residual Plots in ggplot2","text":"","code":"\n# residual size plot\nlibrary(ggplot2)\nbac <- read.csv(\"https://raw.githubusercontent.com/deepbas/statdatasets/main/BAC.csv\")\n\nfit <- lm(BAC ~ Beers, data = bac) # fit the model\nbac$predicted <- predict(fit)   # Save the predicted values\nbac$residuals <- residuals(fit) # Save the residual values\n\nggplot(bac, aes(x = Beers, y = BAC)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +     # regression line  \n  geom_segment(aes(xend = Beers, yend = predicted), alpha = .2) +      # draw line from point to line\n  geom_point(aes(color = abs(residuals), size = abs(residuals))) +  # size of the points\n  scale_color_continuous(low = \"green\", high = \"red\") +   \n  labs(title = \"BAC Vs. Beers\") +# color of the points mapped to residual size - green smaller, red larger\n  guides(color = FALSE, size = FALSE) +                             # Size legend removed\n  geom_point(aes(y = predicted), shape = 1, size = 2) +\n  scale_x_continuous(breaks=1:9)+\n  theme(axis.text=element_text(size=10),\n        axis.title=element_text(size=10,face=\"bold\"),\n        plot.title = element_text(size = 10, face = \"bold\"))\nggplot(bac, aes(x = Beers, y = residuals)) +\n  geom_point() +\n  theme(legend.position = \"none\") +\n  geom_segment(aes(xend = Beers, yend = 0), alpha = .2) +\n  scale_color_continuous(low = \"green\", high = \"red\") +   \n  geom_point(aes(color = abs(residuals), size = abs(residuals))) +  # size of the points\n  geom_hline(yintercept = 0, col = \"blue\", size = 0.5, linetype = \"dashed\") + \n  labs(title = \"BAC Vs. Beers\",\n       x = \"Beers\",\n       y = \"Residuals\") +\n  theme(plot.title = element_text(hjust=0.5, size=7, face='bold')) "},{"path":"helpful-r-codes.html","id":"plotly-codes","chapter":"23 Helpful R codes","heading":"23.2 Plotly codes","text":"","code":"\nlibrary(plotly)\n\ncell_phone_data <- data.frame(\n  Type = c(\"Android\", \"iPhone\", \"Blackberry\", \"Non Smartphone\", \"No Cell Phone\"),\n  Frequency = c(458, 437, 141, 924, 293)\n)\n\ndata <- data.frame(\n  Gender = c(\"Female\", \"Male\"),\n  In_a_relationship = c(32, 10),\n  Its_complicated = c(12, 7),\n  Single = c(63, 45)\n)\nplot_ly(cell_phone_data, labels = ~Type, values = ~Frequency, type = 'pie',\n        textposition = 'inside', hoverinfo = 'label+value+percent',\n        textinfo = 'label', insidetextfont = list(color = '#FFFFFF')) %>%\n  layout(title = 'Cell Phone Usage',\n         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),\n         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))\nplot_ly(data, x = ~Gender, y = ~In_a_relationship, type = 'bar', name = 'In a relationship') %>%\n  add_trace(y = ~Its_complicated, name = 'It\\'s complicated') %>%\n  add_trace(y = ~Single, name = 'Single') %>%\n  layout(yaxis = list(title = 'Number of People'), barmode = 'group')"}]
